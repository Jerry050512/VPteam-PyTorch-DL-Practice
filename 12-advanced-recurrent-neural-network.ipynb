{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Classifier 实现\n",
    "\n",
    "实现目标: 将名字分类为不同的国家\n",
    "\n",
    "## 数据集\n",
    "\n",
    "来源: [Github](https://github.com/d4em0n/nationality-classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCH = 100\n",
    "N_CHARS = 128\n",
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        with open(csv_file, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        self.names = [row[0] for row in rows[1:]]\n",
    "        self.countries = [int(row[1]) for row in rows[1:]]\n",
    "        self.len = len(self.names)\n",
    "\n",
    "        with open('./dataset/name2country/country.json', 'r') as f:\n",
    "            self.country_list = json.load(f)\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.names[idx], self.countries[idx]\n",
    "    \n",
    "    def idx2country(self, idx):\n",
    "        return self.country_list[idx]\n",
    "    \n",
    "train_dataset = NameDataset('./dataset/name2country/train.csv')\n",
    "test_dataset = NameDataset('./dataset/name2country/test.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRIES = train_dataset.country_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    period = time.time() - since\n",
    "    minutes = int(period / 60)\n",
    "    seconds = int(period - minutes * 60)\n",
    "    return '{:3d}m {:2d}s'.format(minutes, seconds)\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "def name2list(name):\n",
    "    return [ord(ch) for ch in name], len(name)\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [s[0] for s in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([s[1] for s in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    seq_tensor = torch.zeros(len(name_sequences), max(seq_lengths)).long()\n",
    "    for idx, (seq, seq_len) in enumerate(sequences_and_lengths):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)\n",
    "\n",
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "    \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)\n",
    "    \n",
    "    def forward(self, input, seq_lengths):\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embedding(input)\n",
    "\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths.cpu())      # 注意这个函数的 `lengths` 参数只接受 CPU 张量\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat((hidden[-1], hidden[-2]), dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        \n",
    "        return self.fc(hidden_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(train_loader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[{time_since(st_time)}] Epoch-{epoch+1} [{i}/{len(train_loader)}] loss: {total_loss/(i*len(inputs)):.4f}\")\n",
    "    return total_loss\n",
    "\n",
    "def test_model():\n",
    "    correct = 0\n",
    "    total = len(test_dataset)\n",
    "    print(\"Evaluating Trained Model...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(test_loader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        percent = f'{100*correct/total:.2f}%'\n",
    "        print(f\"Accuracy: {percent}\")\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0m  0s] Epoch-1 [10/549] loss: 0.0107\n",
      "[  0m  0s] Epoch-1 [20/549] loss: 0.0101\n",
      "[  0m  1s] Epoch-1 [30/549] loss: 0.0093\n",
      "[  0m  1s] Epoch-1 [40/549] loss: 0.0087\n",
      "[  0m  1s] Epoch-1 [50/549] loss: 0.0082\n",
      "[  0m  1s] Epoch-1 [60/549] loss: 0.0077\n",
      "[  0m  1s] Epoch-1 [70/549] loss: 0.0074\n",
      "[  0m  2s] Epoch-1 [80/549] loss: 0.0070\n",
      "[  0m  2s] Epoch-1 [90/549] loss: 0.0068\n",
      "[  0m  2s] Epoch-1 [100/549] loss: 0.0065\n",
      "[  0m  2s] Epoch-1 [110/549] loss: 0.0063\n",
      "[  0m  2s] Epoch-1 [120/549] loss: 0.0061\n",
      "[  0m  2s] Epoch-1 [130/549] loss: 0.0059\n",
      "[  0m  3s] Epoch-1 [140/549] loss: 0.0057\n",
      "[  0m  3s] Epoch-1 [150/549] loss: 0.0055\n",
      "[  0m  3s] Epoch-1 [160/549] loss: 0.0054\n",
      "[  0m  3s] Epoch-1 [170/549] loss: 0.0052\n",
      "[  0m  3s] Epoch-1 [180/549] loss: 0.0051\n",
      "[  0m  3s] Epoch-1 [190/549] loss: 0.0050\n",
      "[  0m  4s] Epoch-1 [200/549] loss: 0.0049\n",
      "[  0m  4s] Epoch-1 [210/549] loss: 0.0047\n",
      "[  0m  4s] Epoch-1 [220/549] loss: 0.0046\n",
      "[  0m  4s] Epoch-1 [230/549] loss: 0.0045\n",
      "[  0m  4s] Epoch-1 [240/549] loss: 0.0045\n",
      "[  0m  5s] Epoch-1 [250/549] loss: 0.0044\n",
      "[  0m  5s] Epoch-1 [260/549] loss: 0.0043\n",
      "[  0m  5s] Epoch-1 [270/549] loss: 0.0042\n",
      "[  0m  5s] Epoch-1 [280/549] loss: 0.0042\n",
      "[  0m  5s] Epoch-1 [290/549] loss: 0.0041\n",
      "[  0m  5s] Epoch-1 [300/549] loss: 0.0040\n",
      "[  0m  6s] Epoch-1 [310/549] loss: 0.0040\n",
      "[  0m  6s] Epoch-1 [320/549] loss: 0.0039\n",
      "[  0m  6s] Epoch-1 [330/549] loss: 0.0038\n",
      "[  0m  6s] Epoch-1 [340/549] loss: 0.0038\n",
      "[  0m  6s] Epoch-1 [350/549] loss: 0.0037\n",
      "[  0m  6s] Epoch-1 [360/549] loss: 0.0037\n",
      "[  0m  7s] Epoch-1 [370/549] loss: 0.0036\n",
      "[  0m  7s] Epoch-1 [380/549] loss: 0.0036\n",
      "[  0m  7s] Epoch-1 [390/549] loss: 0.0035\n",
      "[  0m  7s] Epoch-1 [400/549] loss: 0.0035\n",
      "[  0m  7s] Epoch-1 [410/549] loss: 0.0034\n",
      "[  0m  8s] Epoch-1 [420/549] loss: 0.0034\n",
      "[  0m  8s] Epoch-1 [430/549] loss: 0.0034\n",
      "[  0m  8s] Epoch-1 [440/549] loss: 0.0033\n",
      "[  0m  8s] Epoch-1 [450/549] loss: 0.0033\n",
      "[  0m  8s] Epoch-1 [460/549] loss: 0.0032\n",
      "[  0m  8s] Epoch-1 [470/549] loss: 0.0032\n",
      "[  0m  9s] Epoch-1 [480/549] loss: 0.0032\n",
      "[  0m  9s] Epoch-1 [490/549] loss: 0.0031\n",
      "[  0m  9s] Epoch-1 [500/549] loss: 0.0031\n",
      "[  0m  9s] Epoch-1 [510/549] loss: 0.0031\n",
      "[  0m  9s] Epoch-1 [520/549] loss: 0.0030\n",
      "[  0m 10s] Epoch-1 [530/549] loss: 0.0030\n",
      "[  0m 10s] Epoch-1 [540/549] loss: 0.0030\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 88.60%\n",
      "[  0m 11s] Epoch-2 [10/549] loss: 0.0013\n",
      "[  0m 11s] Epoch-2 [20/549] loss: 0.0013\n",
      "[  0m 11s] Epoch-2 [30/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [40/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [50/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [60/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [70/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [80/549] loss: 0.0013\n",
      "[  0m 12s] Epoch-2 [90/549] loss: 0.0012\n",
      "[  0m 13s] Epoch-2 [100/549] loss: 0.0012\n",
      "[  0m 13s] Epoch-2 [110/549] loss: 0.0012\n",
      "[  0m 13s] Epoch-2 [120/549] loss: 0.0012\n",
      "[  0m 13s] Epoch-2 [130/549] loss: 0.0012\n",
      "[  0m 13s] Epoch-2 [140/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [150/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [160/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [170/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [180/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [190/549] loss: 0.0012\n",
      "[  0m 14s] Epoch-2 [200/549] loss: 0.0012\n",
      "[  0m 15s] Epoch-2 [210/549] loss: 0.0012\n",
      "[  0m 15s] Epoch-2 [220/549] loss: 0.0012\n",
      "[  0m 15s] Epoch-2 [230/549] loss: 0.0012\n",
      "[  0m 15s] Epoch-2 [240/549] loss: 0.0012\n",
      "[  0m 15s] Epoch-2 [250/549] loss: 0.0012\n",
      "[  0m 16s] Epoch-2 [260/549] loss: 0.0012\n",
      "[  0m 16s] Epoch-2 [270/549] loss: 0.0012\n",
      "[  0m 16s] Epoch-2 [280/549] loss: 0.0012\n",
      "[  0m 16s] Epoch-2 [290/549] loss: 0.0012\n",
      "[  0m 16s] Epoch-2 [300/549] loss: 0.0011\n",
      "[  0m 16s] Epoch-2 [310/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [320/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [330/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [340/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [350/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [360/549] loss: 0.0011\n",
      "[  0m 17s] Epoch-2 [370/549] loss: 0.0011\n",
      "[  0m 18s] Epoch-2 [380/549] loss: 0.0011\n",
      "[  0m 18s] Epoch-2 [390/549] loss: 0.0011\n",
      "[  0m 18s] Epoch-2 [400/549] loss: 0.0011\n",
      "[  0m 18s] Epoch-2 [410/549] loss: 0.0011\n",
      "[  0m 18s] Epoch-2 [420/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [430/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [440/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [450/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [460/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [470/549] loss: 0.0011\n",
      "[  0m 19s] Epoch-2 [480/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [490/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [500/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [510/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [520/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [530/549] loss: 0.0011\n",
      "[  0m 20s] Epoch-2 [540/549] loss: 0.0011\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 92.41%\n",
      "[  0m 22s] Epoch-3 [10/549] loss: 0.0008\n",
      "[  0m 22s] Epoch-3 [20/549] loss: 0.0008\n",
      "[  0m 22s] Epoch-3 [30/549] loss: 0.0007\n",
      "[  0m 22s] Epoch-3 [40/549] loss: 0.0007\n",
      "[  0m 22s] Epoch-3 [50/549] loss: 0.0007\n",
      "[  0m 23s] Epoch-3 [60/549] loss: 0.0007\n",
      "[  0m 23s] Epoch-3 [70/549] loss: 0.0007\n",
      "[  0m 23s] Epoch-3 [80/549] loss: 0.0007\n",
      "[  0m 23s] Epoch-3 [90/549] loss: 0.0007\n",
      "[  0m 23s] Epoch-3 [100/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [110/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [120/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [130/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [140/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [150/549] loss: 0.0007\n",
      "[  0m 24s] Epoch-3 [160/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [170/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [180/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [190/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [200/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [210/549] loss: 0.0007\n",
      "[  0m 25s] Epoch-3 [220/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [230/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [240/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [250/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [260/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [270/549] loss: 0.0007\n",
      "[  0m 26s] Epoch-3 [280/549] loss: 0.0007\n",
      "[  0m 27s] Epoch-3 [290/549] loss: 0.0007\n",
      "[  0m 27s] Epoch-3 [300/549] loss: 0.0007\n",
      "[  0m 27s] Epoch-3 [310/549] loss: 0.0007\n",
      "[  0m 27s] Epoch-3 [320/549] loss: 0.0007\n",
      "[  0m 27s] Epoch-3 [330/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [340/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [350/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [360/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [370/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [380/549] loss: 0.0007\n",
      "[  0m 28s] Epoch-3 [390/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [400/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [410/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [420/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [430/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [440/549] loss: 0.0007\n",
      "[  0m 29s] Epoch-3 [450/549] loss: 0.0007\n",
      "[  0m 30s] Epoch-3 [460/549] loss: 0.0007\n",
      "[  0m 30s] Epoch-3 [470/549] loss: 0.0007\n",
      "[  0m 30s] Epoch-3 [480/549] loss: 0.0007\n",
      "[  0m 30s] Epoch-3 [490/549] loss: 0.0007\n",
      "[  0m 30s] Epoch-3 [500/549] loss: 0.0007\n",
      "[  0m 31s] Epoch-3 [510/549] loss: 0.0007\n",
      "[  0m 31s] Epoch-3 [520/549] loss: 0.0007\n",
      "[  0m 31s] Epoch-3 [530/549] loss: 0.0007\n",
      "[  0m 31s] Epoch-3 [540/549] loss: 0.0007\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 94.66%\n",
      "[  0m 32s] Epoch-4 [10/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [20/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [30/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [40/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [50/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [60/549] loss: 0.0005\n",
      "[  0m 33s] Epoch-4 [70/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [80/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [90/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [100/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [110/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [120/549] loss: 0.0005\n",
      "[  0m 34s] Epoch-4 [130/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [140/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [150/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [160/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [170/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [180/549] loss: 0.0005\n",
      "[  0m 35s] Epoch-4 [190/549] loss: 0.0005\n",
      "[  0m 36s] Epoch-4 [200/549] loss: 0.0005\n",
      "[  0m 36s] Epoch-4 [210/549] loss: 0.0005\n",
      "[  0m 36s] Epoch-4 [220/549] loss: 0.0005\n",
      "[  0m 36s] Epoch-4 [230/549] loss: 0.0004\n",
      "[  0m 36s] Epoch-4 [240/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [250/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [260/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [270/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [280/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [290/549] loss: 0.0004\n",
      "[  0m 37s] Epoch-4 [300/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [310/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [320/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [330/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [340/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [350/549] loss: 0.0005\n",
      "[  0m 38s] Epoch-4 [360/549] loss: 0.0005\n",
      "[  0m 39s] Epoch-4 [370/549] loss: 0.0005\n",
      "[  0m 39s] Epoch-4 [380/549] loss: 0.0005\n",
      "[  0m 39s] Epoch-4 [390/549] loss: 0.0005\n",
      "[  0m 39s] Epoch-4 [400/549] loss: 0.0005\n",
      "[  0m 39s] Epoch-4 [410/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [420/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [430/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [440/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [450/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [460/549] loss: 0.0004\n",
      "[  0m 40s] Epoch-4 [470/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [480/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [490/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [500/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [510/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [520/549] loss: 0.0004\n",
      "[  0m 41s] Epoch-4 [530/549] loss: 0.0004\n",
      "[  0m 42s] Epoch-4 [540/549] loss: 0.0004\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.19%\n",
      "[  0m 43s] Epoch-5 [10/549] loss: 0.0003\n",
      "[  0m 43s] Epoch-5 [20/549] loss: 0.0003\n",
      "[  0m 43s] Epoch-5 [30/549] loss: 0.0004\n",
      "[  0m 43s] Epoch-5 [40/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [50/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [60/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [70/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [80/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [90/549] loss: 0.0003\n",
      "[  0m 44s] Epoch-5 [100/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [110/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [120/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [130/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [140/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [150/549] loss: 0.0003\n",
      "[  0m 45s] Epoch-5 [160/549] loss: 0.0003\n",
      "[  0m 46s] Epoch-5 [170/549] loss: 0.0003\n",
      "[  0m 46s] Epoch-5 [180/549] loss: 0.0003\n",
      "[  0m 46s] Epoch-5 [190/549] loss: 0.0003\n",
      "[  0m 46s] Epoch-5 [200/549] loss: 0.0003\n",
      "[  0m 46s] Epoch-5 [210/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [220/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [230/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [240/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [250/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [260/549] loss: 0.0003\n",
      "[  0m 47s] Epoch-5 [270/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [280/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [290/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [300/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [310/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [320/549] loss: 0.0003\n",
      "[  0m 48s] Epoch-5 [330/549] loss: 0.0003\n",
      "[  0m 49s] Epoch-5 [340/549] loss: 0.0003\n",
      "[  0m 49s] Epoch-5 [350/549] loss: 0.0003\n",
      "[  0m 49s] Epoch-5 [360/549] loss: 0.0003\n",
      "[  0m 49s] Epoch-5 [370/549] loss: 0.0003\n",
      "[  0m 49s] Epoch-5 [380/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [390/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [400/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [410/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [420/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [430/549] loss: 0.0003\n",
      "[  0m 50s] Epoch-5 [440/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [450/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [460/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [470/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [480/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [490/549] loss: 0.0003\n",
      "[  0m 51s] Epoch-5 [500/549] loss: 0.0003\n",
      "[  0m 52s] Epoch-5 [510/549] loss: 0.0003\n",
      "[  0m 52s] Epoch-5 [520/549] loss: 0.0003\n",
      "[  0m 52s] Epoch-5 [530/549] loss: 0.0003\n",
      "[  0m 52s] Epoch-5 [540/549] loss: 0.0003\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.62%\n",
      "[  0m 53s] Epoch-6 [10/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [20/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [30/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [40/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [50/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [60/549] loss: 0.0002\n",
      "[  0m 54s] Epoch-6 [70/549] loss: 0.0002\n",
      "[  0m 55s] Epoch-6 [80/549] loss: 0.0002\n",
      "[  0m 55s] Epoch-6 [90/549] loss: 0.0002\n",
      "[  0m 55s] Epoch-6 [100/549] loss: 0.0002\n",
      "[  0m 55s] Epoch-6 [110/549] loss: 0.0002\n",
      "[  0m 55s] Epoch-6 [120/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [130/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [140/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [150/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [160/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [170/549] loss: 0.0002\n",
      "[  0m 56s] Epoch-6 [180/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [190/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [200/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [210/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [220/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [230/549] loss: 0.0002\n",
      "[  0m 57s] Epoch-6 [240/549] loss: 0.0002\n",
      "[  0m 58s] Epoch-6 [250/549] loss: 0.0002\n",
      "[  0m 58s] Epoch-6 [260/549] loss: 0.0002\n",
      "[  0m 58s] Epoch-6 [270/549] loss: 0.0002\n",
      "[  0m 58s] Epoch-6 [280/549] loss: 0.0002\n",
      "[  0m 58s] Epoch-6 [290/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [300/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [310/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [320/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [330/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [340/549] loss: 0.0002\n",
      "[  0m 59s] Epoch-6 [350/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [360/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [370/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [380/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [390/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [400/549] loss: 0.0002\n",
      "[  1m  0s] Epoch-6 [410/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [420/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [430/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [440/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [450/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [460/549] loss: 0.0002\n",
      "[  1m  1s] Epoch-6 [470/549] loss: 0.0002\n",
      "[  1m  2s] Epoch-6 [480/549] loss: 0.0002\n",
      "[  1m  2s] Epoch-6 [490/549] loss: 0.0002\n",
      "[  1m  2s] Epoch-6 [500/549] loss: 0.0002\n",
      "[  1m  2s] Epoch-6 [510/549] loss: 0.0002\n",
      "[  1m  2s] Epoch-6 [520/549] loss: 0.0002\n",
      "[  1m  3s] Epoch-6 [530/549] loss: 0.0002\n",
      "[  1m  3s] Epoch-6 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.93%\n",
      "[  1m  4s] Epoch-7 [10/549] loss: 0.0002\n",
      "[  1m  4s] Epoch-7 [20/549] loss: 0.0002\n",
      "[  1m  4s] Epoch-7 [30/549] loss: 0.0002\n",
      "[  1m  4s] Epoch-7 [40/549] loss: 0.0002\n",
      "[  1m  5s] Epoch-7 [50/549] loss: 0.0002\n",
      "[  1m  5s] Epoch-7 [60/549] loss: 0.0002\n",
      "[  1m  5s] Epoch-7 [70/549] loss: 0.0002\n",
      "[  1m  5s] Epoch-7 [80/549] loss: 0.0002\n",
      "[  1m  5s] Epoch-7 [90/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [100/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [110/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [120/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [130/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [140/549] loss: 0.0002\n",
      "[  1m  6s] Epoch-7 [150/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [160/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [170/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [180/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [190/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [200/549] loss: 0.0002\n",
      "[  1m  7s] Epoch-7 [210/549] loss: 0.0002\n",
      "[  1m  8s] Epoch-7 [220/549] loss: 0.0002\n",
      "[  1m  8s] Epoch-7 [230/549] loss: 0.0002\n",
      "[  1m  8s] Epoch-7 [240/549] loss: 0.0002\n",
      "[  1m  8s] Epoch-7 [250/549] loss: 0.0002\n",
      "[  1m  8s] Epoch-7 [260/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [270/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [280/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [290/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [300/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [310/549] loss: 0.0002\n",
      "[  1m  9s] Epoch-7 [320/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [330/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [340/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [350/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [360/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [370/549] loss: 0.0002\n",
      "[  1m 10s] Epoch-7 [380/549] loss: 0.0002\n",
      "[  1m 11s] Epoch-7 [390/549] loss: 0.0002\n",
      "[  1m 11s] Epoch-7 [400/549] loss: 0.0002\n",
      "[  1m 11s] Epoch-7 [410/549] loss: 0.0002\n",
      "[  1m 11s] Epoch-7 [420/549] loss: 0.0002\n",
      "[  1m 11s] Epoch-7 [430/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [440/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [450/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [460/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [470/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [480/549] loss: 0.0002\n",
      "[  1m 12s] Epoch-7 [490/549] loss: 0.0002\n",
      "[  1m 13s] Epoch-7 [500/549] loss: 0.0002\n",
      "[  1m 13s] Epoch-7 [510/549] loss: 0.0002\n",
      "[  1m 13s] Epoch-7 [520/549] loss: 0.0002\n",
      "[  1m 13s] Epoch-7 [530/549] loss: 0.0002\n",
      "[  1m 13s] Epoch-7 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.23%\n",
      "[  1m 15s] Epoch-8 [10/549] loss: 0.0002\n",
      "[  1m 15s] Epoch-8 [20/549] loss: 0.0002\n",
      "[  1m 15s] Epoch-8 [30/549] loss: 0.0002\n",
      "[  1m 15s] Epoch-8 [40/549] loss: 0.0002\n",
      "[  1m 15s] Epoch-8 [50/549] loss: 0.0002\n",
      "[  1m 15s] Epoch-8 [60/549] loss: 0.0002\n",
      "[  1m 16s] Epoch-8 [70/549] loss: 0.0002\n",
      "[  1m 16s] Epoch-8 [80/549] loss: 0.0001\n",
      "[  1m 16s] Epoch-8 [90/549] loss: 0.0001\n",
      "[  1m 16s] Epoch-8 [100/549] loss: 0.0001\n",
      "[  1m 16s] Epoch-8 [110/549] loss: 0.0001\n",
      "[  1m 16s] Epoch-8 [120/549] loss: 0.0001\n",
      "[  1m 17s] Epoch-8 [130/549] loss: 0.0001\n",
      "[  1m 17s] Epoch-8 [140/549] loss: 0.0001\n",
      "[  1m 17s] Epoch-8 [150/549] loss: 0.0001\n",
      "[  1m 17s] Epoch-8 [160/549] loss: 0.0001\n",
      "[  1m 17s] Epoch-8 [170/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [180/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [190/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [200/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [210/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [220/549] loss: 0.0001\n",
      "[  1m 18s] Epoch-8 [230/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [240/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [250/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [260/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [270/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [280/549] loss: 0.0001\n",
      "[  1m 19s] Epoch-8 [290/549] loss: 0.0001\n",
      "[  1m 20s] Epoch-8 [300/549] loss: 0.0001\n",
      "[  1m 20s] Epoch-8 [310/549] loss: 0.0001\n",
      "[  1m 20s] Epoch-8 [320/549] loss: 0.0001\n",
      "[  1m 20s] Epoch-8 [330/549] loss: 0.0001\n",
      "[  1m 20s] Epoch-8 [340/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [350/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [360/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [370/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [380/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [390/549] loss: 0.0001\n",
      "[  1m 21s] Epoch-8 [400/549] loss: 0.0001\n",
      "[  1m 22s] Epoch-8 [410/549] loss: 0.0002\n",
      "[  1m 22s] Epoch-8 [420/549] loss: 0.0002\n",
      "[  1m 22s] Epoch-8 [430/549] loss: 0.0002\n",
      "[  1m 22s] Epoch-8 [440/549] loss: 0.0002\n",
      "[  1m 22s] Epoch-8 [450/549] loss: 0.0002\n",
      "[  1m 22s] Epoch-8 [460/549] loss: 0.0002\n",
      "[  1m 23s] Epoch-8 [470/549] loss: 0.0002\n",
      "[  1m 23s] Epoch-8 [480/549] loss: 0.0002\n",
      "[  1m 23s] Epoch-8 [490/549] loss: 0.0002\n",
      "[  1m 23s] Epoch-8 [500/549] loss: 0.0002\n",
      "[  1m 23s] Epoch-8 [510/549] loss: 0.0002\n",
      "[  1m 24s] Epoch-8 [520/549] loss: 0.0002\n",
      "[  1m 24s] Epoch-8 [530/549] loss: 0.0002\n",
      "[  1m 24s] Epoch-8 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.12%\n",
      "[  1m 25s] Epoch-9 [10/549] loss: 0.0001\n",
      "[  1m 25s] Epoch-9 [20/549] loss: 0.0001\n",
      "[  1m 25s] Epoch-9 [30/549] loss: 0.0001\n",
      "[  1m 26s] Epoch-9 [40/549] loss: 0.0001\n",
      "[  1m 26s] Epoch-9 [50/549] loss: 0.0001\n",
      "[  1m 26s] Epoch-9 [60/549] loss: 0.0001\n",
      "[  1m 26s] Epoch-9 [70/549] loss: 0.0001\n",
      "[  1m 26s] Epoch-9 [80/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [90/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [100/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [110/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [120/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [130/549] loss: 0.0001\n",
      "[  1m 27s] Epoch-9 [140/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [150/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [160/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [170/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [180/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [190/549] loss: 0.0001\n",
      "[  1m 28s] Epoch-9 [200/549] loss: 0.0001\n",
      "[  1m 29s] Epoch-9 [210/549] loss: 0.0001\n",
      "[  1m 29s] Epoch-9 [220/549] loss: 0.0001\n",
      "[  1m 29s] Epoch-9 [230/549] loss: 0.0001\n",
      "[  1m 29s] Epoch-9 [240/549] loss: 0.0001\n",
      "[  1m 29s] Epoch-9 [250/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [260/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [270/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [280/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [290/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [300/549] loss: 0.0001\n",
      "[  1m 30s] Epoch-9 [310/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [320/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [330/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [340/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [350/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [360/549] loss: 0.0001\n",
      "[  1m 31s] Epoch-9 [370/549] loss: 0.0001\n",
      "[  1m 32s] Epoch-9 [380/549] loss: 0.0001\n",
      "[  1m 32s] Epoch-9 [390/549] loss: 0.0001\n",
      "[  1m 32s] Epoch-9 [400/549] loss: 0.0001\n",
      "[  1m 32s] Epoch-9 [410/549] loss: 0.0001\n",
      "[  1m 32s] Epoch-9 [420/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [430/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [440/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [450/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [460/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [470/549] loss: 0.0001\n",
      "[  1m 33s] Epoch-9 [480/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [490/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [500/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [510/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [520/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [530/549] loss: 0.0001\n",
      "[  1m 34s] Epoch-9 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.98%\n",
      "[  1m 36s] Epoch-10 [10/549] loss: 0.0001\n",
      "[  1m 36s] Epoch-10 [20/549] loss: 0.0001\n",
      "[  1m 36s] Epoch-10 [30/549] loss: 0.0001\n",
      "[  1m 36s] Epoch-10 [40/549] loss: 0.0001\n",
      "[  1m 36s] Epoch-10 [50/549] loss: 0.0001\n",
      "[  1m 37s] Epoch-10 [60/549] loss: 0.0001\n",
      "[  1m 37s] Epoch-10 [70/549] loss: 0.0001\n",
      "[  1m 37s] Epoch-10 [80/549] loss: 0.0001\n",
      "[  1m 37s] Epoch-10 [90/549] loss: 0.0001\n",
      "[  1m 37s] Epoch-10 [100/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [110/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [120/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [130/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [140/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [150/549] loss: 0.0001\n",
      "[  1m 38s] Epoch-10 [160/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [170/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [180/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [190/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [200/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [210/549] loss: 0.0001\n",
      "[  1m 39s] Epoch-10 [220/549] loss: 0.0001\n",
      "[  1m 40s] Epoch-10 [230/549] loss: 0.0001\n",
      "[  1m 40s] Epoch-10 [240/549] loss: 0.0001\n",
      "[  1m 40s] Epoch-10 [250/549] loss: 0.0001\n",
      "[  1m 40s] Epoch-10 [260/549] loss: 0.0001\n",
      "[  1m 40s] Epoch-10 [270/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [280/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [290/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [300/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [310/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [320/549] loss: 0.0001\n",
      "[  1m 41s] Epoch-10 [330/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [340/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [350/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [360/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [370/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [380/549] loss: 0.0001\n",
      "[  1m 42s] Epoch-10 [390/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [400/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [410/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [420/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [430/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [440/549] loss: 0.0001\n",
      "[  1m 43s] Epoch-10 [450/549] loss: 0.0001\n",
      "[  1m 44s] Epoch-10 [460/549] loss: 0.0001\n",
      "[  1m 44s] Epoch-10 [470/549] loss: 0.0001\n",
      "[  1m 44s] Epoch-10 [480/549] loss: 0.0001\n",
      "[  1m 44s] Epoch-10 [490/549] loss: 0.0001\n",
      "[  1m 44s] Epoch-10 [500/549] loss: 0.0001\n",
      "[  1m 45s] Epoch-10 [510/549] loss: 0.0001\n",
      "[  1m 45s] Epoch-10 [520/549] loss: 0.0001\n",
      "[  1m 45s] Epoch-10 [530/549] loss: 0.0001\n",
      "[  1m 45s] Epoch-10 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.15%\n",
      "[  1m 46s] Epoch-11 [10/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [20/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [30/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [40/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [50/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [60/549] loss: 0.0001\n",
      "[  1m 47s] Epoch-11 [70/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [80/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [90/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [100/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [110/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [120/549] loss: 0.0001\n",
      "[  1m 48s] Epoch-11 [130/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [140/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [150/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [160/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [170/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [180/549] loss: 0.0001\n",
      "[  1m 49s] Epoch-11 [190/549] loss: 0.0001\n",
      "[  1m 50s] Epoch-11 [200/549] loss: 0.0001\n",
      "[  1m 50s] Epoch-11 [210/549] loss: 0.0001\n",
      "[  1m 50s] Epoch-11 [220/549] loss: 0.0001\n",
      "[  1m 50s] Epoch-11 [230/549] loss: 0.0001\n",
      "[  1m 50s] Epoch-11 [240/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [250/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [260/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [270/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [280/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [290/549] loss: 0.0001\n",
      "[  1m 51s] Epoch-11 [300/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [310/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [320/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [330/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [340/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [350/549] loss: 0.0001\n",
      "[  1m 52s] Epoch-11 [360/549] loss: 0.0001\n",
      "[  1m 53s] Epoch-11 [370/549] loss: 0.0001\n",
      "[  1m 53s] Epoch-11 [380/549] loss: 0.0001\n",
      "[  1m 53s] Epoch-11 [390/549] loss: 0.0001\n",
      "[  1m 53s] Epoch-11 [400/549] loss: 0.0001\n",
      "[  1m 53s] Epoch-11 [410/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [420/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [430/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [440/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [450/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [460/549] loss: 0.0001\n",
      "[  1m 54s] Epoch-11 [470/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [480/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [490/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [500/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [510/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [520/549] loss: 0.0001\n",
      "[  1m 55s] Epoch-11 [530/549] loss: 0.0001\n",
      "[  1m 56s] Epoch-11 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.81%\n",
      "[  1m 57s] Epoch-12 [10/549] loss: 0.0001\n",
      "[  1m 57s] Epoch-12 [20/549] loss: 0.0001\n",
      "[  1m 57s] Epoch-12 [30/549] loss: 0.0001\n",
      "[  1m 57s] Epoch-12 [40/549] loss: 0.0001\n",
      "[  1m 58s] Epoch-12 [50/549] loss: 0.0001\n",
      "[  1m 58s] Epoch-12 [60/549] loss: 0.0001\n",
      "[  1m 58s] Epoch-12 [70/549] loss: 0.0001\n",
      "[  1m 58s] Epoch-12 [80/549] loss: 0.0001\n",
      "[  1m 58s] Epoch-12 [90/549] loss: 0.0001\n",
      "[  1m 59s] Epoch-12 [100/549] loss: 0.0001\n",
      "[  1m 59s] Epoch-12 [110/549] loss: 0.0001\n",
      "[  1m 59s] Epoch-12 [120/549] loss: 0.0001\n",
      "[  1m 59s] Epoch-12 [130/549] loss: 0.0001\n",
      "[  1m 59s] Epoch-12 [140/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [150/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [160/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [170/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [180/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [190/549] loss: 0.0001\n",
      "[  2m  0s] Epoch-12 [200/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [210/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [220/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [230/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [240/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [250/549] loss: 0.0001\n",
      "[  2m  1s] Epoch-12 [260/549] loss: 0.0001\n",
      "[  2m  2s] Epoch-12 [270/549] loss: 0.0001\n",
      "[  2m  2s] Epoch-12 [280/549] loss: 0.0001\n",
      "[  2m  2s] Epoch-12 [290/549] loss: 0.0001\n",
      "[  2m  2s] Epoch-12 [300/549] loss: 0.0001\n",
      "[  2m  2s] Epoch-12 [310/549] loss: 0.0001\n",
      "[  2m  3s] Epoch-12 [320/549] loss: 0.0001\n",
      "[  2m  3s] Epoch-12 [330/549] loss: 0.0001\n",
      "[  2m  3s] Epoch-12 [340/549] loss: 0.0001\n",
      "[  2m  3s] Epoch-12 [350/549] loss: 0.0001\n",
      "[  2m  3s] Epoch-12 [360/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [370/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [380/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [390/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [400/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [410/549] loss: 0.0001\n",
      "[  2m  4s] Epoch-12 [420/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [430/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [440/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [450/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [460/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [470/549] loss: 0.0001\n",
      "[  2m  5s] Epoch-12 [480/549] loss: 0.0001\n",
      "[  2m  6s] Epoch-12 [490/549] loss: 0.0001\n",
      "[  2m  6s] Epoch-12 [500/549] loss: 0.0001\n",
      "[  2m  6s] Epoch-12 [510/549] loss: 0.0001\n",
      "[  2m  6s] Epoch-12 [520/549] loss: 0.0001\n",
      "[  2m  6s] Epoch-12 [530/549] loss: 0.0001\n",
      "[  2m  7s] Epoch-12 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.13%\n",
      "[  2m  8s] Epoch-13 [10/549] loss: 0.0001\n",
      "[  2m  8s] Epoch-13 [20/549] loss: 0.0001\n",
      "[  2m  8s] Epoch-13 [30/549] loss: 0.0001\n",
      "[  2m  8s] Epoch-13 [40/549] loss: 0.0001\n",
      "[  2m  8s] Epoch-13 [50/549] loss: 0.0001\n",
      "[  2m  9s] Epoch-13 [60/549] loss: 0.0001\n",
      "[  2m  9s] Epoch-13 [70/549] loss: 0.0001\n",
      "[  2m  9s] Epoch-13 [80/549] loss: 0.0001\n",
      "[  2m  9s] Epoch-13 [90/549] loss: 0.0001\n",
      "[  2m  9s] Epoch-13 [100/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [110/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [120/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [130/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [140/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [150/549] loss: 0.0001\n",
      "[  2m 10s] Epoch-13 [160/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [170/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [180/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [190/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [200/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [210/549] loss: 0.0001\n",
      "[  2m 11s] Epoch-13 [220/549] loss: 0.0001\n",
      "[  2m 12s] Epoch-13 [230/549] loss: 0.0001\n",
      "[  2m 12s] Epoch-13 [240/549] loss: 0.0001\n",
      "[  2m 12s] Epoch-13 [250/549] loss: 0.0001\n",
      "[  2m 12s] Epoch-13 [260/549] loss: 0.0001\n",
      "[  2m 12s] Epoch-13 [270/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [280/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [290/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [300/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [310/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [320/549] loss: 0.0001\n",
      "[  2m 13s] Epoch-13 [330/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [340/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [350/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [360/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [370/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [380/549] loss: 0.0001\n",
      "[  2m 14s] Epoch-13 [390/549] loss: 0.0001\n",
      "[  2m 15s] Epoch-13 [400/549] loss: 0.0001\n",
      "[  2m 15s] Epoch-13 [410/549] loss: 0.0001\n",
      "[  2m 15s] Epoch-13 [420/549] loss: 0.0001\n",
      "[  2m 15s] Epoch-13 [430/549] loss: 0.0001\n",
      "[  2m 15s] Epoch-13 [440/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [450/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [460/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [470/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [480/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [490/549] loss: 0.0001\n",
      "[  2m 16s] Epoch-13 [500/549] loss: 0.0001\n",
      "[  2m 17s] Epoch-13 [510/549] loss: 0.0001\n",
      "[  2m 17s] Epoch-13 [520/549] loss: 0.0001\n",
      "[  2m 17s] Epoch-13 [530/549] loss: 0.0001\n",
      "[  2m 17s] Epoch-13 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.12%\n",
      "[  2m 18s] Epoch-14 [10/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [20/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [30/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [40/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [50/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [60/549] loss: 0.0001\n",
      "[  2m 19s] Epoch-14 [70/549] loss: 0.0001\n",
      "[  2m 20s] Epoch-14 [80/549] loss: 0.0001\n",
      "[  2m 20s] Epoch-14 [90/549] loss: 0.0001\n",
      "[  2m 20s] Epoch-14 [100/549] loss: 0.0001\n",
      "[  2m 20s] Epoch-14 [110/549] loss: 0.0001\n",
      "[  2m 20s] Epoch-14 [120/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [130/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [140/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [150/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [160/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [170/549] loss: 0.0001\n",
      "[  2m 21s] Epoch-14 [180/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [190/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [200/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [210/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [220/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [230/549] loss: 0.0001\n",
      "[  2m 22s] Epoch-14 [240/549] loss: 0.0001\n",
      "[  2m 23s] Epoch-14 [250/549] loss: 0.0001\n",
      "[  2m 23s] Epoch-14 [260/549] loss: 0.0001\n",
      "[  2m 23s] Epoch-14 [270/549] loss: 0.0001\n",
      "[  2m 23s] Epoch-14 [280/549] loss: 0.0001\n",
      "[  2m 23s] Epoch-14 [290/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [300/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [310/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [320/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [330/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [340/549] loss: 0.0001\n",
      "[  2m 24s] Epoch-14 [350/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [360/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [370/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [380/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [390/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [400/549] loss: 0.0001\n",
      "[  2m 25s] Epoch-14 [410/549] loss: 0.0001\n",
      "[  2m 26s] Epoch-14 [420/549] loss: 0.0001\n",
      "[  2m 26s] Epoch-14 [430/549] loss: 0.0001\n",
      "[  2m 26s] Epoch-14 [440/549] loss: 0.0001\n",
      "[  2m 26s] Epoch-14 [450/549] loss: 0.0001\n",
      "[  2m 26s] Epoch-14 [460/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [470/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [480/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [490/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [500/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [510/549] loss: 0.0001\n",
      "[  2m 27s] Epoch-14 [520/549] loss: 0.0001\n",
      "[  2m 28s] Epoch-14 [530/549] loss: 0.0001\n",
      "[  2m 28s] Epoch-14 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.44%\n",
      "[  2m 29s] Epoch-15 [10/549] loss: 0.0000\n",
      "[  2m 29s] Epoch-15 [20/549] loss: 0.0000\n",
      "[  2m 29s] Epoch-15 [30/549] loss: 0.0000\n",
      "[  2m 30s] Epoch-15 [40/549] loss: 0.0000\n",
      "[  2m 30s] Epoch-15 [50/549] loss: 0.0000\n",
      "[  2m 30s] Epoch-15 [60/549] loss: 0.0000\n",
      "[  2m 30s] Epoch-15 [70/549] loss: 0.0000\n",
      "[  2m 30s] Epoch-15 [80/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [90/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [100/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [110/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [120/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [130/549] loss: 0.0000\n",
      "[  2m 31s] Epoch-15 [140/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [150/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [160/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [170/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [180/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [190/549] loss: 0.0000\n",
      "[  2m 32s] Epoch-15 [200/549] loss: 0.0000\n",
      "[  2m 33s] Epoch-15 [210/549] loss: 0.0000\n",
      "[  2m 33s] Epoch-15 [220/549] loss: 0.0000\n",
      "[  2m 33s] Epoch-15 [230/549] loss: 0.0000\n",
      "[  2m 33s] Epoch-15 [240/549] loss: 0.0000\n",
      "[  2m 33s] Epoch-15 [250/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [260/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [270/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [280/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [290/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [300/549] loss: 0.0000\n",
      "[  2m 34s] Epoch-15 [310/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [320/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [330/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [340/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [350/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [360/549] loss: 0.0000\n",
      "[  2m 35s] Epoch-15 [370/549] loss: 0.0000\n",
      "[  2m 36s] Epoch-15 [380/549] loss: 0.0000\n",
      "[  2m 36s] Epoch-15 [390/549] loss: 0.0000\n",
      "[  2m 36s] Epoch-15 [400/549] loss: 0.0000\n",
      "[  2m 36s] Epoch-15 [410/549] loss: 0.0000\n",
      "[  2m 36s] Epoch-15 [420/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [430/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [440/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [450/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [460/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [470/549] loss: 0.0000\n",
      "[  2m 37s] Epoch-15 [480/549] loss: 0.0000\n",
      "[  2m 38s] Epoch-15 [490/549] loss: 0.0000\n",
      "[  2m 38s] Epoch-15 [500/549] loss: 0.0000\n",
      "[  2m 38s] Epoch-15 [510/549] loss: 0.0000\n",
      "[  2m 38s] Epoch-15 [520/549] loss: 0.0001\n",
      "[  2m 38s] Epoch-15 [530/549] loss: 0.0001\n",
      "[  2m 38s] Epoch-15 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.22%\n",
      "[  2m 40s] Epoch-16 [10/549] loss: 0.0000\n",
      "[  2m 40s] Epoch-16 [20/549] loss: 0.0000\n",
      "[  2m 40s] Epoch-16 [30/549] loss: 0.0000\n",
      "[  2m 40s] Epoch-16 [40/549] loss: 0.0000\n",
      "[  2m 41s] Epoch-16 [50/549] loss: 0.0000\n",
      "[  2m 41s] Epoch-16 [60/549] loss: 0.0001\n",
      "[  2m 41s] Epoch-16 [70/549] loss: 0.0001\n",
      "[  2m 41s] Epoch-16 [80/549] loss: 0.0001\n",
      "[  2m 41s] Epoch-16 [90/549] loss: 0.0001\n",
      "[  2m 41s] Epoch-16 [100/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [110/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [120/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [130/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [140/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [150/549] loss: 0.0001\n",
      "[  2m 42s] Epoch-16 [160/549] loss: 0.0001\n",
      "[  2m 43s] Epoch-16 [170/549] loss: 0.0001\n",
      "[  2m 43s] Epoch-16 [180/549] loss: 0.0001\n",
      "[  2m 43s] Epoch-16 [190/549] loss: 0.0001\n",
      "[  2m 43s] Epoch-16 [200/549] loss: 0.0001\n",
      "[  2m 43s] Epoch-16 [210/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [220/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [230/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [240/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [250/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [260/549] loss: 0.0001\n",
      "[  2m 44s] Epoch-16 [270/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [280/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [290/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [300/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [310/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [320/549] loss: 0.0001\n",
      "[  2m 45s] Epoch-16 [330/549] loss: 0.0001\n",
      "[  2m 46s] Epoch-16 [340/549] loss: 0.0001\n",
      "[  2m 46s] Epoch-16 [350/549] loss: 0.0001\n",
      "[  2m 46s] Epoch-16 [360/549] loss: 0.0001\n",
      "[  2m 46s] Epoch-16 [370/549] loss: 0.0001\n",
      "[  2m 46s] Epoch-16 [380/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [390/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [400/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [410/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [420/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [430/549] loss: 0.0001\n",
      "[  2m 47s] Epoch-16 [440/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [450/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [460/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [470/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [480/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [490/549] loss: 0.0001\n",
      "[  2m 48s] Epoch-16 [500/549] loss: 0.0001\n",
      "[  2m 49s] Epoch-16 [510/549] loss: 0.0001\n",
      "[  2m 49s] Epoch-16 [520/549] loss: 0.0001\n",
      "[  2m 49s] Epoch-16 [530/549] loss: 0.0001\n",
      "[  2m 49s] Epoch-16 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.05%\n",
      "[  2m 51s] Epoch-17 [10/549] loss: 0.0001\n",
      "[  2m 51s] Epoch-17 [20/549] loss: 0.0001\n",
      "[  2m 51s] Epoch-17 [30/549] loss: 0.0002\n",
      "[  2m 51s] Epoch-17 [40/549] loss: 0.0002\n",
      "[  2m 51s] Epoch-17 [50/549] loss: 0.0001\n",
      "[  2m 51s] Epoch-17 [60/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [70/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [80/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [90/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [100/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [110/549] loss: 0.0001\n",
      "[  2m 52s] Epoch-17 [120/549] loss: 0.0001\n",
      "[  2m 53s] Epoch-17 [130/549] loss: 0.0001\n",
      "[  2m 53s] Epoch-17 [140/549] loss: 0.0001\n",
      "[  2m 53s] Epoch-17 [150/549] loss: 0.0001\n",
      "[  2m 53s] Epoch-17 [160/549] loss: 0.0001\n",
      "[  2m 53s] Epoch-17 [170/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [180/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [190/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [200/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [210/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [220/549] loss: 0.0001\n",
      "[  2m 54s] Epoch-17 [230/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [240/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [250/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [260/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [270/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [280/549] loss: 0.0001\n",
      "[  2m 55s] Epoch-17 [290/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [300/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [310/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [320/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [330/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [340/549] loss: 0.0001\n",
      "[  2m 56s] Epoch-17 [350/549] loss: 0.0001\n",
      "[  2m 57s] Epoch-17 [360/549] loss: 0.0001\n",
      "[  2m 57s] Epoch-17 [370/549] loss: 0.0001\n",
      "[  2m 57s] Epoch-17 [380/549] loss: 0.0001\n",
      "[  2m 57s] Epoch-17 [390/549] loss: 0.0001\n",
      "[  2m 57s] Epoch-17 [400/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [410/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [420/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [430/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [440/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [450/549] loss: 0.0001\n",
      "[  2m 58s] Epoch-17 [460/549] loss: 0.0001\n",
      "[  2m 59s] Epoch-17 [470/549] loss: 0.0001\n",
      "[  2m 59s] Epoch-17 [480/549] loss: 0.0001\n",
      "[  2m 59s] Epoch-17 [490/549] loss: 0.0001\n",
      "[  2m 59s] Epoch-17 [500/549] loss: 0.0001\n",
      "[  2m 59s] Epoch-17 [510/549] loss: 0.0001\n",
      "[  3m  0s] Epoch-17 [520/549] loss: 0.0001\n",
      "[  3m  0s] Epoch-17 [530/549] loss: 0.0001\n",
      "[  3m  0s] Epoch-17 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.36%\n",
      "[  3m  1s] Epoch-18 [10/549] loss: 0.0000\n",
      "[  3m  1s] Epoch-18 [20/549] loss: 0.0000\n",
      "[  3m  2s] Epoch-18 [30/549] loss: 0.0001\n",
      "[  3m  2s] Epoch-18 [40/549] loss: 0.0001\n",
      "[  3m  2s] Epoch-18 [50/549] loss: 0.0001\n",
      "[  3m  2s] Epoch-18 [60/549] loss: 0.0001\n",
      "[  3m  2s] Epoch-18 [70/549] loss: 0.0001\n",
      "[  3m  2s] Epoch-18 [80/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [90/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [100/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [110/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [120/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [130/549] loss: 0.0000\n",
      "[  3m  3s] Epoch-18 [140/549] loss: 0.0000\n",
      "[  3m  4s] Epoch-18 [150/549] loss: 0.0000\n",
      "[  3m  4s] Epoch-18 [160/549] loss: 0.0000\n",
      "[  3m  4s] Epoch-18 [170/549] loss: 0.0000\n",
      "[  3m  4s] Epoch-18 [180/549] loss: 0.0000\n",
      "[  3m  4s] Epoch-18 [190/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [200/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [210/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [220/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [230/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [240/549] loss: 0.0000\n",
      "[  3m  5s] Epoch-18 [250/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [260/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [270/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [280/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [290/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [300/549] loss: 0.0000\n",
      "[  3m  6s] Epoch-18 [310/549] loss: 0.0000\n",
      "[  3m  7s] Epoch-18 [320/549] loss: 0.0000\n",
      "[  3m  7s] Epoch-18 [330/549] loss: 0.0000\n",
      "[  3m  7s] Epoch-18 [340/549] loss: 0.0000\n",
      "[  3m  7s] Epoch-18 [350/549] loss: 0.0000\n",
      "[  3m  7s] Epoch-18 [360/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [370/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [380/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [390/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [400/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [410/549] loss: 0.0000\n",
      "[  3m  8s] Epoch-18 [420/549] loss: 0.0000\n",
      "[  3m  9s] Epoch-18 [430/549] loss: 0.0000\n",
      "[  3m  9s] Epoch-18 [440/549] loss: 0.0000\n",
      "[  3m  9s] Epoch-18 [450/549] loss: 0.0000\n",
      "[  3m  9s] Epoch-18 [460/549] loss: 0.0000\n",
      "[  3m  9s] Epoch-18 [470/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [480/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [490/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [500/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [510/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [520/549] loss: 0.0000\n",
      "[  3m 10s] Epoch-18 [530/549] loss: 0.0000\n",
      "[  3m 11s] Epoch-18 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.57%\n",
      "[  3m 12s] Epoch-19 [10/549] loss: 0.0000\n",
      "[  3m 12s] Epoch-19 [20/549] loss: 0.0000\n",
      "[  3m 12s] Epoch-19 [30/549] loss: 0.0000\n",
      "[  3m 12s] Epoch-19 [40/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [50/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [60/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [70/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [80/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [90/549] loss: 0.0000\n",
      "[  3m 13s] Epoch-19 [100/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [110/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [120/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [130/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [140/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [150/549] loss: 0.0000\n",
      "[  3m 14s] Epoch-19 [160/549] loss: 0.0000\n",
      "[  3m 15s] Epoch-19 [170/549] loss: 0.0000\n",
      "[  3m 15s] Epoch-19 [180/549] loss: 0.0000\n",
      "[  3m 15s] Epoch-19 [190/549] loss: 0.0000\n",
      "[  3m 15s] Epoch-19 [200/549] loss: 0.0000\n",
      "[  3m 15s] Epoch-19 [210/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [220/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [230/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [240/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [250/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [260/549] loss: 0.0000\n",
      "[  3m 16s] Epoch-19 [270/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [280/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [290/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [300/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [310/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [320/549] loss: 0.0000\n",
      "[  3m 17s] Epoch-19 [330/549] loss: 0.0000\n",
      "[  3m 18s] Epoch-19 [340/549] loss: 0.0000\n",
      "[  3m 18s] Epoch-19 [350/549] loss: 0.0000\n",
      "[  3m 18s] Epoch-19 [360/549] loss: 0.0000\n",
      "[  3m 18s] Epoch-19 [370/549] loss: 0.0000\n",
      "[  3m 18s] Epoch-19 [380/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [390/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [400/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [410/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [420/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [430/549] loss: 0.0000\n",
      "[  3m 19s] Epoch-19 [440/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [450/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [460/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [470/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [480/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [490/549] loss: 0.0000\n",
      "[  3m 20s] Epoch-19 [500/549] loss: 0.0000\n",
      "[  3m 21s] Epoch-19 [510/549] loss: 0.0000\n",
      "[  3m 21s] Epoch-19 [520/549] loss: 0.0000\n",
      "[  3m 21s] Epoch-19 [530/549] loss: 0.0000\n",
      "[  3m 21s] Epoch-19 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.64%\n",
      "[  3m 22s] Epoch-20 [10/549] loss: 0.0000\n",
      "[  3m 23s] Epoch-20 [20/549] loss: 0.0000\n",
      "[  3m 23s] Epoch-20 [30/549] loss: 0.0000\n",
      "[  3m 23s] Epoch-20 [40/549] loss: 0.0000\n",
      "[  3m 23s] Epoch-20 [50/549] loss: 0.0000\n",
      "[  3m 23s] Epoch-20 [60/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [70/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [80/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [90/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [100/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [110/549] loss: 0.0000\n",
      "[  3m 24s] Epoch-20 [120/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [130/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [140/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [150/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [160/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [170/549] loss: 0.0000\n",
      "[  3m 25s] Epoch-20 [180/549] loss: 0.0000\n",
      "[  3m 26s] Epoch-20 [190/549] loss: 0.0000\n",
      "[  3m 26s] Epoch-20 [200/549] loss: 0.0000\n",
      "[  3m 26s] Epoch-20 [210/549] loss: 0.0000\n",
      "[  3m 26s] Epoch-20 [220/549] loss: 0.0000\n",
      "[  3m 26s] Epoch-20 [230/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [240/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [250/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [260/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [270/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [280/549] loss: 0.0000\n",
      "[  3m 27s] Epoch-20 [290/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [300/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [310/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [320/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [330/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [340/549] loss: 0.0000\n",
      "[  3m 28s] Epoch-20 [350/549] loss: 0.0000\n",
      "[  3m 29s] Epoch-20 [360/549] loss: 0.0000\n",
      "[  3m 29s] Epoch-20 [370/549] loss: 0.0000\n",
      "[  3m 29s] Epoch-20 [380/549] loss: 0.0000\n",
      "[  3m 29s] Epoch-20 [390/549] loss: 0.0000\n",
      "[  3m 29s] Epoch-20 [400/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [410/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [420/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [430/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [440/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [450/549] loss: 0.0000\n",
      "[  3m 30s] Epoch-20 [460/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [470/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [480/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [490/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [500/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [510/549] loss: 0.0000\n",
      "[  3m 31s] Epoch-20 [520/549] loss: 0.0000\n",
      "[  3m 32s] Epoch-20 [530/549] loss: 0.0000\n",
      "[  3m 32s] Epoch-20 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.07%\n",
      "[  3m 33s] Epoch-21 [10/549] loss: 0.0001\n",
      "[  3m 33s] Epoch-21 [20/549] loss: 0.0001\n",
      "[  3m 33s] Epoch-21 [30/549] loss: 0.0001\n",
      "[  3m 34s] Epoch-21 [40/549] loss: 0.0001\n",
      "[  3m 34s] Epoch-21 [50/549] loss: 0.0001\n",
      "[  3m 34s] Epoch-21 [60/549] loss: 0.0001\n",
      "[  3m 34s] Epoch-21 [70/549] loss: 0.0001\n",
      "[  3m 34s] Epoch-21 [80/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [90/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [100/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [110/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [120/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [130/549] loss: 0.0001\n",
      "[  3m 35s] Epoch-21 [140/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [150/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [160/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [170/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [180/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [190/549] loss: 0.0001\n",
      "[  3m 36s] Epoch-21 [200/549] loss: 0.0001\n",
      "[  3m 37s] Epoch-21 [210/549] loss: 0.0001\n",
      "[  3m 37s] Epoch-21 [220/549] loss: 0.0001\n",
      "[  3m 37s] Epoch-21 [230/549] loss: 0.0001\n",
      "[  3m 37s] Epoch-21 [240/549] loss: 0.0001\n",
      "[  3m 37s] Epoch-21 [250/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [260/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [270/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [280/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [290/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [300/549] loss: 0.0001\n",
      "[  3m 38s] Epoch-21 [310/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [320/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [330/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [340/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [350/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [360/549] loss: 0.0001\n",
      "[  3m 39s] Epoch-21 [370/549] loss: 0.0001\n",
      "[  3m 40s] Epoch-21 [380/549] loss: 0.0001\n",
      "[  3m 40s] Epoch-21 [390/549] loss: 0.0001\n",
      "[  3m 40s] Epoch-21 [400/549] loss: 0.0001\n",
      "[  3m 40s] Epoch-21 [410/549] loss: 0.0001\n",
      "[  3m 40s] Epoch-21 [420/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [430/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [440/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [450/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [460/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [470/549] loss: 0.0001\n",
      "[  3m 41s] Epoch-21 [480/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [490/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [500/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [510/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [520/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [530/549] loss: 0.0001\n",
      "[  3m 42s] Epoch-21 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.19%\n",
      "[  3m 44s] Epoch-22 [10/549] loss: 0.0001\n",
      "[  3m 44s] Epoch-22 [20/549] loss: 0.0001\n",
      "[  3m 44s] Epoch-22 [30/549] loss: 0.0001\n",
      "[  3m 44s] Epoch-22 [40/549] loss: 0.0001\n",
      "[  3m 44s] Epoch-22 [50/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [60/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [70/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [80/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [90/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [100/549] loss: 0.0001\n",
      "[  3m 45s] Epoch-22 [110/549] loss: 0.0001\n",
      "[  3m 46s] Epoch-22 [120/549] loss: 0.0001\n",
      "[  3m 46s] Epoch-22 [130/549] loss: 0.0001\n",
      "[  3m 46s] Epoch-22 [140/549] loss: 0.0001\n",
      "[  3m 46s] Epoch-22 [150/549] loss: 0.0001\n",
      "[  3m 46s] Epoch-22 [160/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [170/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [180/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [190/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [200/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [210/549] loss: 0.0001\n",
      "[  3m 47s] Epoch-22 [220/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [230/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [240/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [250/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [260/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [270/549] loss: 0.0001\n",
      "[  3m 48s] Epoch-22 [280/549] loss: 0.0001\n",
      "[  3m 49s] Epoch-22 [290/549] loss: 0.0001\n",
      "[  3m 49s] Epoch-22 [300/549] loss: 0.0001\n",
      "[  3m 49s] Epoch-22 [310/549] loss: 0.0001\n",
      "[  3m 49s] Epoch-22 [320/549] loss: 0.0001\n",
      "[  3m 49s] Epoch-22 [330/549] loss: 0.0001\n",
      "[  3m 50s] Epoch-22 [340/549] loss: 0.0001\n",
      "[  3m 50s] Epoch-22 [350/549] loss: 0.0001\n",
      "[  3m 50s] Epoch-22 [360/549] loss: 0.0001\n",
      "[  3m 50s] Epoch-22 [370/549] loss: 0.0001\n",
      "[  3m 50s] Epoch-22 [380/549] loss: 0.0000\n",
      "[  3m 50s] Epoch-22 [390/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [400/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [410/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [420/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [430/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [440/549] loss: 0.0000\n",
      "[  3m 51s] Epoch-22 [450/549] loss: 0.0000\n",
      "[  3m 52s] Epoch-22 [460/549] loss: 0.0000\n",
      "[  3m 52s] Epoch-22 [470/549] loss: 0.0000\n",
      "[  3m 52s] Epoch-22 [480/549] loss: 0.0000\n",
      "[  3m 52s] Epoch-22 [490/549] loss: 0.0000\n",
      "[  3m 52s] Epoch-22 [500/549] loss: 0.0000\n",
      "[  3m 53s] Epoch-22 [510/549] loss: 0.0000\n",
      "[  3m 53s] Epoch-22 [520/549] loss: 0.0000\n",
      "[  3m 53s] Epoch-22 [530/549] loss: 0.0000\n",
      "[  3m 53s] Epoch-22 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.51%\n",
      "[  3m 54s] Epoch-23 [10/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [20/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [30/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [40/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [50/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [60/549] loss: 0.0000\n",
      "[  3m 55s] Epoch-23 [70/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [80/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [90/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [100/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [110/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [120/549] loss: 0.0000\n",
      "[  3m 56s] Epoch-23 [130/549] loss: 0.0000\n",
      "[  3m 57s] Epoch-23 [140/549] loss: 0.0000\n",
      "[  3m 57s] Epoch-23 [150/549] loss: 0.0000\n",
      "[  3m 57s] Epoch-23 [160/549] loss: 0.0000\n",
      "[  3m 57s] Epoch-23 [170/549] loss: 0.0000\n",
      "[  3m 57s] Epoch-23 [180/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [190/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [200/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [210/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [220/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [230/549] loss: 0.0000\n",
      "[  3m 58s] Epoch-23 [240/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [250/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [260/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [270/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [280/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [290/549] loss: 0.0000\n",
      "[  3m 59s] Epoch-23 [300/549] loss: 0.0000\n",
      "[  4m  0s] Epoch-23 [310/549] loss: 0.0000\n",
      "[  4m  0s] Epoch-23 [320/549] loss: 0.0000\n",
      "[  4m  0s] Epoch-23 [330/549] loss: 0.0000\n",
      "[  4m  0s] Epoch-23 [340/549] loss: 0.0000\n",
      "[  4m  0s] Epoch-23 [350/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [360/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [370/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [380/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [390/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [400/549] loss: 0.0000\n",
      "[  4m  1s] Epoch-23 [410/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [420/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [430/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [440/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [450/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [460/549] loss: 0.0000\n",
      "[  4m  2s] Epoch-23 [470/549] loss: 0.0000\n",
      "[  4m  3s] Epoch-23 [480/549] loss: 0.0000\n",
      "[  4m  3s] Epoch-23 [490/549] loss: 0.0000\n",
      "[  4m  3s] Epoch-23 [500/549] loss: 0.0000\n",
      "[  4m  3s] Epoch-23 [510/549] loss: 0.0000\n",
      "[  4m  3s] Epoch-23 [520/549] loss: 0.0000\n",
      "[  4m  4s] Epoch-23 [530/549] loss: 0.0000\n",
      "[  4m  4s] Epoch-23 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.52%\n",
      "[  4m  5s] Epoch-24 [10/549] loss: 0.0000\n",
      "[  4m  5s] Epoch-24 [20/549] loss: 0.0000\n",
      "[  4m  5s] Epoch-24 [30/549] loss: 0.0000\n",
      "[  4m  5s] Epoch-24 [40/549] loss: 0.0000\n",
      "[  4m  6s] Epoch-24 [50/549] loss: 0.0000\n",
      "[  4m  6s] Epoch-24 [60/549] loss: 0.0000\n",
      "[  4m  6s] Epoch-24 [70/549] loss: 0.0000\n",
      "[  4m  6s] Epoch-24 [80/549] loss: 0.0000\n",
      "[  4m  6s] Epoch-24 [90/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [100/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [110/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [120/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [130/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [140/549] loss: 0.0000\n",
      "[  4m  7s] Epoch-24 [150/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [160/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [170/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [180/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [190/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [200/549] loss: 0.0000\n",
      "[  4m  8s] Epoch-24 [210/549] loss: 0.0000\n",
      "[  4m  9s] Epoch-24 [220/549] loss: 0.0000\n",
      "[  4m  9s] Epoch-24 [230/549] loss: 0.0000\n",
      "[  4m  9s] Epoch-24 [240/549] loss: 0.0000\n",
      "[  4m  9s] Epoch-24 [250/549] loss: 0.0000\n",
      "[  4m  9s] Epoch-24 [260/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [270/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [280/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [290/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [300/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [310/549] loss: 0.0000\n",
      "[  4m 10s] Epoch-24 [320/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [330/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [340/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [350/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [360/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [370/549] loss: 0.0000\n",
      "[  4m 11s] Epoch-24 [380/549] loss: 0.0000\n",
      "[  4m 12s] Epoch-24 [390/549] loss: 0.0000\n",
      "[  4m 12s] Epoch-24 [400/549] loss: 0.0000\n",
      "[  4m 12s] Epoch-24 [410/549] loss: 0.0000\n",
      "[  4m 12s] Epoch-24 [420/549] loss: 0.0000\n",
      "[  4m 12s] Epoch-24 [430/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [440/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [450/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [460/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [470/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [480/549] loss: 0.0000\n",
      "[  4m 13s] Epoch-24 [490/549] loss: 0.0000\n",
      "[  4m 14s] Epoch-24 [500/549] loss: 0.0000\n",
      "[  4m 14s] Epoch-24 [510/549] loss: 0.0000\n",
      "[  4m 14s] Epoch-24 [520/549] loss: 0.0000\n",
      "[  4m 14s] Epoch-24 [530/549] loss: 0.0000\n",
      "[  4m 14s] Epoch-24 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.27%\n",
      "[  4m 16s] Epoch-25 [10/549] loss: 0.0001\n",
      "[  4m 16s] Epoch-25 [20/549] loss: 0.0001\n",
      "[  4m 16s] Epoch-25 [30/549] loss: 0.0001\n",
      "[  4m 16s] Epoch-25 [40/549] loss: 0.0001\n",
      "[  4m 16s] Epoch-25 [50/549] loss: 0.0001\n",
      "[  4m 16s] Epoch-25 [60/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [70/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [80/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [90/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [100/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [110/549] loss: 0.0001\n",
      "[  4m 17s] Epoch-25 [120/549] loss: 0.0001\n",
      "[  4m 18s] Epoch-25 [130/549] loss: 0.0001\n",
      "[  4m 18s] Epoch-25 [140/549] loss: 0.0001\n",
      "[  4m 18s] Epoch-25 [150/549] loss: 0.0001\n",
      "[  4m 18s] Epoch-25 [160/549] loss: 0.0001\n",
      "[  4m 18s] Epoch-25 [170/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [180/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [190/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [200/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [210/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [220/549] loss: 0.0001\n",
      "[  4m 19s] Epoch-25 [230/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [240/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [250/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [260/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [270/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [280/549] loss: 0.0001\n",
      "[  4m 20s] Epoch-25 [290/549] loss: 0.0001\n",
      "[  4m 21s] Epoch-25 [300/549] loss: 0.0001\n",
      "[  4m 21s] Epoch-25 [310/549] loss: 0.0001\n",
      "[  4m 21s] Epoch-25 [320/549] loss: 0.0001\n",
      "[  4m 21s] Epoch-25 [330/549] loss: 0.0001\n",
      "[  4m 21s] Epoch-25 [340/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [350/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [360/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [370/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [380/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [390/549] loss: 0.0001\n",
      "[  4m 22s] Epoch-25 [400/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [410/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [420/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [430/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [440/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [450/549] loss: 0.0001\n",
      "[  4m 23s] Epoch-25 [460/549] loss: 0.0001\n",
      "[  4m 24s] Epoch-25 [470/549] loss: 0.0001\n",
      "[  4m 24s] Epoch-25 [480/549] loss: 0.0001\n",
      "[  4m 24s] Epoch-25 [490/549] loss: 0.0001\n",
      "[  4m 24s] Epoch-25 [500/549] loss: 0.0001\n",
      "[  4m 24s] Epoch-25 [510/549] loss: 0.0001\n",
      "[  4m 25s] Epoch-25 [520/549] loss: 0.0001\n",
      "[  4m 25s] Epoch-25 [530/549] loss: 0.0001\n",
      "[  4m 25s] Epoch-25 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.28%\n",
      "[  4m 26s] Epoch-26 [10/549] loss: 0.0001\n",
      "[  4m 26s] Epoch-26 [20/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [30/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [40/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [50/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [60/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [70/549] loss: 0.0001\n",
      "[  4m 27s] Epoch-26 [80/549] loss: 0.0001\n",
      "[  4m 28s] Epoch-26 [90/549] loss: 0.0001\n",
      "[  4m 28s] Epoch-26 [100/549] loss: 0.0001\n",
      "[  4m 28s] Epoch-26 [110/549] loss: 0.0001\n",
      "[  4m 28s] Epoch-26 [120/549] loss: 0.0001\n",
      "[  4m 28s] Epoch-26 [130/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [140/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [150/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [160/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [170/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [180/549] loss: 0.0001\n",
      "[  4m 29s] Epoch-26 [190/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [200/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [210/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [220/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [230/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [240/549] loss: 0.0001\n",
      "[  4m 30s] Epoch-26 [250/549] loss: 0.0001\n",
      "[  4m 31s] Epoch-26 [260/549] loss: 0.0001\n",
      "[  4m 31s] Epoch-26 [270/549] loss: 0.0001\n",
      "[  4m 31s] Epoch-26 [280/549] loss: 0.0001\n",
      "[  4m 31s] Epoch-26 [290/549] loss: 0.0001\n",
      "[  4m 31s] Epoch-26 [300/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [310/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [320/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [330/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [340/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [350/549] loss: 0.0001\n",
      "[  4m 32s] Epoch-26 [360/549] loss: 0.0001\n",
      "[  4m 33s] Epoch-26 [370/549] loss: 0.0001\n",
      "[  4m 33s] Epoch-26 [380/549] loss: 0.0000\n",
      "[  4m 33s] Epoch-26 [390/549] loss: 0.0000\n",
      "[  4m 33s] Epoch-26 [400/549] loss: 0.0000\n",
      "[  4m 33s] Epoch-26 [410/549] loss: 0.0000\n",
      "[  4m 33s] Epoch-26 [420/549] loss: 0.0000\n",
      "[  4m 34s] Epoch-26 [430/549] loss: 0.0000\n",
      "[  4m 34s] Epoch-26 [440/549] loss: 0.0000\n",
      "[  4m 34s] Epoch-26 [450/549] loss: 0.0000\n",
      "[  4m 34s] Epoch-26 [460/549] loss: 0.0000\n",
      "[  4m 34s] Epoch-26 [470/549] loss: 0.0000\n",
      "[  4m 35s] Epoch-26 [480/549] loss: 0.0000\n",
      "[  4m 35s] Epoch-26 [490/549] loss: 0.0000\n",
      "[  4m 35s] Epoch-26 [500/549] loss: 0.0000\n",
      "[  4m 35s] Epoch-26 [510/549] loss: 0.0000\n",
      "[  4m 35s] Epoch-26 [520/549] loss: 0.0001\n",
      "[  4m 35s] Epoch-26 [530/549] loss: 0.0001\n",
      "[  4m 36s] Epoch-26 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.47%\n",
      "[  4m 37s] Epoch-27 [10/549] loss: 0.0000\n",
      "[  4m 37s] Epoch-27 [20/549] loss: 0.0000\n",
      "[  4m 37s] Epoch-27 [30/549] loss: 0.0000\n",
      "[  4m 37s] Epoch-27 [40/549] loss: 0.0000\n",
      "[  4m 38s] Epoch-27 [50/549] loss: 0.0000\n",
      "[  4m 38s] Epoch-27 [60/549] loss: 0.0000\n",
      "[  4m 38s] Epoch-27 [70/549] loss: 0.0000\n",
      "[  4m 38s] Epoch-27 [80/549] loss: 0.0000\n",
      "[  4m 38s] Epoch-27 [90/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [100/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [110/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [120/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [130/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [140/549] loss: 0.0000\n",
      "[  4m 39s] Epoch-27 [150/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [160/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [170/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [180/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [190/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [200/549] loss: 0.0000\n",
      "[  4m 40s] Epoch-27 [210/549] loss: 0.0000\n",
      "[  4m 41s] Epoch-27 [220/549] loss: 0.0000\n",
      "[  4m 41s] Epoch-27 [230/549] loss: 0.0000\n",
      "[  4m 41s] Epoch-27 [240/549] loss: 0.0000\n",
      "[  4m 41s] Epoch-27 [250/549] loss: 0.0000\n",
      "[  4m 41s] Epoch-27 [260/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [270/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [280/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [290/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [300/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [310/549] loss: 0.0000\n",
      "[  4m 42s] Epoch-27 [320/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [330/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [340/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [350/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [360/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [370/549] loss: 0.0000\n",
      "[  4m 43s] Epoch-27 [380/549] loss: 0.0000\n",
      "[  4m 44s] Epoch-27 [390/549] loss: 0.0000\n",
      "[  4m 44s] Epoch-27 [400/549] loss: 0.0000\n",
      "[  4m 44s] Epoch-27 [410/549] loss: 0.0000\n",
      "[  4m 44s] Epoch-27 [420/549] loss: 0.0000\n",
      "[  4m 44s] Epoch-27 [430/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [440/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [450/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [460/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [470/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [480/549] loss: 0.0000\n",
      "[  4m 45s] Epoch-27 [490/549] loss: 0.0000\n",
      "[  4m 46s] Epoch-27 [500/549] loss: 0.0000\n",
      "[  4m 46s] Epoch-27 [510/549] loss: 0.0000\n",
      "[  4m 46s] Epoch-27 [520/549] loss: 0.0000\n",
      "[  4m 46s] Epoch-27 [530/549] loss: 0.0000\n",
      "[  4m 46s] Epoch-27 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.61%\n",
      "[  4m 48s] Epoch-28 [10/549] loss: 0.0000\n",
      "[  4m 48s] Epoch-28 [20/549] loss: 0.0000\n",
      "[  4m 48s] Epoch-28 [30/549] loss: 0.0000\n",
      "[  4m 48s] Epoch-28 [40/549] loss: 0.0000\n",
      "[  4m 48s] Epoch-28 [50/549] loss: 0.0000\n",
      "[  4m 48s] Epoch-28 [60/549] loss: 0.0000\n",
      "[  4m 49s] Epoch-28 [70/549] loss: 0.0000\n",
      "[  4m 49s] Epoch-28 [80/549] loss: 0.0000\n",
      "[  4m 49s] Epoch-28 [90/549] loss: 0.0000\n",
      "[  4m 49s] Epoch-28 [100/549] loss: 0.0000\n",
      "[  4m 49s] Epoch-28 [110/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [120/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [130/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [140/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [150/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [160/549] loss: 0.0000\n",
      "[  4m 50s] Epoch-28 [170/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [180/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [190/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [200/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [210/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [220/549] loss: 0.0000\n",
      "[  4m 51s] Epoch-28 [230/549] loss: 0.0000\n",
      "[  4m 52s] Epoch-28 [240/549] loss: 0.0000\n",
      "[  4m 52s] Epoch-28 [250/549] loss: 0.0000\n",
      "[  4m 52s] Epoch-28 [260/549] loss: 0.0000\n",
      "[  4m 52s] Epoch-28 [270/549] loss: 0.0000\n",
      "[  4m 52s] Epoch-28 [280/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [290/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [300/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [310/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [320/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [330/549] loss: 0.0000\n",
      "[  4m 53s] Epoch-28 [340/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [350/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [360/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [370/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [380/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [390/549] loss: 0.0000\n",
      "[  4m 54s] Epoch-28 [400/549] loss: 0.0000\n",
      "[  4m 55s] Epoch-28 [410/549] loss: 0.0000\n",
      "[  4m 55s] Epoch-28 [420/549] loss: 0.0000\n",
      "[  4m 55s] Epoch-28 [430/549] loss: 0.0000\n",
      "[  4m 55s] Epoch-28 [440/549] loss: 0.0000\n",
      "[  4m 55s] Epoch-28 [450/549] loss: 0.0000\n",
      "[  4m 56s] Epoch-28 [460/549] loss: 0.0000\n",
      "[  4m 56s] Epoch-28 [470/549] loss: 0.0000\n",
      "[  4m 56s] Epoch-28 [480/549] loss: 0.0000\n",
      "[  4m 56s] Epoch-28 [490/549] loss: 0.0000\n",
      "[  4m 56s] Epoch-28 [500/549] loss: 0.0000\n",
      "[  4m 57s] Epoch-28 [510/549] loss: 0.0000\n",
      "[  4m 57s] Epoch-28 [520/549] loss: 0.0000\n",
      "[  4m 57s] Epoch-28 [530/549] loss: 0.0000\n",
      "[  4m 57s] Epoch-28 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.23%\n",
      "[  4m 58s] Epoch-29 [10/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [20/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [30/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [40/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [50/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [60/549] loss: 0.0000\n",
      "[  4m 59s] Epoch-29 [70/549] loss: 0.0000\n",
      "[  5m  0s] Epoch-29 [80/549] loss: 0.0000\n",
      "[  5m  0s] Epoch-29 [90/549] loss: 0.0000\n",
      "[  5m  0s] Epoch-29 [100/549] loss: 0.0000\n",
      "[  5m  0s] Epoch-29 [110/549] loss: 0.0000\n",
      "[  5m  0s] Epoch-29 [120/549] loss: 0.0000\n",
      "[  5m  1s] Epoch-29 [130/549] loss: 0.0000\n",
      "[  5m  1s] Epoch-29 [140/549] loss: 0.0000\n",
      "[  5m  1s] Epoch-29 [150/549] loss: 0.0000\n",
      "[  5m  1s] Epoch-29 [160/549] loss: 0.0000\n",
      "[  5m  1s] Epoch-29 [170/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [180/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [190/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [200/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [210/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [220/549] loss: 0.0000\n",
      "[  5m  2s] Epoch-29 [230/549] loss: 0.0000\n",
      "[  5m  3s] Epoch-29 [240/549] loss: 0.0000\n",
      "[  5m  3s] Epoch-29 [250/549] loss: 0.0000\n",
      "[  5m  3s] Epoch-29 [260/549] loss: 0.0000\n",
      "[  5m  3s] Epoch-29 [270/549] loss: 0.0000\n",
      "[  5m  3s] Epoch-29 [280/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [290/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [300/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [310/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [320/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [330/549] loss: 0.0000\n",
      "[  5m  4s] Epoch-29 [340/549] loss: 0.0000\n",
      "[  5m  5s] Epoch-29 [350/549] loss: 0.0000\n",
      "[  5m  5s] Epoch-29 [360/549] loss: 0.0000\n",
      "[  5m  5s] Epoch-29 [370/549] loss: 0.0000\n",
      "[  5m  5s] Epoch-29 [380/549] loss: 0.0000\n",
      "[  5m  5s] Epoch-29 [390/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [400/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [410/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [420/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [430/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [440/549] loss: 0.0000\n",
      "[  5m  6s] Epoch-29 [450/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [460/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [470/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [480/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [490/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [500/549] loss: 0.0000\n",
      "[  5m  7s] Epoch-29 [510/549] loss: 0.0000\n",
      "[  5m  8s] Epoch-29 [520/549] loss: 0.0000\n",
      "[  5m  8s] Epoch-29 [530/549] loss: 0.0000\n",
      "[  5m  8s] Epoch-29 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.40%\n",
      "[  5m  9s] Epoch-30 [10/549] loss: 0.0000\n",
      "[  5m  9s] Epoch-30 [20/549] loss: 0.0000\n",
      "[  5m 10s] Epoch-30 [30/549] loss: 0.0000\n",
      "[  5m 10s] Epoch-30 [40/549] loss: 0.0000\n",
      "[  5m 10s] Epoch-30 [50/549] loss: 0.0000\n",
      "[  5m 10s] Epoch-30 [60/549] loss: 0.0000\n",
      "[  5m 10s] Epoch-30 [70/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [80/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [90/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [100/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [110/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [120/549] loss: 0.0000\n",
      "[  5m 11s] Epoch-30 [130/549] loss: 0.0000\n",
      "[  5m 12s] Epoch-30 [140/549] loss: 0.0000\n",
      "[  5m 12s] Epoch-30 [150/549] loss: 0.0000\n",
      "[  5m 12s] Epoch-30 [160/549] loss: 0.0000\n",
      "[  5m 12s] Epoch-30 [170/549] loss: 0.0000\n",
      "[  5m 12s] Epoch-30 [180/549] loss: 0.0000\n",
      "[  5m 13s] Epoch-30 [190/549] loss: 0.0000\n",
      "[  5m 13s] Epoch-30 [200/549] loss: 0.0000\n",
      "[  5m 13s] Epoch-30 [210/549] loss: 0.0000\n",
      "[  5m 13s] Epoch-30 [220/549] loss: 0.0000\n",
      "[  5m 13s] Epoch-30 [230/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [240/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [250/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [260/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [270/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [280/549] loss: 0.0000\n",
      "[  5m 14s] Epoch-30 [290/549] loss: 0.0000\n",
      "[  5m 15s] Epoch-30 [300/549] loss: 0.0000\n",
      "[  5m 15s] Epoch-30 [310/549] loss: 0.0000\n",
      "[  5m 15s] Epoch-30 [320/549] loss: 0.0000\n",
      "[  5m 15s] Epoch-30 [330/549] loss: 0.0000\n",
      "[  5m 15s] Epoch-30 [340/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [350/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [360/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [370/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [380/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [390/549] loss: 0.0000\n",
      "[  5m 16s] Epoch-30 [400/549] loss: 0.0000\n",
      "[  5m 17s] Epoch-30 [410/549] loss: 0.0000\n",
      "[  5m 17s] Epoch-30 [420/549] loss: 0.0000\n",
      "[  5m 17s] Epoch-30 [430/549] loss: 0.0000\n",
      "[  5m 17s] Epoch-30 [440/549] loss: 0.0000\n",
      "[  5m 17s] Epoch-30 [450/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [460/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [470/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [480/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [490/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [500/549] loss: 0.0000\n",
      "[  5m 18s] Epoch-30 [510/549] loss: 0.0000\n",
      "[  5m 19s] Epoch-30 [520/549] loss: 0.0000\n",
      "[  5m 19s] Epoch-30 [530/549] loss: 0.0000\n",
      "[  5m 19s] Epoch-30 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.11%\n",
      "[  5m 20s] Epoch-31 [10/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [20/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [30/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [40/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [50/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [60/549] loss: 0.0001\n",
      "[  5m 21s] Epoch-31 [70/549] loss: 0.0001\n",
      "[  5m 22s] Epoch-31 [80/549] loss: 0.0000\n",
      "[  5m 22s] Epoch-31 [90/549] loss: 0.0000\n",
      "[  5m 22s] Epoch-31 [100/549] loss: 0.0000\n",
      "[  5m 22s] Epoch-31 [110/549] loss: 0.0000\n",
      "[  5m 22s] Epoch-31 [120/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [130/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [140/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [150/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [160/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [170/549] loss: 0.0000\n",
      "[  5m 23s] Epoch-31 [180/549] loss: 0.0000\n",
      "[  5m 24s] Epoch-31 [190/549] loss: 0.0000\n",
      "[  5m 24s] Epoch-31 [200/549] loss: 0.0000\n",
      "[  5m 24s] Epoch-31 [210/549] loss: 0.0000\n",
      "[  5m 24s] Epoch-31 [220/549] loss: 0.0000\n",
      "[  5m 24s] Epoch-31 [230/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [240/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [250/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [260/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [270/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [280/549] loss: 0.0000\n",
      "[  5m 25s] Epoch-31 [290/549] loss: 0.0000\n",
      "[  5m 26s] Epoch-31 [300/549] loss: 0.0000\n",
      "[  5m 26s] Epoch-31 [310/549] loss: 0.0000\n",
      "[  5m 26s] Epoch-31 [320/549] loss: 0.0000\n",
      "[  5m 26s] Epoch-31 [330/549] loss: 0.0000\n",
      "[  5m 26s] Epoch-31 [340/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [350/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [360/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [370/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [380/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [390/549] loss: 0.0000\n",
      "[  5m 27s] Epoch-31 [400/549] loss: 0.0000\n",
      "[  5m 28s] Epoch-31 [410/549] loss: 0.0000\n",
      "[  5m 28s] Epoch-31 [420/549] loss: 0.0001\n",
      "[  5m 28s] Epoch-31 [430/549] loss: 0.0001\n",
      "[  5m 28s] Epoch-31 [440/549] loss: 0.0001\n",
      "[  5m 28s] Epoch-31 [450/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [460/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [470/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [480/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [490/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [500/549] loss: 0.0001\n",
      "[  5m 29s] Epoch-31 [510/549] loss: 0.0001\n",
      "[  5m 30s] Epoch-31 [520/549] loss: 0.0001\n",
      "[  5m 30s] Epoch-31 [530/549] loss: 0.0001\n",
      "[  5m 30s] Epoch-31 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.13%\n",
      "[  5m 31s] Epoch-32 [10/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [20/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [30/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [40/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [50/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [60/549] loss: 0.0001\n",
      "[  5m 32s] Epoch-32 [70/549] loss: 0.0001\n",
      "[  5m 33s] Epoch-32 [80/549] loss: 0.0001\n",
      "[  5m 33s] Epoch-32 [90/549] loss: 0.0000\n",
      "[  5m 33s] Epoch-32 [100/549] loss: 0.0000\n",
      "[  5m 33s] Epoch-32 [110/549] loss: 0.0000\n",
      "[  5m 33s] Epoch-32 [120/549] loss: 0.0000\n",
      "[  5m 33s] Epoch-32 [130/549] loss: 0.0000\n",
      "[  5m 34s] Epoch-32 [140/549] loss: 0.0000\n",
      "[  5m 34s] Epoch-32 [150/549] loss: 0.0000\n",
      "[  5m 34s] Epoch-32 [160/549] loss: 0.0000\n",
      "[  5m 34s] Epoch-32 [170/549] loss: 0.0000\n",
      "[  5m 34s] Epoch-32 [180/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [190/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [200/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [210/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [220/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [230/549] loss: 0.0000\n",
      "[  5m 35s] Epoch-32 [240/549] loss: 0.0000\n",
      "[  5m 36s] Epoch-32 [250/549] loss: 0.0000\n",
      "[  5m 36s] Epoch-32 [260/549] loss: 0.0000\n",
      "[  5m 36s] Epoch-32 [270/549] loss: 0.0000\n",
      "[  5m 36s] Epoch-32 [280/549] loss: 0.0000\n",
      "[  5m 36s] Epoch-32 [290/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [300/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [310/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [320/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [330/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [340/549] loss: 0.0000\n",
      "[  5m 37s] Epoch-32 [350/549] loss: 0.0000\n",
      "[  5m 38s] Epoch-32 [360/549] loss: 0.0000\n",
      "[  5m 38s] Epoch-32 [370/549] loss: 0.0000\n",
      "[  5m 38s] Epoch-32 [380/549] loss: 0.0000\n",
      "[  5m 38s] Epoch-32 [390/549] loss: 0.0000\n",
      "[  5m 38s] Epoch-32 [400/549] loss: 0.0000\n",
      "[  5m 39s] Epoch-32 [410/549] loss: 0.0000\n",
      "[  5m 39s] Epoch-32 [420/549] loss: 0.0000\n",
      "[  5m 39s] Epoch-32 [430/549] loss: 0.0000\n",
      "[  5m 39s] Epoch-32 [440/549] loss: 0.0000\n",
      "[  5m 39s] Epoch-32 [450/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [460/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [470/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [480/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [490/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [500/549] loss: 0.0000\n",
      "[  5m 40s] Epoch-32 [510/549] loss: 0.0000\n",
      "[  5m 41s] Epoch-32 [520/549] loss: 0.0000\n",
      "[  5m 41s] Epoch-32 [530/549] loss: 0.0000\n",
      "[  5m 41s] Epoch-32 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.14%\n",
      "[  5m 42s] Epoch-33 [10/549] loss: 0.0001\n",
      "[  5m 42s] Epoch-33 [20/549] loss: 0.0001\n",
      "[  5m 43s] Epoch-33 [30/549] loss: 0.0001\n",
      "[  5m 43s] Epoch-33 [40/549] loss: 0.0001\n",
      "[  5m 43s] Epoch-33 [50/549] loss: 0.0001\n",
      "[  5m 43s] Epoch-33 [60/549] loss: 0.0001\n",
      "[  5m 43s] Epoch-33 [70/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [80/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [90/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [100/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [110/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [120/549] loss: 0.0001\n",
      "[  5m 44s] Epoch-33 [130/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [140/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [150/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [160/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [170/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [180/549] loss: 0.0001\n",
      "[  5m 45s] Epoch-33 [190/549] loss: 0.0001\n",
      "[  5m 46s] Epoch-33 [200/549] loss: 0.0001\n",
      "[  5m 46s] Epoch-33 [210/549] loss: 0.0001\n",
      "[  5m 46s] Epoch-33 [220/549] loss: 0.0001\n",
      "[  5m 46s] Epoch-33 [230/549] loss: 0.0001\n",
      "[  5m 46s] Epoch-33 [240/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [250/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [260/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [270/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [280/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [290/549] loss: 0.0001\n",
      "[  5m 47s] Epoch-33 [300/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [310/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [320/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [330/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [340/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [350/549] loss: 0.0001\n",
      "[  5m 48s] Epoch-33 [360/549] loss: 0.0001\n",
      "[  5m 49s] Epoch-33 [370/549] loss: 0.0001\n",
      "[  5m 49s] Epoch-33 [380/549] loss: 0.0001\n",
      "[  5m 49s] Epoch-33 [390/549] loss: 0.0001\n",
      "[  5m 49s] Epoch-33 [400/549] loss: 0.0001\n",
      "[  5m 49s] Epoch-33 [410/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [420/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [430/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [440/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [450/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [460/549] loss: 0.0001\n",
      "[  5m 50s] Epoch-33 [470/549] loss: 0.0001\n",
      "[  5m 51s] Epoch-33 [480/549] loss: 0.0001\n",
      "[  5m 51s] Epoch-33 [490/549] loss: 0.0001\n",
      "[  5m 51s] Epoch-33 [500/549] loss: 0.0001\n",
      "[  5m 51s] Epoch-33 [510/549] loss: 0.0001\n",
      "[  5m 51s] Epoch-33 [520/549] loss: 0.0001\n",
      "[  5m 52s] Epoch-33 [530/549] loss: 0.0001\n",
      "[  5m 52s] Epoch-33 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.68%\n",
      "[  5m 53s] Epoch-34 [10/549] loss: 0.0000\n",
      "[  5m 53s] Epoch-34 [20/549] loss: 0.0000\n",
      "[  5m 53s] Epoch-34 [30/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [40/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [50/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [60/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [70/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [80/549] loss: 0.0000\n",
      "[  5m 54s] Epoch-34 [90/549] loss: 0.0000\n",
      "[  5m 55s] Epoch-34 [100/549] loss: 0.0000\n",
      "[  5m 55s] Epoch-34 [110/549] loss: 0.0000\n",
      "[  5m 55s] Epoch-34 [120/549] loss: 0.0000\n",
      "[  5m 55s] Epoch-34 [130/549] loss: 0.0000\n",
      "[  5m 55s] Epoch-34 [140/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [150/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [160/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [170/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [180/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [190/549] loss: 0.0000\n",
      "[  5m 56s] Epoch-34 [200/549] loss: 0.0000\n",
      "[  5m 57s] Epoch-34 [210/549] loss: 0.0000\n",
      "[  5m 57s] Epoch-34 [220/549] loss: 0.0000\n",
      "[  5m 57s] Epoch-34 [230/549] loss: 0.0000\n",
      "[  5m 57s] Epoch-34 [240/549] loss: 0.0000\n",
      "[  5m 57s] Epoch-34 [250/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [260/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [270/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [280/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [290/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [300/549] loss: 0.0000\n",
      "[  5m 58s] Epoch-34 [310/549] loss: 0.0000\n",
      "[  5m 59s] Epoch-34 [320/549] loss: 0.0000\n",
      "[  5m 59s] Epoch-34 [330/549] loss: 0.0000\n",
      "[  5m 59s] Epoch-34 [340/549] loss: 0.0000\n",
      "[  5m 59s] Epoch-34 [350/549] loss: 0.0000\n",
      "[  5m 59s] Epoch-34 [360/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [370/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [380/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [390/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [400/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [410/549] loss: 0.0000\n",
      "[  6m  0s] Epoch-34 [420/549] loss: 0.0000\n",
      "[  6m  1s] Epoch-34 [430/549] loss: 0.0000\n",
      "[  6m  1s] Epoch-34 [440/549] loss: 0.0000\n",
      "[  6m  1s] Epoch-34 [450/549] loss: 0.0000\n",
      "[  6m  1s] Epoch-34 [460/549] loss: 0.0000\n",
      "[  6m  1s] Epoch-34 [470/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [480/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [490/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [500/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [510/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [520/549] loss: 0.0000\n",
      "[  6m  2s] Epoch-34 [530/549] loss: 0.0000\n",
      "[  6m  3s] Epoch-34 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.69%\n",
      "[  6m  4s] Epoch-35 [10/549] loss: 0.0000\n",
      "[  6m  4s] Epoch-35 [20/549] loss: 0.0000\n",
      "[  6m  4s] Epoch-35 [30/549] loss: 0.0000\n",
      "[  6m  4s] Epoch-35 [40/549] loss: 0.0000\n",
      "[  6m  5s] Epoch-35 [50/549] loss: 0.0000\n",
      "[  6m  5s] Epoch-35 [60/549] loss: 0.0000\n",
      "[  6m  5s] Epoch-35 [70/549] loss: 0.0000\n",
      "[  6m  5s] Epoch-35 [80/549] loss: 0.0000\n",
      "[  6m  5s] Epoch-35 [90/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [100/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [110/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [120/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [130/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [140/549] loss: 0.0000\n",
      "[  6m  6s] Epoch-35 [150/549] loss: 0.0000\n",
      "[  6m  7s] Epoch-35 [160/549] loss: 0.0000\n",
      "[  6m  7s] Epoch-35 [170/549] loss: 0.0000\n",
      "[  6m  7s] Epoch-35 [180/549] loss: 0.0000\n",
      "[  6m  7s] Epoch-35 [190/549] loss: 0.0000\n",
      "[  6m  7s] Epoch-35 [200/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [210/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [220/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [230/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [240/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [250/549] loss: 0.0000\n",
      "[  6m  8s] Epoch-35 [260/549] loss: 0.0000\n",
      "[  6m  9s] Epoch-35 [270/549] loss: 0.0000\n",
      "[  6m  9s] Epoch-35 [280/549] loss: 0.0000\n",
      "[  6m  9s] Epoch-35 [290/549] loss: 0.0000\n",
      "[  6m  9s] Epoch-35 [300/549] loss: 0.0000\n",
      "[  6m  9s] Epoch-35 [310/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [320/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [330/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [340/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [350/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [360/549] loss: 0.0000\n",
      "[  6m 10s] Epoch-35 [370/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [380/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [390/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [400/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [410/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [420/549] loss: 0.0000\n",
      "[  6m 11s] Epoch-35 [430/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [440/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [450/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [460/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [470/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [480/549] loss: 0.0000\n",
      "[  6m 12s] Epoch-35 [490/549] loss: 0.0000\n",
      "[  6m 13s] Epoch-35 [500/549] loss: 0.0000\n",
      "[  6m 13s] Epoch-35 [510/549] loss: 0.0000\n",
      "[  6m 13s] Epoch-35 [520/549] loss: 0.0000\n",
      "[  6m 13s] Epoch-35 [530/549] loss: 0.0000\n",
      "[  6m 13s] Epoch-35 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.72%\n",
      "[  6m 15s] Epoch-36 [10/549] loss: 0.0000\n",
      "[  6m 15s] Epoch-36 [20/549] loss: 0.0000\n",
      "[  6m 15s] Epoch-36 [30/549] loss: 0.0000\n",
      "[  6m 15s] Epoch-36 [40/549] loss: 0.0000\n",
      "[  6m 15s] Epoch-36 [50/549] loss: 0.0000\n",
      "[  6m 16s] Epoch-36 [60/549] loss: 0.0000\n",
      "[  6m 16s] Epoch-36 [70/549] loss: 0.0000\n",
      "[  6m 16s] Epoch-36 [80/549] loss: 0.0000\n",
      "[  6m 16s] Epoch-36 [90/549] loss: 0.0000\n",
      "[  6m 16s] Epoch-36 [100/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [110/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [120/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [130/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [140/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [150/549] loss: 0.0000\n",
      "[  6m 17s] Epoch-36 [160/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [170/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [180/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [190/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [200/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [210/549] loss: 0.0000\n",
      "[  6m 18s] Epoch-36 [220/549] loss: 0.0000\n",
      "[  6m 19s] Epoch-36 [230/549] loss: 0.0000\n",
      "[  6m 19s] Epoch-36 [240/549] loss: 0.0000\n",
      "[  6m 19s] Epoch-36 [250/549] loss: 0.0000\n",
      "[  6m 19s] Epoch-36 [260/549] loss: 0.0000\n",
      "[  6m 19s] Epoch-36 [270/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [280/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [290/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [300/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [310/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [320/549] loss: 0.0000\n",
      "[  6m 20s] Epoch-36 [330/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [340/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [350/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [360/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [370/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [380/549] loss: 0.0000\n",
      "[  6m 21s] Epoch-36 [390/549] loss: 0.0000\n",
      "[  6m 22s] Epoch-36 [400/549] loss: 0.0000\n",
      "[  6m 22s] Epoch-36 [410/549] loss: 0.0000\n",
      "[  6m 22s] Epoch-36 [420/549] loss: 0.0000\n",
      "[  6m 22s] Epoch-36 [430/549] loss: 0.0000\n",
      "[  6m 22s] Epoch-36 [440/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [450/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [460/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [470/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [480/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [490/549] loss: 0.0000\n",
      "[  6m 23s] Epoch-36 [500/549] loss: 0.0000\n",
      "[  6m 24s] Epoch-36 [510/549] loss: 0.0000\n",
      "[  6m 24s] Epoch-36 [520/549] loss: 0.0000\n",
      "[  6m 24s] Epoch-36 [530/549] loss: 0.0000\n",
      "[  6m 24s] Epoch-36 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.82%\n",
      "[  6m 25s] Epoch-37 [10/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [20/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [30/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [40/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [50/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [60/549] loss: 0.0000\n",
      "[  6m 26s] Epoch-37 [70/549] loss: 0.0000\n",
      "[  6m 27s] Epoch-37 [80/549] loss: 0.0000\n",
      "[  6m 27s] Epoch-37 [90/549] loss: 0.0000\n",
      "[  6m 27s] Epoch-37 [100/549] loss: 0.0000\n",
      "[  6m 27s] Epoch-37 [110/549] loss: 0.0000\n",
      "[  6m 27s] Epoch-37 [120/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [130/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [140/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [150/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [160/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [170/549] loss: 0.0000\n",
      "[  6m 28s] Epoch-37 [180/549] loss: 0.0000\n",
      "[  6m 29s] Epoch-37 [190/549] loss: 0.0000\n",
      "[  6m 29s] Epoch-37 [200/549] loss: 0.0000\n",
      "[  6m 29s] Epoch-37 [210/549] loss: 0.0000\n",
      "[  6m 29s] Epoch-37 [220/549] loss: 0.0000\n",
      "[  6m 29s] Epoch-37 [230/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [240/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [250/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [260/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [270/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [280/549] loss: 0.0000\n",
      "[  6m 30s] Epoch-37 [290/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [300/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [310/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [320/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [330/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [340/549] loss: 0.0001\n",
      "[  6m 31s] Epoch-37 [350/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [360/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [370/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [380/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [390/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [400/549] loss: 0.0001\n",
      "[  6m 32s] Epoch-37 [410/549] loss: 0.0001\n",
      "[  6m 33s] Epoch-37 [420/549] loss: 0.0001\n",
      "[  6m 33s] Epoch-37 [430/549] loss: 0.0001\n",
      "[  6m 33s] Epoch-37 [440/549] loss: 0.0001\n",
      "[  6m 33s] Epoch-37 [450/549] loss: 0.0001\n",
      "[  6m 33s] Epoch-37 [460/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [470/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [480/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [490/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [500/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [510/549] loss: 0.0001\n",
      "[  6m 34s] Epoch-37 [520/549] loss: 0.0001\n",
      "[  6m 35s] Epoch-37 [530/549] loss: 0.0001\n",
      "[  6m 35s] Epoch-37 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.06%\n",
      "[  6m 36s] Epoch-38 [10/549] loss: 0.0001\n",
      "[  6m 36s] Epoch-38 [20/549] loss: 0.0001\n",
      "[  6m 36s] Epoch-38 [30/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [40/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [50/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [60/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [70/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [80/549] loss: 0.0001\n",
      "[  6m 37s] Epoch-38 [90/549] loss: 0.0001\n",
      "[  6m 38s] Epoch-38 [100/549] loss: 0.0001\n",
      "[  6m 38s] Epoch-38 [110/549] loss: 0.0001\n",
      "[  6m 38s] Epoch-38 [120/549] loss: 0.0001\n",
      "[  6m 38s] Epoch-38 [130/549] loss: 0.0001\n",
      "[  6m 38s] Epoch-38 [140/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [150/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [160/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [170/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [180/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [190/549] loss: 0.0001\n",
      "[  6m 39s] Epoch-38 [200/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [210/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [220/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [230/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [240/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [250/549] loss: 0.0001\n",
      "[  6m 40s] Epoch-38 [260/549] loss: 0.0001\n",
      "[  6m 41s] Epoch-38 [270/549] loss: 0.0001\n",
      "[  6m 41s] Epoch-38 [280/549] loss: 0.0001\n",
      "[  6m 41s] Epoch-38 [290/549] loss: 0.0001\n",
      "[  6m 41s] Epoch-38 [300/549] loss: 0.0001\n",
      "[  6m 41s] Epoch-38 [310/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [320/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [330/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [340/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [350/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [360/549] loss: 0.0001\n",
      "[  6m 42s] Epoch-38 [370/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [380/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [390/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [400/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [410/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [420/549] loss: 0.0001\n",
      "[  6m 43s] Epoch-38 [430/549] loss: 0.0001\n",
      "[  6m 44s] Epoch-38 [440/549] loss: 0.0001\n",
      "[  6m 44s] Epoch-38 [450/549] loss: 0.0001\n",
      "[  6m 44s] Epoch-38 [460/549] loss: 0.0001\n",
      "[  6m 44s] Epoch-38 [470/549] loss: 0.0001\n",
      "[  6m 44s] Epoch-38 [480/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [490/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [500/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [510/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [520/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [530/549] loss: 0.0001\n",
      "[  6m 45s] Epoch-38 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.48%\n",
      "[  6m 47s] Epoch-39 [10/549] loss: 0.0000\n",
      "[  6m 47s] Epoch-39 [20/549] loss: 0.0000\n",
      "[  6m 47s] Epoch-39 [30/549] loss: 0.0000\n",
      "[  6m 47s] Epoch-39 [40/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [50/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [60/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [70/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [80/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [90/549] loss: 0.0000\n",
      "[  6m 48s] Epoch-39 [100/549] loss: 0.0000\n",
      "[  6m 49s] Epoch-39 [110/549] loss: 0.0000\n",
      "[  6m 49s] Epoch-39 [120/549] loss: 0.0000\n",
      "[  6m 49s] Epoch-39 [130/549] loss: 0.0000\n",
      "[  6m 49s] Epoch-39 [140/549] loss: 0.0000\n",
      "[  6m 49s] Epoch-39 [150/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [160/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [170/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [180/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [190/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [200/549] loss: 0.0000\n",
      "[  6m 50s] Epoch-39 [210/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [220/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [230/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [240/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [250/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [260/549] loss: 0.0000\n",
      "[  6m 51s] Epoch-39 [270/549] loss: 0.0000\n",
      "[  6m 52s] Epoch-39 [280/549] loss: 0.0000\n",
      "[  6m 52s] Epoch-39 [290/549] loss: 0.0000\n",
      "[  6m 52s] Epoch-39 [300/549] loss: 0.0000\n",
      "[  6m 52s] Epoch-39 [310/549] loss: 0.0000\n",
      "[  6m 52s] Epoch-39 [320/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [330/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [340/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [350/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [360/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [370/549] loss: 0.0000\n",
      "[  6m 53s] Epoch-39 [380/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [390/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [400/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [410/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [420/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [430/549] loss: 0.0000\n",
      "[  6m 54s] Epoch-39 [440/549] loss: 0.0000\n",
      "[  6m 55s] Epoch-39 [450/549] loss: 0.0000\n",
      "[  6m 55s] Epoch-39 [460/549] loss: 0.0000\n",
      "[  6m 55s] Epoch-39 [470/549] loss: 0.0000\n",
      "[  6m 55s] Epoch-39 [480/549] loss: 0.0000\n",
      "[  6m 55s] Epoch-39 [490/549] loss: 0.0000\n",
      "[  6m 56s] Epoch-39 [500/549] loss: 0.0000\n",
      "[  6m 56s] Epoch-39 [510/549] loss: 0.0000\n",
      "[  6m 56s] Epoch-39 [520/549] loss: 0.0000\n",
      "[  6m 56s] Epoch-39 [530/549] loss: 0.0000\n",
      "[  6m 56s] Epoch-39 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.69%\n",
      "[  6m 58s] Epoch-40 [10/549] loss: 0.0000\n",
      "[  6m 58s] Epoch-40 [20/549] loss: 0.0000\n",
      "[  6m 58s] Epoch-40 [30/549] loss: 0.0000\n",
      "[  6m 58s] Epoch-40 [40/549] loss: 0.0000\n",
      "[  6m 58s] Epoch-40 [50/549] loss: 0.0000\n",
      "[  6m 58s] Epoch-40 [60/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [70/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [80/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [90/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [100/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [110/549] loss: 0.0000\n",
      "[  6m 59s] Epoch-40 [120/549] loss: 0.0000\n",
      "[  7m  0s] Epoch-40 [130/549] loss: 0.0000\n",
      "[  7m  0s] Epoch-40 [140/549] loss: 0.0000\n",
      "[  7m  0s] Epoch-40 [150/549] loss: 0.0000\n",
      "[  7m  0s] Epoch-40 [160/549] loss: 0.0000\n",
      "[  7m  0s] Epoch-40 [170/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [180/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [190/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [200/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [210/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [220/549] loss: 0.0000\n",
      "[  7m  1s] Epoch-40 [230/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [240/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [250/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [260/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [270/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [280/549] loss: 0.0000\n",
      "[  7m  2s] Epoch-40 [290/549] loss: 0.0000\n",
      "[  7m  3s] Epoch-40 [300/549] loss: 0.0000\n",
      "[  7m  3s] Epoch-40 [310/549] loss: 0.0000\n",
      "[  7m  3s] Epoch-40 [320/549] loss: 0.0000\n",
      "[  7m  3s] Epoch-40 [330/549] loss: 0.0000\n",
      "[  7m  3s] Epoch-40 [340/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [350/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [360/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [370/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [380/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [390/549] loss: 0.0000\n",
      "[  7m  4s] Epoch-40 [400/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [410/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [420/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [430/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [440/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [450/549] loss: 0.0000\n",
      "[  7m  5s] Epoch-40 [460/549] loss: 0.0000\n",
      "[  7m  6s] Epoch-40 [470/549] loss: 0.0000\n",
      "[  7m  6s] Epoch-40 [480/549] loss: 0.0000\n",
      "[  7m  6s] Epoch-40 [490/549] loss: 0.0000\n",
      "[  7m  6s] Epoch-40 [500/549] loss: 0.0000\n",
      "[  7m  6s] Epoch-40 [510/549] loss: 0.0000\n",
      "[  7m  7s] Epoch-40 [520/549] loss: 0.0000\n",
      "[  7m  7s] Epoch-40 [530/549] loss: 0.0000\n",
      "[  7m  7s] Epoch-40 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.76%\n",
      "[  7m  8s] Epoch-41 [10/549] loss: 0.0000\n",
      "[  7m  8s] Epoch-41 [20/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [30/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [40/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [50/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [60/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [70/549] loss: 0.0000\n",
      "[  7m  9s] Epoch-41 [80/549] loss: 0.0000\n",
      "[  7m 10s] Epoch-41 [90/549] loss: 0.0000\n",
      "[  7m 10s] Epoch-41 [100/549] loss: 0.0000\n",
      "[  7m 10s] Epoch-41 [110/549] loss: 0.0000\n",
      "[  7m 10s] Epoch-41 [120/549] loss: 0.0000\n",
      "[  7m 10s] Epoch-41 [130/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [140/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [150/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [160/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [170/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [180/549] loss: 0.0000\n",
      "[  7m 11s] Epoch-41 [190/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [200/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [210/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [220/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [230/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [240/549] loss: 0.0000\n",
      "[  7m 12s] Epoch-41 [250/549] loss: 0.0000\n",
      "[  7m 13s] Epoch-41 [260/549] loss: 0.0000\n",
      "[  7m 13s] Epoch-41 [270/549] loss: 0.0000\n",
      "[  7m 13s] Epoch-41 [280/549] loss: 0.0000\n",
      "[  7m 13s] Epoch-41 [290/549] loss: 0.0000\n",
      "[  7m 13s] Epoch-41 [300/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [310/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [320/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [330/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [340/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [350/549] loss: 0.0000\n",
      "[  7m 14s] Epoch-41 [360/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [370/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [380/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [390/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [400/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [410/549] loss: 0.0000\n",
      "[  7m 15s] Epoch-41 [420/549] loss: 0.0000\n",
      "[  7m 16s] Epoch-41 [430/549] loss: 0.0000\n",
      "[  7m 16s] Epoch-41 [440/549] loss: 0.0000\n",
      "[  7m 16s] Epoch-41 [450/549] loss: 0.0000\n",
      "[  7m 16s] Epoch-41 [460/549] loss: 0.0000\n",
      "[  7m 16s] Epoch-41 [470/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [480/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [490/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [500/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [510/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [520/549] loss: 0.0000\n",
      "[  7m 17s] Epoch-41 [530/549] loss: 0.0000\n",
      "[  7m 18s] Epoch-41 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.91%\n",
      "[  7m 19s] Epoch-42 [10/549] loss: 0.0000\n",
      "[  7m 19s] Epoch-42 [20/549] loss: 0.0000\n",
      "[  7m 19s] Epoch-42 [30/549] loss: 0.0000\n",
      "[  7m 19s] Epoch-42 [40/549] loss: 0.0000\n",
      "[  7m 20s] Epoch-42 [50/549] loss: 0.0000\n",
      "[  7m 20s] Epoch-42 [60/549] loss: 0.0000\n",
      "[  7m 20s] Epoch-42 [70/549] loss: 0.0000\n",
      "[  7m 20s] Epoch-42 [80/549] loss: 0.0000\n",
      "[  7m 20s] Epoch-42 [90/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [100/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [110/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [120/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [130/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [140/549] loss: 0.0000\n",
      "[  7m 21s] Epoch-42 [150/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [160/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [170/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [180/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [190/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [200/549] loss: 0.0000\n",
      "[  7m 22s] Epoch-42 [210/549] loss: 0.0000\n",
      "[  7m 23s] Epoch-42 [220/549] loss: 0.0000\n",
      "[  7m 23s] Epoch-42 [230/549] loss: 0.0000\n",
      "[  7m 23s] Epoch-42 [240/549] loss: 0.0000\n",
      "[  7m 23s] Epoch-42 [250/549] loss: 0.0000\n",
      "[  7m 23s] Epoch-42 [260/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [270/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [280/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [290/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [300/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [310/549] loss: 0.0000\n",
      "[  7m 24s] Epoch-42 [320/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [330/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [340/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [350/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [360/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [370/549] loss: 0.0000\n",
      "[  7m 25s] Epoch-42 [380/549] loss: 0.0000\n",
      "[  7m 26s] Epoch-42 [390/549] loss: 0.0000\n",
      "[  7m 26s] Epoch-42 [400/549] loss: 0.0000\n",
      "[  7m 26s] Epoch-42 [410/549] loss: 0.0000\n",
      "[  7m 26s] Epoch-42 [420/549] loss: 0.0000\n",
      "[  7m 26s] Epoch-42 [430/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [440/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [450/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [460/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [470/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [480/549] loss: 0.0000\n",
      "[  7m 27s] Epoch-42 [490/549] loss: 0.0000\n",
      "[  7m 28s] Epoch-42 [500/549] loss: 0.0000\n",
      "[  7m 28s] Epoch-42 [510/549] loss: 0.0000\n",
      "[  7m 28s] Epoch-42 [520/549] loss: 0.0000\n",
      "[  7m 28s] Epoch-42 [530/549] loss: 0.0000\n",
      "[  7m 28s] Epoch-42 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.98%\n",
      "[  7m 30s] Epoch-43 [10/549] loss: 0.0000\n",
      "[  7m 30s] Epoch-43 [20/549] loss: 0.0000\n",
      "[  7m 30s] Epoch-43 [30/549] loss: 0.0000\n",
      "[  7m 30s] Epoch-43 [40/549] loss: 0.0000\n",
      "[  7m 30s] Epoch-43 [50/549] loss: 0.0000\n",
      "[  7m 30s] Epoch-43 [60/549] loss: 0.0000\n",
      "[  7m 31s] Epoch-43 [70/549] loss: 0.0000\n",
      "[  7m 31s] Epoch-43 [80/549] loss: 0.0000\n",
      "[  7m 31s] Epoch-43 [90/549] loss: 0.0000\n",
      "[  7m 31s] Epoch-43 [100/549] loss: 0.0000\n",
      "[  7m 31s] Epoch-43 [110/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [120/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [130/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [140/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [150/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [160/549] loss: 0.0000\n",
      "[  7m 32s] Epoch-43 [170/549] loss: 0.0000\n",
      "[  7m 33s] Epoch-43 [180/549] loss: 0.0000\n",
      "[  7m 33s] Epoch-43 [190/549] loss: 0.0000\n",
      "[  7m 33s] Epoch-43 [200/549] loss: 0.0000\n",
      "[  7m 33s] Epoch-43 [210/549] loss: 0.0000\n",
      "[  7m 33s] Epoch-43 [220/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [230/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [240/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [250/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [260/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [270/549] loss: 0.0000\n",
      "[  7m 34s] Epoch-43 [280/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [290/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [300/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [310/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [320/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [330/549] loss: 0.0000\n",
      "[  7m 35s] Epoch-43 [340/549] loss: 0.0000\n",
      "[  7m 36s] Epoch-43 [350/549] loss: 0.0000\n",
      "[  7m 36s] Epoch-43 [360/549] loss: 0.0000\n",
      "[  7m 36s] Epoch-43 [370/549] loss: 0.0000\n",
      "[  7m 36s] Epoch-43 [380/549] loss: 0.0000\n",
      "[  7m 36s] Epoch-43 [390/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [400/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [410/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [420/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [430/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [440/549] loss: 0.0000\n",
      "[  7m 37s] Epoch-43 [450/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [460/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [470/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [480/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [490/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [500/549] loss: 0.0000\n",
      "[  7m 38s] Epoch-43 [510/549] loss: 0.0000\n",
      "[  7m 39s] Epoch-43 [520/549] loss: 0.0000\n",
      "[  7m 39s] Epoch-43 [530/549] loss: 0.0000\n",
      "[  7m 39s] Epoch-43 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.99%\n",
      "[  7m 40s] Epoch-44 [10/549] loss: 0.0000\n",
      "[  7m 40s] Epoch-44 [20/549] loss: 0.0000\n",
      "[  7m 41s] Epoch-44 [30/549] loss: 0.0000\n",
      "[  7m 41s] Epoch-44 [40/549] loss: 0.0000\n",
      "[  7m 41s] Epoch-44 [50/549] loss: 0.0000\n",
      "[  7m 41s] Epoch-44 [60/549] loss: 0.0000\n",
      "[  7m 41s] Epoch-44 [70/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [80/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [90/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [100/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [110/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [120/549] loss: 0.0000\n",
      "[  7m 42s] Epoch-44 [130/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [140/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [150/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [160/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [170/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [180/549] loss: 0.0000\n",
      "[  7m 43s] Epoch-44 [190/549] loss: 0.0000\n",
      "[  7m 44s] Epoch-44 [200/549] loss: 0.0000\n",
      "[  7m 44s] Epoch-44 [210/549] loss: 0.0000\n",
      "[  7m 44s] Epoch-44 [220/549] loss: 0.0000\n",
      "[  7m 44s] Epoch-44 [230/549] loss: 0.0000\n",
      "[  7m 44s] Epoch-44 [240/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [250/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [260/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [270/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [280/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [290/549] loss: 0.0000\n",
      "[  7m 45s] Epoch-44 [300/549] loss: 0.0000\n",
      "[  7m 46s] Epoch-44 [310/549] loss: 0.0000\n",
      "[  7m 46s] Epoch-44 [320/549] loss: 0.0000\n",
      "[  7m 46s] Epoch-44 [330/549] loss: 0.0000\n",
      "[  7m 46s] Epoch-44 [340/549] loss: 0.0000\n",
      "[  7m 46s] Epoch-44 [350/549] loss: 0.0000\n",
      "[  7m 47s] Epoch-44 [360/549] loss: 0.0000\n",
      "[  7m 47s] Epoch-44 [370/549] loss: 0.0000\n",
      "[  7m 47s] Epoch-44 [380/549] loss: 0.0001\n",
      "[  7m 47s] Epoch-44 [390/549] loss: 0.0001\n",
      "[  7m 47s] Epoch-44 [400/549] loss: 0.0001\n",
      "[  7m 47s] Epoch-44 [410/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [420/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [430/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [440/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [450/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [460/549] loss: 0.0001\n",
      "[  7m 48s] Epoch-44 [470/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [480/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [490/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [500/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [510/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [520/549] loss: 0.0001\n",
      "[  7m 49s] Epoch-44 [530/549] loss: 0.0001\n",
      "[  7m 50s] Epoch-44 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.25%\n",
      "[  7m 51s] Epoch-45 [10/549] loss: 0.0001\n",
      "[  7m 51s] Epoch-45 [20/549] loss: 0.0002\n",
      "[  7m 51s] Epoch-45 [30/549] loss: 0.0002\n",
      "[  7m 51s] Epoch-45 [40/549] loss: 0.0002\n",
      "[  7m 52s] Epoch-45 [50/549] loss: 0.0002\n",
      "[  7m 52s] Epoch-45 [60/549] loss: 0.0002\n",
      "[  7m 52s] Epoch-45 [70/549] loss: 0.0002\n",
      "[  7m 52s] Epoch-45 [80/549] loss: 0.0002\n",
      "[  7m 52s] Epoch-45 [90/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [100/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [110/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [120/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [130/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [140/549] loss: 0.0002\n",
      "[  7m 53s] Epoch-45 [150/549] loss: 0.0002\n",
      "[  7m 54s] Epoch-45 [160/549] loss: 0.0002\n",
      "[  7m 54s] Epoch-45 [170/549] loss: 0.0002\n",
      "[  7m 54s] Epoch-45 [180/549] loss: 0.0002\n",
      "[  7m 54s] Epoch-45 [190/549] loss: 0.0002\n",
      "[  7m 54s] Epoch-45 [200/549] loss: 0.0002\n",
      "[  7m 55s] Epoch-45 [210/549] loss: 0.0001\n",
      "[  7m 55s] Epoch-45 [220/549] loss: 0.0001\n",
      "[  7m 55s] Epoch-45 [230/549] loss: 0.0001\n",
      "[  7m 55s] Epoch-45 [240/549] loss: 0.0001\n",
      "[  7m 55s] Epoch-45 [250/549] loss: 0.0001\n",
      "[  7m 55s] Epoch-45 [260/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [270/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [280/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [290/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [300/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [310/549] loss: 0.0001\n",
      "[  7m 56s] Epoch-45 [320/549] loss: 0.0001\n",
      "[  7m 57s] Epoch-45 [330/549] loss: 0.0001\n",
      "[  7m 57s] Epoch-45 [340/549] loss: 0.0001\n",
      "[  7m 57s] Epoch-45 [350/549] loss: 0.0001\n",
      "[  7m 57s] Epoch-45 [360/549] loss: 0.0001\n",
      "[  7m 57s] Epoch-45 [370/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [380/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [390/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [400/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [410/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [420/549] loss: 0.0001\n",
      "[  7m 58s] Epoch-45 [430/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [440/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [450/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [460/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [470/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [480/549] loss: 0.0001\n",
      "[  7m 59s] Epoch-45 [490/549] loss: 0.0001\n",
      "[  8m  0s] Epoch-45 [500/549] loss: 0.0001\n",
      "[  8m  0s] Epoch-45 [510/549] loss: 0.0001\n",
      "[  8m  0s] Epoch-45 [520/549] loss: 0.0001\n",
      "[  8m  0s] Epoch-45 [530/549] loss: 0.0001\n",
      "[  8m  0s] Epoch-45 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.33%\n",
      "[  8m  2s] Epoch-46 [10/549] loss: 0.0000\n",
      "[  8m  2s] Epoch-46 [20/549] loss: 0.0000\n",
      "[  8m  2s] Epoch-46 [30/549] loss: 0.0000\n",
      "[  8m  2s] Epoch-46 [40/549] loss: 0.0000\n",
      "[  8m  2s] Epoch-46 [50/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [60/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [70/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [80/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [90/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [100/549] loss: 0.0000\n",
      "[  8m  3s] Epoch-46 [110/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [120/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [130/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [140/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [150/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [160/549] loss: 0.0000\n",
      "[  8m  4s] Epoch-46 [170/549] loss: 0.0000\n",
      "[  8m  5s] Epoch-46 [180/549] loss: 0.0000\n",
      "[  8m  5s] Epoch-46 [190/549] loss: 0.0000\n",
      "[  8m  5s] Epoch-46 [200/549] loss: 0.0000\n",
      "[  8m  5s] Epoch-46 [210/549] loss: 0.0000\n",
      "[  8m  5s] Epoch-46 [220/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [230/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [240/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [250/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [260/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [270/549] loss: 0.0000\n",
      "[  8m  6s] Epoch-46 [280/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [290/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [300/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [310/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [320/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [330/549] loss: 0.0000\n",
      "[  8m  7s] Epoch-46 [340/549] loss: 0.0000\n",
      "[  8m  8s] Epoch-46 [350/549] loss: 0.0000\n",
      "[  8m  8s] Epoch-46 [360/549] loss: 0.0000\n",
      "[  8m  8s] Epoch-46 [370/549] loss: 0.0000\n",
      "[  8m  8s] Epoch-46 [380/549] loss: 0.0000\n",
      "[  8m  8s] Epoch-46 [390/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [400/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [410/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [420/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [430/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [440/549] loss: 0.0000\n",
      "[  8m  9s] Epoch-46 [450/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [460/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [470/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [480/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [490/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [500/549] loss: 0.0000\n",
      "[  8m 10s] Epoch-46 [510/549] loss: 0.0000\n",
      "[  8m 11s] Epoch-46 [520/549] loss: 0.0000\n",
      "[  8m 11s] Epoch-46 [530/549] loss: 0.0000\n",
      "[  8m 11s] Epoch-46 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.77%\n",
      "[  8m 12s] Epoch-47 [10/549] loss: 0.0000\n",
      "[  8m 12s] Epoch-47 [20/549] loss: 0.0000\n",
      "[  8m 13s] Epoch-47 [30/549] loss: 0.0000\n",
      "[  8m 13s] Epoch-47 [40/549] loss: 0.0000\n",
      "[  8m 13s] Epoch-47 [50/549] loss: 0.0000\n",
      "[  8m 13s] Epoch-47 [60/549] loss: 0.0000\n",
      "[  8m 13s] Epoch-47 [70/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [80/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [90/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [100/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [110/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [120/549] loss: 0.0000\n",
      "[  8m 14s] Epoch-47 [130/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [140/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [150/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [160/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [170/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [180/549] loss: 0.0000\n",
      "[  8m 15s] Epoch-47 [190/549] loss: 0.0000\n",
      "[  8m 16s] Epoch-47 [200/549] loss: 0.0000\n",
      "[  8m 16s] Epoch-47 [210/549] loss: 0.0000\n",
      "[  8m 16s] Epoch-47 [220/549] loss: 0.0000\n",
      "[  8m 16s] Epoch-47 [230/549] loss: 0.0000\n",
      "[  8m 16s] Epoch-47 [240/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [250/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [260/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [270/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [280/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [290/549] loss: 0.0000\n",
      "[  8m 17s] Epoch-47 [300/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [310/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [320/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [330/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [340/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [350/549] loss: 0.0000\n",
      "[  8m 18s] Epoch-47 [360/549] loss: 0.0000\n",
      "[  8m 19s] Epoch-47 [370/549] loss: 0.0000\n",
      "[  8m 19s] Epoch-47 [380/549] loss: 0.0000\n",
      "[  8m 19s] Epoch-47 [390/549] loss: 0.0000\n",
      "[  8m 19s] Epoch-47 [400/549] loss: 0.0000\n",
      "[  8m 19s] Epoch-47 [410/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [420/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [430/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [440/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [450/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [460/549] loss: 0.0000\n",
      "[  8m 20s] Epoch-47 [470/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [480/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [490/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [500/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [510/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [520/549] loss: 0.0000\n",
      "[  8m 21s] Epoch-47 [530/549] loss: 0.0000\n",
      "[  8m 22s] Epoch-47 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.84%\n",
      "[  8m 23s] Epoch-48 [10/549] loss: 0.0000\n",
      "[  8m 23s] Epoch-48 [20/549] loss: 0.0000\n",
      "[  8m 23s] Epoch-48 [30/549] loss: 0.0000\n",
      "[  8m 23s] Epoch-48 [40/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [50/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [60/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [70/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [80/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [90/549] loss: 0.0000\n",
      "[  8m 24s] Epoch-48 [100/549] loss: 0.0000\n",
      "[  8m 25s] Epoch-48 [110/549] loss: 0.0000\n",
      "[  8m 25s] Epoch-48 [120/549] loss: 0.0000\n",
      "[  8m 25s] Epoch-48 [130/549] loss: 0.0000\n",
      "[  8m 25s] Epoch-48 [140/549] loss: 0.0000\n",
      "[  8m 25s] Epoch-48 [150/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [160/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [170/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [180/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [190/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [200/549] loss: 0.0000\n",
      "[  8m 26s] Epoch-48 [210/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [220/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [230/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [240/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [250/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [260/549] loss: 0.0000\n",
      "[  8m 27s] Epoch-48 [270/549] loss: 0.0000\n",
      "[  8m 28s] Epoch-48 [280/549] loss: 0.0000\n",
      "[  8m 28s] Epoch-48 [290/549] loss: 0.0000\n",
      "[  8m 28s] Epoch-48 [300/549] loss: 0.0000\n",
      "[  8m 28s] Epoch-48 [310/549] loss: 0.0000\n",
      "[  8m 28s] Epoch-48 [320/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [330/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [340/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [350/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [360/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [370/549] loss: 0.0000\n",
      "[  8m 29s] Epoch-48 [380/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [390/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [400/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [410/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [420/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [430/549] loss: 0.0000\n",
      "[  8m 30s] Epoch-48 [440/549] loss: 0.0000\n",
      "[  8m 31s] Epoch-48 [450/549] loss: 0.0000\n",
      "[  8m 31s] Epoch-48 [460/549] loss: 0.0000\n",
      "[  8m 31s] Epoch-48 [470/549] loss: 0.0000\n",
      "[  8m 31s] Epoch-48 [480/549] loss: 0.0000\n",
      "[  8m 31s] Epoch-48 [490/549] loss: 0.0000\n",
      "[  8m 32s] Epoch-48 [500/549] loss: 0.0000\n",
      "[  8m 32s] Epoch-48 [510/549] loss: 0.0000\n",
      "[  8m 32s] Epoch-48 [520/549] loss: 0.0000\n",
      "[  8m 32s] Epoch-48 [530/549] loss: 0.0000\n",
      "[  8m 32s] Epoch-48 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.96%\n",
      "[  8m 34s] Epoch-49 [10/549] loss: 0.0000\n",
      "[  8m 34s] Epoch-49 [20/549] loss: 0.0000\n",
      "[  8m 34s] Epoch-49 [30/549] loss: 0.0000\n",
      "[  8m 34s] Epoch-49 [40/549] loss: 0.0000\n",
      "[  8m 34s] Epoch-49 [50/549] loss: 0.0000\n",
      "[  8m 34s] Epoch-49 [60/549] loss: 0.0000\n",
      "[  8m 35s] Epoch-49 [70/549] loss: 0.0000\n",
      "[  8m 35s] Epoch-49 [80/549] loss: 0.0000\n",
      "[  8m 35s] Epoch-49 [90/549] loss: 0.0000\n",
      "[  8m 35s] Epoch-49 [100/549] loss: 0.0000\n",
      "[  8m 35s] Epoch-49 [110/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [120/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [130/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [140/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [150/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [160/549] loss: 0.0000\n",
      "[  8m 36s] Epoch-49 [170/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [180/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [190/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [200/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [210/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [220/549] loss: 0.0000\n",
      "[  8m 37s] Epoch-49 [230/549] loss: 0.0000\n",
      "[  8m 38s] Epoch-49 [240/549] loss: 0.0000\n",
      "[  8m 38s] Epoch-49 [250/549] loss: 0.0000\n",
      "[  8m 38s] Epoch-49 [260/549] loss: 0.0000\n",
      "[  8m 38s] Epoch-49 [270/549] loss: 0.0000\n",
      "[  8m 38s] Epoch-49 [280/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [290/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [300/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [310/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [320/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [330/549] loss: 0.0000\n",
      "[  8m 39s] Epoch-49 [340/549] loss: 0.0000\n",
      "[  8m 40s] Epoch-49 [350/549] loss: 0.0000\n",
      "[  8m 40s] Epoch-49 [360/549] loss: 0.0000\n",
      "[  8m 40s] Epoch-49 [370/549] loss: 0.0000\n",
      "[  8m 40s] Epoch-49 [380/549] loss: 0.0000\n",
      "[  8m 40s] Epoch-49 [390/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [400/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [410/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [420/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [430/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [440/549] loss: 0.0000\n",
      "[  8m 41s] Epoch-49 [450/549] loss: 0.0000\n",
      "[  8m 42s] Epoch-49 [460/549] loss: 0.0000\n",
      "[  8m 42s] Epoch-49 [470/549] loss: 0.0000\n",
      "[  8m 42s] Epoch-49 [480/549] loss: 0.0000\n",
      "[  8m 42s] Epoch-49 [490/549] loss: 0.0000\n",
      "[  8m 42s] Epoch-49 [500/549] loss: 0.0000\n",
      "[  8m 43s] Epoch-49 [510/549] loss: 0.0000\n",
      "[  8m 43s] Epoch-49 [520/549] loss: 0.0000\n",
      "[  8m 43s] Epoch-49 [530/549] loss: 0.0000\n",
      "[  8m 43s] Epoch-49 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.98%\n",
      "[  8m 44s] Epoch-50 [10/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [20/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [30/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [40/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [50/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [60/549] loss: 0.0000\n",
      "[  8m 45s] Epoch-50 [70/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [80/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [90/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [100/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [110/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [120/549] loss: 0.0000\n",
      "[  8m 46s] Epoch-50 [130/549] loss: 0.0000\n",
      "[  8m 47s] Epoch-50 [140/549] loss: 0.0000\n",
      "[  8m 47s] Epoch-50 [150/549] loss: 0.0000\n",
      "[  8m 47s] Epoch-50 [160/549] loss: 0.0000\n",
      "[  8m 47s] Epoch-50 [170/549] loss: 0.0000\n",
      "[  8m 47s] Epoch-50 [180/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [190/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [200/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [210/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [220/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [230/549] loss: 0.0000\n",
      "[  8m 48s] Epoch-50 [240/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [250/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [260/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [270/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [280/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [290/549] loss: 0.0000\n",
      "[  8m 49s] Epoch-50 [300/549] loss: 0.0000\n",
      "[  8m 50s] Epoch-50 [310/549] loss: 0.0000\n",
      "[  8m 50s] Epoch-50 [320/549] loss: 0.0000\n",
      "[  8m 50s] Epoch-50 [330/549] loss: 0.0000\n",
      "[  8m 50s] Epoch-50 [340/549] loss: 0.0000\n",
      "[  8m 50s] Epoch-50 [350/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [360/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [370/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [380/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [390/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [400/549] loss: 0.0000\n",
      "[  8m 51s] Epoch-50 [410/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [420/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [430/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [440/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [450/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [460/549] loss: 0.0000\n",
      "[  8m 52s] Epoch-50 [470/549] loss: 0.0000\n",
      "[  8m 53s] Epoch-50 [480/549] loss: 0.0000\n",
      "[  8m 53s] Epoch-50 [490/549] loss: 0.0000\n",
      "[  8m 53s] Epoch-50 [500/549] loss: 0.0000\n",
      "[  8m 53s] Epoch-50 [510/549] loss: 0.0000\n",
      "[  8m 53s] Epoch-50 [520/549] loss: 0.0000\n",
      "[  8m 54s] Epoch-50 [530/549] loss: 0.0000\n",
      "[  8m 54s] Epoch-50 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.98%\n",
      "[  8m 55s] Epoch-51 [10/549] loss: 0.0000\n",
      "[  8m 55s] Epoch-51 [20/549] loss: 0.0000\n",
      "[  8m 55s] Epoch-51 [30/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [40/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [50/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [60/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [70/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [80/549] loss: 0.0000\n",
      "[  8m 56s] Epoch-51 [90/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [100/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [110/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [120/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [130/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [140/549] loss: 0.0000\n",
      "[  8m 57s] Epoch-51 [150/549] loss: 0.0000\n",
      "[  8m 58s] Epoch-51 [160/549] loss: 0.0000\n",
      "[  8m 58s] Epoch-51 [170/549] loss: 0.0000\n",
      "[  8m 58s] Epoch-51 [180/549] loss: 0.0000\n",
      "[  8m 58s] Epoch-51 [190/549] loss: 0.0000\n",
      "[  8m 58s] Epoch-51 [200/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [210/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [220/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [230/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [240/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [250/549] loss: 0.0000\n",
      "[  8m 59s] Epoch-51 [260/549] loss: 0.0000\n",
      "[  9m  0s] Epoch-51 [270/549] loss: 0.0000\n",
      "[  9m  0s] Epoch-51 [280/549] loss: 0.0000\n",
      "[  9m  0s] Epoch-51 [290/549] loss: 0.0000\n",
      "[  9m  0s] Epoch-51 [300/549] loss: 0.0000\n",
      "[  9m  0s] Epoch-51 [310/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [320/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [330/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [340/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [350/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [360/549] loss: 0.0000\n",
      "[  9m  1s] Epoch-51 [370/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [380/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [390/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [400/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [410/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [420/549] loss: 0.0000\n",
      "[  9m  2s] Epoch-51 [430/549] loss: 0.0000\n",
      "[  9m  3s] Epoch-51 [440/549] loss: 0.0000\n",
      "[  9m  3s] Epoch-51 [450/549] loss: 0.0000\n",
      "[  9m  3s] Epoch-51 [460/549] loss: 0.0000\n",
      "[  9m  3s] Epoch-51 [470/549] loss: 0.0000\n",
      "[  9m  3s] Epoch-51 [480/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [490/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [500/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [510/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [520/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [530/549] loss: 0.0000\n",
      "[  9m  4s] Epoch-51 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.98%\n",
      "[  9m  6s] Epoch-52 [10/549] loss: 0.0000\n",
      "[  9m  6s] Epoch-52 [20/549] loss: 0.0000\n",
      "[  9m  6s] Epoch-52 [30/549] loss: 0.0000\n",
      "[  9m  6s] Epoch-52 [40/549] loss: 0.0000\n",
      "[  9m  6s] Epoch-52 [50/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [60/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [70/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [80/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [90/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [100/549] loss: 0.0000\n",
      "[  9m  7s] Epoch-52 [110/549] loss: 0.0000\n",
      "[  9m  8s] Epoch-52 [120/549] loss: 0.0000\n",
      "[  9m  8s] Epoch-52 [130/549] loss: 0.0000\n",
      "[  9m  8s] Epoch-52 [140/549] loss: 0.0000\n",
      "[  9m  8s] Epoch-52 [150/549] loss: 0.0000\n",
      "[  9m  8s] Epoch-52 [160/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [170/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [180/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [190/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [200/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [210/549] loss: 0.0000\n",
      "[  9m  9s] Epoch-52 [220/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [230/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [240/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [250/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [260/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [270/549] loss: 0.0000\n",
      "[  9m 10s] Epoch-52 [280/549] loss: 0.0000\n",
      "[  9m 11s] Epoch-52 [290/549] loss: 0.0000\n",
      "[  9m 11s] Epoch-52 [300/549] loss: 0.0000\n",
      "[  9m 11s] Epoch-52 [310/549] loss: 0.0000\n",
      "[  9m 11s] Epoch-52 [320/549] loss: 0.0000\n",
      "[  9m 11s] Epoch-52 [330/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [340/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [350/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [360/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [370/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [380/549] loss: 0.0000\n",
      "[  9m 12s] Epoch-52 [390/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [400/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [410/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [420/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [430/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [440/549] loss: 0.0000\n",
      "[  9m 13s] Epoch-52 [450/549] loss: 0.0000\n",
      "[  9m 14s] Epoch-52 [460/549] loss: 0.0000\n",
      "[  9m 14s] Epoch-52 [470/549] loss: 0.0000\n",
      "[  9m 14s] Epoch-52 [480/549] loss: 0.0000\n",
      "[  9m 14s] Epoch-52 [490/549] loss: 0.0000\n",
      "[  9m 14s] Epoch-52 [500/549] loss: 0.0000\n",
      "[  9m 15s] Epoch-52 [510/549] loss: 0.0000\n",
      "[  9m 15s] Epoch-52 [520/549] loss: 0.0000\n",
      "[  9m 15s] Epoch-52 [530/549] loss: 0.0000\n",
      "[  9m 15s] Epoch-52 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.96%\n",
      "[  9m 16s] Epoch-53 [10/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [20/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [30/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [40/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [50/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [60/549] loss: 0.0000\n",
      "[  9m 17s] Epoch-53 [70/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [80/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [90/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [100/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [110/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [120/549] loss: 0.0000\n",
      "[  9m 18s] Epoch-53 [130/549] loss: 0.0000\n",
      "[  9m 19s] Epoch-53 [140/549] loss: 0.0000\n",
      "[  9m 19s] Epoch-53 [150/549] loss: 0.0000\n",
      "[  9m 19s] Epoch-53 [160/549] loss: 0.0000\n",
      "[  9m 19s] Epoch-53 [170/549] loss: 0.0001\n",
      "[  9m 19s] Epoch-53 [180/549] loss: 0.0001\n",
      "[  9m 20s] Epoch-53 [190/549] loss: 0.0001\n",
      "[  9m 20s] Epoch-53 [200/549] loss: 0.0001\n",
      "[  9m 20s] Epoch-53 [210/549] loss: 0.0001\n",
      "[  9m 20s] Epoch-53 [220/549] loss: 0.0002\n",
      "[  9m 20s] Epoch-53 [230/549] loss: 0.0002\n",
      "[  9m 20s] Epoch-53 [240/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [250/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [260/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [270/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [280/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [290/549] loss: 0.0002\n",
      "[  9m 21s] Epoch-53 [300/549] loss: 0.0002\n",
      "[  9m 22s] Epoch-53 [310/549] loss: 0.0002\n",
      "[  9m 22s] Epoch-53 [320/549] loss: 0.0002\n",
      "[  9m 22s] Epoch-53 [330/549] loss: 0.0002\n",
      "[  9m 22s] Epoch-53 [340/549] loss: 0.0002\n",
      "[  9m 22s] Epoch-53 [350/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [360/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [370/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [380/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [390/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [400/549] loss: 0.0002\n",
      "[  9m 23s] Epoch-53 [410/549] loss: 0.0002\n",
      "[  9m 24s] Epoch-53 [420/549] loss: 0.0003\n",
      "[  9m 24s] Epoch-53 [430/549] loss: 0.0003\n",
      "[  9m 24s] Epoch-53 [440/549] loss: 0.0003\n",
      "[  9m 24s] Epoch-53 [450/549] loss: 0.0002\n",
      "[  9m 24s] Epoch-53 [460/549] loss: 0.0002\n",
      "[  9m 24s] Epoch-53 [470/549] loss: 0.0002\n",
      "[  9m 25s] Epoch-53 [480/549] loss: 0.0002\n",
      "[  9m 25s] Epoch-53 [490/549] loss: 0.0002\n",
      "[  9m 25s] Epoch-53 [500/549] loss: 0.0002\n",
      "[  9m 25s] Epoch-53 [510/549] loss: 0.0002\n",
      "[  9m 25s] Epoch-53 [520/549] loss: 0.0002\n",
      "[  9m 26s] Epoch-53 [530/549] loss: 0.0002\n",
      "[  9m 26s] Epoch-53 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.85%\n",
      "[  9m 27s] Epoch-54 [10/549] loss: 0.0001\n",
      "[  9m 27s] Epoch-54 [20/549] loss: 0.0001\n",
      "[  9m 27s] Epoch-54 [30/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [40/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [50/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [60/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [70/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [80/549] loss: 0.0001\n",
      "[  9m 28s] Epoch-54 [90/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [100/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [110/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [120/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [130/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [140/549] loss: 0.0001\n",
      "[  9m 29s] Epoch-54 [150/549] loss: 0.0001\n",
      "[  9m 30s] Epoch-54 [160/549] loss: 0.0001\n",
      "[  9m 30s] Epoch-54 [170/549] loss: 0.0001\n",
      "[  9m 30s] Epoch-54 [180/549] loss: 0.0001\n",
      "[  9m 30s] Epoch-54 [190/549] loss: 0.0001\n",
      "[  9m 30s] Epoch-54 [200/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [210/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [220/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [230/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [240/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [250/549] loss: 0.0001\n",
      "[  9m 31s] Epoch-54 [260/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [270/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [280/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [290/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [300/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [310/549] loss: 0.0001\n",
      "[  9m 32s] Epoch-54 [320/549] loss: 0.0001\n",
      "[  9m 33s] Epoch-54 [330/549] loss: 0.0001\n",
      "[  9m 33s] Epoch-54 [340/549] loss: 0.0001\n",
      "[  9m 33s] Epoch-54 [350/549] loss: 0.0001\n",
      "[  9m 33s] Epoch-54 [360/549] loss: 0.0001\n",
      "[  9m 33s] Epoch-54 [370/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [380/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [390/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [400/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [410/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [420/549] loss: 0.0001\n",
      "[  9m 34s] Epoch-54 [430/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [440/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [450/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [460/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [470/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [480/549] loss: 0.0001\n",
      "[  9m 35s] Epoch-54 [490/549] loss: 0.0001\n",
      "[  9m 36s] Epoch-54 [500/549] loss: 0.0001\n",
      "[  9m 36s] Epoch-54 [510/549] loss: 0.0001\n",
      "[  9m 36s] Epoch-54 [520/549] loss: 0.0001\n",
      "[  9m 36s] Epoch-54 [530/549] loss: 0.0001\n",
      "[  9m 36s] Epoch-54 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.45%\n",
      "[  9m 38s] Epoch-55 [10/549] loss: 0.0000\n",
      "[  9m 38s] Epoch-55 [20/549] loss: 0.0000\n",
      "[  9m 38s] Epoch-55 [30/549] loss: 0.0000\n",
      "[  9m 38s] Epoch-55 [40/549] loss: 0.0000\n",
      "[  9m 38s] Epoch-55 [50/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [60/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [70/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [80/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [90/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [100/549] loss: 0.0000\n",
      "[  9m 39s] Epoch-55 [110/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [120/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [130/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [140/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [150/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [160/549] loss: 0.0000\n",
      "[  9m 40s] Epoch-55 [170/549] loss: 0.0000\n",
      "[  9m 41s] Epoch-55 [180/549] loss: 0.0000\n",
      "[  9m 41s] Epoch-55 [190/549] loss: 0.0000\n",
      "[  9m 41s] Epoch-55 [200/549] loss: 0.0000\n",
      "[  9m 41s] Epoch-55 [210/549] loss: 0.0000\n",
      "[  9m 41s] Epoch-55 [220/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [230/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [240/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [250/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [260/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [270/549] loss: 0.0000\n",
      "[  9m 42s] Epoch-55 [280/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [290/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [300/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [310/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [320/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [330/549] loss: 0.0000\n",
      "[  9m 43s] Epoch-55 [340/549] loss: 0.0000\n",
      "[  9m 44s] Epoch-55 [350/549] loss: 0.0000\n",
      "[  9m 44s] Epoch-55 [360/549] loss: 0.0000\n",
      "[  9m 44s] Epoch-55 [370/549] loss: 0.0000\n",
      "[  9m 44s] Epoch-55 [380/549] loss: 0.0000\n",
      "[  9m 44s] Epoch-55 [390/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [400/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [410/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [420/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [430/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [440/549] loss: 0.0000\n",
      "[  9m 45s] Epoch-55 [450/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [460/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [470/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [480/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [490/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [500/549] loss: 0.0000\n",
      "[  9m 46s] Epoch-55 [510/549] loss: 0.0000\n",
      "[  9m 47s] Epoch-55 [520/549] loss: 0.0000\n",
      "[  9m 47s] Epoch-55 [530/549] loss: 0.0000\n",
      "[  9m 47s] Epoch-55 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.69%\n",
      "[  9m 48s] Epoch-56 [10/549] loss: 0.0000\n",
      "[  9m 48s] Epoch-56 [20/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [30/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [40/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [50/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [60/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [70/549] loss: 0.0000\n",
      "[  9m 49s] Epoch-56 [80/549] loss: 0.0000\n",
      "[  9m 50s] Epoch-56 [90/549] loss: 0.0000\n",
      "[  9m 50s] Epoch-56 [100/549] loss: 0.0000\n",
      "[  9m 50s] Epoch-56 [110/549] loss: 0.0000\n",
      "[  9m 50s] Epoch-56 [120/549] loss: 0.0000\n",
      "[  9m 50s] Epoch-56 [130/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [140/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [150/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [160/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [170/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [180/549] loss: 0.0000\n",
      "[  9m 51s] Epoch-56 [190/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [200/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [210/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [220/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [230/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [240/549] loss: 0.0000\n",
      "[  9m 52s] Epoch-56 [250/549] loss: 0.0000\n",
      "[  9m 53s] Epoch-56 [260/549] loss: 0.0000\n",
      "[  9m 53s] Epoch-56 [270/549] loss: 0.0000\n",
      "[  9m 53s] Epoch-56 [280/549] loss: 0.0000\n",
      "[  9m 53s] Epoch-56 [290/549] loss: 0.0000\n",
      "[  9m 53s] Epoch-56 [300/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [310/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [320/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [330/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [340/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [350/549] loss: 0.0000\n",
      "[  9m 54s] Epoch-56 [360/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [370/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [380/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [390/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [400/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [410/549] loss: 0.0000\n",
      "[  9m 55s] Epoch-56 [420/549] loss: 0.0000\n",
      "[  9m 56s] Epoch-56 [430/549] loss: 0.0000\n",
      "[  9m 56s] Epoch-56 [440/549] loss: 0.0000\n",
      "[  9m 56s] Epoch-56 [450/549] loss: 0.0000\n",
      "[  9m 56s] Epoch-56 [460/549] loss: 0.0000\n",
      "[  9m 56s] Epoch-56 [470/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [480/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [490/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [500/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [510/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [520/549] loss: 0.0000\n",
      "[  9m 57s] Epoch-56 [530/549] loss: 0.0000\n",
      "[  9m 58s] Epoch-56 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.82%\n",
      "[  9m 59s] Epoch-57 [10/549] loss: 0.0000\n",
      "[  9m 59s] Epoch-57 [20/549] loss: 0.0000\n",
      "[  9m 59s] Epoch-57 [30/549] loss: 0.0000\n",
      "[  9m 59s] Epoch-57 [40/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [50/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [60/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [70/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [80/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [90/549] loss: 0.0000\n",
      "[ 10m  0s] Epoch-57 [100/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [110/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [120/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [130/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [140/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [150/549] loss: 0.0000\n",
      "[ 10m  1s] Epoch-57 [160/549] loss: 0.0000\n",
      "[ 10m  2s] Epoch-57 [170/549] loss: 0.0000\n",
      "[ 10m  2s] Epoch-57 [180/549] loss: 0.0000\n",
      "[ 10m  2s] Epoch-57 [190/549] loss: 0.0000\n",
      "[ 10m  2s] Epoch-57 [200/549] loss: 0.0000\n",
      "[ 10m  2s] Epoch-57 [210/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [220/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [230/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [240/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [250/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [260/549] loss: 0.0000\n",
      "[ 10m  3s] Epoch-57 [270/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [280/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [290/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [300/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [310/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [320/549] loss: 0.0000\n",
      "[ 10m  4s] Epoch-57 [330/549] loss: 0.0000\n",
      "[ 10m  5s] Epoch-57 [340/549] loss: 0.0000\n",
      "[ 10m  5s] Epoch-57 [350/549] loss: 0.0000\n",
      "[ 10m  5s] Epoch-57 [360/549] loss: 0.0000\n",
      "[ 10m  5s] Epoch-57 [370/549] loss: 0.0000\n",
      "[ 10m  5s] Epoch-57 [380/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [390/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [400/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [410/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [420/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [430/549] loss: 0.0000\n",
      "[ 10m  6s] Epoch-57 [440/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [450/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [460/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [470/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [480/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [490/549] loss: 0.0000\n",
      "[ 10m  7s] Epoch-57 [500/549] loss: 0.0000\n",
      "[ 10m  8s] Epoch-57 [510/549] loss: 0.0000\n",
      "[ 10m  8s] Epoch-57 [520/549] loss: 0.0000\n",
      "[ 10m  8s] Epoch-57 [530/549] loss: 0.0000\n",
      "[ 10m  8s] Epoch-57 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.92%\n",
      "[ 10m  9s] Epoch-58 [10/549] loss: 0.0000\n",
      "[ 10m 10s] Epoch-58 [20/549] loss: 0.0000\n",
      "[ 10m 10s] Epoch-58 [30/549] loss: 0.0000\n",
      "[ 10m 10s] Epoch-58 [40/549] loss: 0.0000\n",
      "[ 10m 10s] Epoch-58 [50/549] loss: 0.0000\n",
      "[ 10m 10s] Epoch-58 [60/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [70/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [80/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [90/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [100/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [110/549] loss: 0.0000\n",
      "[ 10m 11s] Epoch-58 [120/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [130/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [140/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [150/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [160/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [170/549] loss: 0.0000\n",
      "[ 10m 12s] Epoch-58 [180/549] loss: 0.0000\n",
      "[ 10m 13s] Epoch-58 [190/549] loss: 0.0000\n",
      "[ 10m 13s] Epoch-58 [200/549] loss: 0.0000\n",
      "[ 10m 13s] Epoch-58 [210/549] loss: 0.0000\n",
      "[ 10m 13s] Epoch-58 [220/549] loss: 0.0000\n",
      "[ 10m 13s] Epoch-58 [230/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [240/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [250/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [260/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [270/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [280/549] loss: 0.0000\n",
      "[ 10m 14s] Epoch-58 [290/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [300/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [310/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [320/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [330/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [340/549] loss: 0.0000\n",
      "[ 10m 15s] Epoch-58 [350/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [360/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [370/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [380/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [390/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [400/549] loss: 0.0000\n",
      "[ 10m 16s] Epoch-58 [410/549] loss: 0.0000\n",
      "[ 10m 17s] Epoch-58 [420/549] loss: 0.0000\n",
      "[ 10m 17s] Epoch-58 [430/549] loss: 0.0000\n",
      "[ 10m 17s] Epoch-58 [440/549] loss: 0.0000\n",
      "[ 10m 17s] Epoch-58 [450/549] loss: 0.0000\n",
      "[ 10m 17s] Epoch-58 [460/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [470/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [480/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [490/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [500/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [510/549] loss: 0.0000\n",
      "[ 10m 18s] Epoch-58 [520/549] loss: 0.0000\n",
      "[ 10m 19s] Epoch-58 [530/549] loss: 0.0000\n",
      "[ 10m 19s] Epoch-58 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.84%\n",
      "[ 10m 20s] Epoch-59 [10/549] loss: 0.0000\n",
      "[ 10m 20s] Epoch-59 [20/549] loss: 0.0000\n",
      "[ 10m 20s] Epoch-59 [30/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [40/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [50/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [60/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [70/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [80/549] loss: 0.0000\n",
      "[ 10m 21s] Epoch-59 [90/549] loss: 0.0000\n",
      "[ 10m 22s] Epoch-59 [100/549] loss: 0.0000\n",
      "[ 10m 22s] Epoch-59 [110/549] loss: 0.0000\n",
      "[ 10m 22s] Epoch-59 [120/549] loss: 0.0000\n",
      "[ 10m 22s] Epoch-59 [130/549] loss: 0.0000\n",
      "[ 10m 22s] Epoch-59 [140/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [150/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [160/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [170/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [180/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [190/549] loss: 0.0000\n",
      "[ 10m 23s] Epoch-59 [200/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [210/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [220/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [230/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [240/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [250/549] loss: 0.0000\n",
      "[ 10m 24s] Epoch-59 [260/549] loss: 0.0000\n",
      "[ 10m 25s] Epoch-59 [270/549] loss: 0.0000\n",
      "[ 10m 25s] Epoch-59 [280/549] loss: 0.0000\n",
      "[ 10m 25s] Epoch-59 [290/549] loss: 0.0000\n",
      "[ 10m 25s] Epoch-59 [300/549] loss: 0.0000\n",
      "[ 10m 25s] Epoch-59 [310/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [320/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [330/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [340/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [350/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [360/549] loss: 0.0000\n",
      "[ 10m 26s] Epoch-59 [370/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [380/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [390/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [400/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [410/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [420/549] loss: 0.0000\n",
      "[ 10m 27s] Epoch-59 [430/549] loss: 0.0000\n",
      "[ 10m 28s] Epoch-59 [440/549] loss: 0.0000\n",
      "[ 10m 28s] Epoch-59 [450/549] loss: 0.0000\n",
      "[ 10m 28s] Epoch-59 [460/549] loss: 0.0000\n",
      "[ 10m 28s] Epoch-59 [470/549] loss: 0.0000\n",
      "[ 10m 28s] Epoch-59 [480/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [490/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [500/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [510/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [520/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [530/549] loss: 0.0000\n",
      "[ 10m 29s] Epoch-59 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.88%\n",
      "[ 10m 31s] Epoch-60 [10/549] loss: 0.0000\n",
      "[ 10m 31s] Epoch-60 [20/549] loss: 0.0000\n",
      "[ 10m 31s] Epoch-60 [30/549] loss: 0.0000\n",
      "[ 10m 31s] Epoch-60 [40/549] loss: 0.0000\n",
      "[ 10m 31s] Epoch-60 [50/549] loss: 0.0000\n",
      "[ 10m 32s] Epoch-60 [60/549] loss: 0.0000\n",
      "[ 10m 32s] Epoch-60 [70/549] loss: 0.0000\n",
      "[ 10m 32s] Epoch-60 [80/549] loss: 0.0000\n",
      "[ 10m 32s] Epoch-60 [90/549] loss: 0.0000\n",
      "[ 10m 32s] Epoch-60 [100/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [110/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [120/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [130/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [140/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [150/549] loss: 0.0000\n",
      "[ 10m 33s] Epoch-60 [160/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [170/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [180/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [190/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [200/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [210/549] loss: 0.0000\n",
      "[ 10m 34s] Epoch-60 [220/549] loss: 0.0000\n",
      "[ 10m 35s] Epoch-60 [230/549] loss: 0.0000\n",
      "[ 10m 35s] Epoch-60 [240/549] loss: 0.0000\n",
      "[ 10m 35s] Epoch-60 [250/549] loss: 0.0000\n",
      "[ 10m 35s] Epoch-60 [260/549] loss: 0.0000\n",
      "[ 10m 35s] Epoch-60 [270/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [280/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [290/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [300/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [310/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [320/549] loss: 0.0000\n",
      "[ 10m 36s] Epoch-60 [330/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [340/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [350/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [360/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [370/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [380/549] loss: 0.0000\n",
      "[ 10m 37s] Epoch-60 [390/549] loss: 0.0000\n",
      "[ 10m 38s] Epoch-60 [400/549] loss: 0.0000\n",
      "[ 10m 38s] Epoch-60 [410/549] loss: 0.0000\n",
      "[ 10m 38s] Epoch-60 [420/549] loss: 0.0000\n",
      "[ 10m 38s] Epoch-60 [430/549] loss: 0.0000\n",
      "[ 10m 38s] Epoch-60 [440/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [450/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [460/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [470/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [480/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [490/549] loss: 0.0000\n",
      "[ 10m 39s] Epoch-60 [500/549] loss: 0.0000\n",
      "[ 10m 40s] Epoch-60 [510/549] loss: 0.0000\n",
      "[ 10m 40s] Epoch-60 [520/549] loss: 0.0000\n",
      "[ 10m 40s] Epoch-60 [530/549] loss: 0.0000\n",
      "[ 10m 40s] Epoch-60 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.98%\n",
      "[ 10m 41s] Epoch-61 [10/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [20/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [30/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [40/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [50/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [60/549] loss: 0.0000\n",
      "[ 10m 42s] Epoch-61 [70/549] loss: 0.0000\n",
      "[ 10m 43s] Epoch-61 [80/549] loss: 0.0000\n",
      "[ 10m 43s] Epoch-61 [90/549] loss: 0.0000\n",
      "[ 10m 43s] Epoch-61 [100/549] loss: 0.0000\n",
      "[ 10m 43s] Epoch-61 [110/549] loss: 0.0000\n",
      "[ 10m 43s] Epoch-61 [120/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [130/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [140/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [150/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [160/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [170/549] loss: 0.0000\n",
      "[ 10m 44s] Epoch-61 [180/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [190/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [200/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [210/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [220/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [230/549] loss: 0.0000\n",
      "[ 10m 45s] Epoch-61 [240/549] loss: 0.0000\n",
      "[ 10m 46s] Epoch-61 [250/549] loss: 0.0000\n",
      "[ 10m 46s] Epoch-61 [260/549] loss: 0.0000\n",
      "[ 10m 46s] Epoch-61 [270/549] loss: 0.0000\n",
      "[ 10m 46s] Epoch-61 [280/549] loss: 0.0000\n",
      "[ 10m 46s] Epoch-61 [290/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [300/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [310/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [320/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [330/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [340/549] loss: 0.0000\n",
      "[ 10m 47s] Epoch-61 [350/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [360/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [370/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [380/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [390/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [400/549] loss: 0.0000\n",
      "[ 10m 48s] Epoch-61 [410/549] loss: 0.0000\n",
      "[ 10m 49s] Epoch-61 [420/549] loss: 0.0000\n",
      "[ 10m 49s] Epoch-61 [430/549] loss: 0.0000\n",
      "[ 10m 49s] Epoch-61 [440/549] loss: 0.0000\n",
      "[ 10m 49s] Epoch-61 [450/549] loss: 0.0000\n",
      "[ 10m 49s] Epoch-61 [460/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [470/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [480/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [490/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [500/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [510/549] loss: 0.0000\n",
      "[ 10m 50s] Epoch-61 [520/549] loss: 0.0000\n",
      "[ 10m 51s] Epoch-61 [530/549] loss: 0.0000\n",
      "[ 10m 51s] Epoch-61 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.88%\n",
      "[ 10m 52s] Epoch-62 [10/549] loss: 0.0000\n",
      "[ 10m 52s] Epoch-62 [20/549] loss: 0.0000\n",
      "[ 10m 52s] Epoch-62 [30/549] loss: 0.0000\n",
      "[ 10m 53s] Epoch-62 [40/549] loss: 0.0000\n",
      "[ 10m 53s] Epoch-62 [50/549] loss: 0.0000\n",
      "[ 10m 53s] Epoch-62 [60/549] loss: 0.0000\n",
      "[ 10m 53s] Epoch-62 [70/549] loss: 0.0000\n",
      "[ 10m 53s] Epoch-62 [80/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [90/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [100/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [110/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [120/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [130/549] loss: 0.0000\n",
      "[ 10m 54s] Epoch-62 [140/549] loss: 0.0000\n",
      "[ 10m 55s] Epoch-62 [150/549] loss: 0.0000\n",
      "[ 10m 55s] Epoch-62 [160/549] loss: 0.0000\n",
      "[ 10m 55s] Epoch-62 [170/549] loss: 0.0000\n",
      "[ 10m 55s] Epoch-62 [180/549] loss: 0.0000\n",
      "[ 10m 55s] Epoch-62 [190/549] loss: 0.0001\n",
      "[ 10m 55s] Epoch-62 [200/549] loss: 0.0001\n",
      "[ 10m 56s] Epoch-62 [210/549] loss: 0.0001\n",
      "[ 10m 56s] Epoch-62 [220/549] loss: 0.0001\n",
      "[ 10m 56s] Epoch-62 [230/549] loss: 0.0001\n",
      "[ 10m 56s] Epoch-62 [240/549] loss: 0.0002\n",
      "[ 10m 56s] Epoch-62 [250/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [260/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [270/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [280/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [290/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [300/549] loss: 0.0002\n",
      "[ 10m 57s] Epoch-62 [310/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [320/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [330/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [340/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [350/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [360/549] loss: 0.0002\n",
      "[ 10m 58s] Epoch-62 [370/549] loss: 0.0002\n",
      "[ 10m 59s] Epoch-62 [380/549] loss: 0.0002\n",
      "[ 10m 59s] Epoch-62 [390/549] loss: 0.0002\n",
      "[ 10m 59s] Epoch-62 [400/549] loss: 0.0002\n",
      "[ 10m 59s] Epoch-62 [410/549] loss: 0.0002\n",
      "[ 10m 59s] Epoch-62 [420/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [430/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [440/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [450/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [460/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [470/549] loss: 0.0002\n",
      "[ 11m  0s] Epoch-62 [480/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [490/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [500/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [510/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [520/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [530/549] loss: 0.0002\n",
      "[ 11m  1s] Epoch-62 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 95.79%\n",
      "[ 11m  3s] Epoch-63 [10/549] loss: 0.0002\n",
      "[ 11m  3s] Epoch-63 [20/549] loss: 0.0002\n",
      "[ 11m  3s] Epoch-63 [30/549] loss: 0.0002\n",
      "[ 11m  3s] Epoch-63 [40/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [50/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [60/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [70/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [80/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [90/549] loss: 0.0002\n",
      "[ 11m  4s] Epoch-63 [100/549] loss: 0.0002\n",
      "[ 11m  5s] Epoch-63 [110/549] loss: 0.0002\n",
      "[ 11m  5s] Epoch-63 [120/549] loss: 0.0001\n",
      "[ 11m  5s] Epoch-63 [130/549] loss: 0.0001\n",
      "[ 11m  5s] Epoch-63 [140/549] loss: 0.0001\n",
      "[ 11m  5s] Epoch-63 [150/549] loss: 0.0001\n",
      "[ 11m  5s] Epoch-63 [160/549] loss: 0.0001\n",
      "[ 11m  6s] Epoch-63 [170/549] loss: 0.0001\n",
      "[ 11m  6s] Epoch-63 [180/549] loss: 0.0001\n",
      "[ 11m  6s] Epoch-63 [190/549] loss: 0.0001\n",
      "[ 11m  6s] Epoch-63 [200/549] loss: 0.0001\n",
      "[ 11m  6s] Epoch-63 [210/549] loss: 0.0001\n",
      "[ 11m  7s] Epoch-63 [220/549] loss: 0.0001\n",
      "[ 11m  7s] Epoch-63 [230/549] loss: 0.0001\n",
      "[ 11m  7s] Epoch-63 [240/549] loss: 0.0001\n",
      "[ 11m  7s] Epoch-63 [250/549] loss: 0.0001\n",
      "[ 11m  7s] Epoch-63 [260/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [270/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [280/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [290/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [300/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [310/549] loss: 0.0001\n",
      "[ 11m  8s] Epoch-63 [320/549] loss: 0.0001\n",
      "[ 11m  9s] Epoch-63 [330/549] loss: 0.0001\n",
      "[ 11m  9s] Epoch-63 [340/549] loss: 0.0001\n",
      "[ 11m  9s] Epoch-63 [350/549] loss: 0.0001\n",
      "[ 11m  9s] Epoch-63 [360/549] loss: 0.0001\n",
      "[ 11m  9s] Epoch-63 [370/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [380/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [390/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [400/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [410/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [420/549] loss: 0.0001\n",
      "[ 11m 10s] Epoch-63 [430/549] loss: 0.0001\n",
      "[ 11m 11s] Epoch-63 [440/549] loss: 0.0001\n",
      "[ 11m 11s] Epoch-63 [450/549] loss: 0.0001\n",
      "[ 11m 11s] Epoch-63 [460/549] loss: 0.0001\n",
      "[ 11m 11s] Epoch-63 [470/549] loss: 0.0001\n",
      "[ 11m 11s] Epoch-63 [480/549] loss: 0.0001\n",
      "[ 11m 12s] Epoch-63 [490/549] loss: 0.0001\n",
      "[ 11m 12s] Epoch-63 [500/549] loss: 0.0001\n",
      "[ 11m 12s] Epoch-63 [510/549] loss: 0.0001\n",
      "[ 11m 12s] Epoch-63 [520/549] loss: 0.0001\n",
      "[ 11m 12s] Epoch-63 [530/549] loss: 0.0001\n",
      "[ 11m 13s] Epoch-63 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.35%\n",
      "[ 11m 14s] Epoch-64 [10/549] loss: 0.0000\n",
      "[ 11m 14s] Epoch-64 [20/549] loss: 0.0000\n",
      "[ 11m 14s] Epoch-64 [30/549] loss: 0.0000\n",
      "[ 11m 14s] Epoch-64 [40/549] loss: 0.0000\n",
      "[ 11m 15s] Epoch-64 [50/549] loss: 0.0000\n",
      "[ 11m 15s] Epoch-64 [60/549] loss: 0.0000\n",
      "[ 11m 15s] Epoch-64 [70/549] loss: 0.0000\n",
      "[ 11m 15s] Epoch-64 [80/549] loss: 0.0000\n",
      "[ 11m 15s] Epoch-64 [90/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [100/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [110/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [120/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [130/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [140/549] loss: 0.0000\n",
      "[ 11m 16s] Epoch-64 [150/549] loss: 0.0000\n",
      "[ 11m 17s] Epoch-64 [160/549] loss: 0.0000\n",
      "[ 11m 17s] Epoch-64 [170/549] loss: 0.0000\n",
      "[ 11m 17s] Epoch-64 [180/549] loss: 0.0000\n",
      "[ 11m 17s] Epoch-64 [190/549] loss: 0.0000\n",
      "[ 11m 17s] Epoch-64 [200/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [210/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [220/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [230/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [240/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [250/549] loss: 0.0000\n",
      "[ 11m 18s] Epoch-64 [260/549] loss: 0.0000\n",
      "[ 11m 19s] Epoch-64 [270/549] loss: 0.0000\n",
      "[ 11m 19s] Epoch-64 [280/549] loss: 0.0000\n",
      "[ 11m 19s] Epoch-64 [290/549] loss: 0.0000\n",
      "[ 11m 19s] Epoch-64 [300/549] loss: 0.0000\n",
      "[ 11m 19s] Epoch-64 [310/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [320/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [330/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [340/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [350/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [360/549] loss: 0.0000\n",
      "[ 11m 20s] Epoch-64 [370/549] loss: 0.0000\n",
      "[ 11m 21s] Epoch-64 [380/549] loss: 0.0000\n",
      "[ 11m 21s] Epoch-64 [390/549] loss: 0.0000\n",
      "[ 11m 21s] Epoch-64 [400/549] loss: 0.0000\n",
      "[ 11m 21s] Epoch-64 [410/549] loss: 0.0000\n",
      "[ 11m 21s] Epoch-64 [420/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [430/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [440/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [450/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [460/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [470/549] loss: 0.0000\n",
      "[ 11m 22s] Epoch-64 [480/549] loss: 0.0000\n",
      "[ 11m 23s] Epoch-64 [490/549] loss: 0.0000\n",
      "[ 11m 23s] Epoch-64 [500/549] loss: 0.0000\n",
      "[ 11m 23s] Epoch-64 [510/549] loss: 0.0000\n",
      "[ 11m 23s] Epoch-64 [520/549] loss: 0.0000\n",
      "[ 11m 23s] Epoch-64 [530/549] loss: 0.0000\n",
      "[ 11m 24s] Epoch-64 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.63%\n",
      "[ 11m 25s] Epoch-65 [10/549] loss: 0.0000\n",
      "[ 11m 25s] Epoch-65 [20/549] loss: 0.0000\n",
      "[ 11m 25s] Epoch-65 [30/549] loss: 0.0000\n",
      "[ 11m 25s] Epoch-65 [40/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [50/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [60/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [70/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [80/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [90/549] loss: 0.0000\n",
      "[ 11m 26s] Epoch-65 [100/549] loss: 0.0000\n",
      "[ 11m 27s] Epoch-65 [110/549] loss: 0.0000\n",
      "[ 11m 27s] Epoch-65 [120/549] loss: 0.0000\n",
      "[ 11m 27s] Epoch-65 [130/549] loss: 0.0000\n",
      "[ 11m 27s] Epoch-65 [140/549] loss: 0.0000\n",
      "[ 11m 27s] Epoch-65 [150/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [160/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [170/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [180/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [190/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [200/549] loss: 0.0000\n",
      "[ 11m 28s] Epoch-65 [210/549] loss: 0.0000\n",
      "[ 11m 29s] Epoch-65 [220/549] loss: 0.0000\n",
      "[ 11m 29s] Epoch-65 [230/549] loss: 0.0000\n",
      "[ 11m 29s] Epoch-65 [240/549] loss: 0.0000\n",
      "[ 11m 29s] Epoch-65 [250/549] loss: 0.0000\n",
      "[ 11m 29s] Epoch-65 [260/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [270/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [280/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [290/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [300/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [310/549] loss: 0.0000\n",
      "[ 11m 30s] Epoch-65 [320/549] loss: 0.0000\n",
      "[ 11m 31s] Epoch-65 [330/549] loss: 0.0000\n",
      "[ 11m 31s] Epoch-65 [340/549] loss: 0.0000\n",
      "[ 11m 31s] Epoch-65 [350/549] loss: 0.0000\n",
      "[ 11m 31s] Epoch-65 [360/549] loss: 0.0000\n",
      "[ 11m 31s] Epoch-65 [370/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [380/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [390/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [400/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [410/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [420/549] loss: 0.0000\n",
      "[ 11m 32s] Epoch-65 [430/549] loss: 0.0000\n",
      "[ 11m 33s] Epoch-65 [440/549] loss: 0.0000\n",
      "[ 11m 33s] Epoch-65 [450/549] loss: 0.0000\n",
      "[ 11m 33s] Epoch-65 [460/549] loss: 0.0000\n",
      "[ 11m 33s] Epoch-65 [470/549] loss: 0.0000\n",
      "[ 11m 33s] Epoch-65 [480/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [490/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [500/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [510/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [520/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [530/549] loss: 0.0000\n",
      "[ 11m 34s] Epoch-65 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.74%\n",
      "[ 11m 36s] Epoch-66 [10/549] loss: 0.0000\n",
      "[ 11m 36s] Epoch-66 [20/549] loss: 0.0000\n",
      "[ 11m 36s] Epoch-66 [30/549] loss: 0.0000\n",
      "[ 11m 36s] Epoch-66 [40/549] loss: 0.0000\n",
      "[ 11m 36s] Epoch-66 [50/549] loss: 0.0000\n",
      "[ 11m 37s] Epoch-66 [60/549] loss: 0.0000\n",
      "[ 11m 37s] Epoch-66 [70/549] loss: 0.0000\n",
      "[ 11m 37s] Epoch-66 [80/549] loss: 0.0000\n",
      "[ 11m 37s] Epoch-66 [90/549] loss: 0.0000\n",
      "[ 11m 37s] Epoch-66 [100/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [110/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [120/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [130/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [140/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [150/549] loss: 0.0000\n",
      "[ 11m 38s] Epoch-66 [160/549] loss: 0.0000\n",
      "[ 11m 39s] Epoch-66 [170/549] loss: 0.0000\n",
      "[ 11m 39s] Epoch-66 [180/549] loss: 0.0000\n",
      "[ 11m 39s] Epoch-66 [190/549] loss: 0.0000\n",
      "[ 11m 39s] Epoch-66 [200/549] loss: 0.0000\n",
      "[ 11m 39s] Epoch-66 [210/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [220/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [230/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [240/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [250/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [260/549] loss: 0.0000\n",
      "[ 11m 40s] Epoch-66 [270/549] loss: 0.0000\n",
      "[ 11m 41s] Epoch-66 [280/549] loss: 0.0000\n",
      "[ 11m 41s] Epoch-66 [290/549] loss: 0.0000\n",
      "[ 11m 41s] Epoch-66 [300/549] loss: 0.0000\n",
      "[ 11m 41s] Epoch-66 [310/549] loss: 0.0000\n",
      "[ 11m 41s] Epoch-66 [320/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [330/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [340/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [350/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [360/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [370/549] loss: 0.0000\n",
      "[ 11m 42s] Epoch-66 [380/549] loss: 0.0000\n",
      "[ 11m 43s] Epoch-66 [390/549] loss: 0.0000\n",
      "[ 11m 43s] Epoch-66 [400/549] loss: 0.0000\n",
      "[ 11m 43s] Epoch-66 [410/549] loss: 0.0000\n",
      "[ 11m 43s] Epoch-66 [420/549] loss: 0.0000\n",
      "[ 11m 43s] Epoch-66 [430/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [440/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [450/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [460/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [470/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [480/549] loss: 0.0000\n",
      "[ 11m 44s] Epoch-66 [490/549] loss: 0.0000\n",
      "[ 11m 45s] Epoch-66 [500/549] loss: 0.0000\n",
      "[ 11m 45s] Epoch-66 [510/549] loss: 0.0000\n",
      "[ 11m 45s] Epoch-66 [520/549] loss: 0.0000\n",
      "[ 11m 45s] Epoch-66 [530/549] loss: 0.0000\n",
      "[ 11m 45s] Epoch-66 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.73%\n",
      "[ 11m 47s] Epoch-67 [10/549] loss: 0.0000\n",
      "[ 11m 47s] Epoch-67 [20/549] loss: 0.0000\n",
      "[ 11m 47s] Epoch-67 [30/549] loss: 0.0000\n",
      "[ 11m 47s] Epoch-67 [40/549] loss: 0.0000\n",
      "[ 11m 47s] Epoch-67 [50/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [60/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [70/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [80/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [90/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [100/549] loss: 0.0000\n",
      "[ 11m 48s] Epoch-67 [110/549] loss: 0.0000\n",
      "[ 11m 49s] Epoch-67 [120/549] loss: 0.0000\n",
      "[ 11m 49s] Epoch-67 [130/549] loss: 0.0000\n",
      "[ 11m 49s] Epoch-67 [140/549] loss: 0.0000\n",
      "[ 11m 49s] Epoch-67 [150/549] loss: 0.0000\n",
      "[ 11m 49s] Epoch-67 [160/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [170/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [180/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [190/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [200/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [210/549] loss: 0.0000\n",
      "[ 11m 50s] Epoch-67 [220/549] loss: 0.0000\n",
      "[ 11m 51s] Epoch-67 [230/549] loss: 0.0000\n",
      "[ 11m 51s] Epoch-67 [240/549] loss: 0.0000\n",
      "[ 11m 51s] Epoch-67 [250/549] loss: 0.0000\n",
      "[ 11m 51s] Epoch-67 [260/549] loss: 0.0000\n",
      "[ 11m 51s] Epoch-67 [270/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [280/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [290/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [300/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [310/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [320/549] loss: 0.0000\n",
      "[ 11m 52s] Epoch-67 [330/549] loss: 0.0000\n",
      "[ 11m 53s] Epoch-67 [340/549] loss: 0.0000\n",
      "[ 11m 53s] Epoch-67 [350/549] loss: 0.0000\n",
      "[ 11m 53s] Epoch-67 [360/549] loss: 0.0000\n",
      "[ 11m 53s] Epoch-67 [370/549] loss: 0.0000\n",
      "[ 11m 53s] Epoch-67 [380/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [390/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [400/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [410/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [420/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [430/549] loss: 0.0000\n",
      "[ 11m 54s] Epoch-67 [440/549] loss: 0.0000\n",
      "[ 11m 55s] Epoch-67 [450/549] loss: 0.0000\n",
      "[ 11m 55s] Epoch-67 [460/549] loss: 0.0000\n",
      "[ 11m 55s] Epoch-67 [470/549] loss: 0.0000\n",
      "[ 11m 55s] Epoch-67 [480/549] loss: 0.0000\n",
      "[ 11m 55s] Epoch-67 [490/549] loss: 0.0000\n",
      "[ 11m 56s] Epoch-67 [500/549] loss: 0.0000\n",
      "[ 11m 56s] Epoch-67 [510/549] loss: 0.0000\n",
      "[ 11m 56s] Epoch-67 [520/549] loss: 0.0000\n",
      "[ 11m 56s] Epoch-67 [530/549] loss: 0.0000\n",
      "[ 11m 56s] Epoch-67 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.76%\n",
      "[ 11m 58s] Epoch-68 [10/549] loss: 0.0000\n",
      "[ 11m 58s] Epoch-68 [20/549] loss: 0.0000\n",
      "[ 11m 58s] Epoch-68 [30/549] loss: 0.0000\n",
      "[ 11m 58s] Epoch-68 [40/549] loss: 0.0000\n",
      "[ 11m 58s] Epoch-68 [50/549] loss: 0.0000\n",
      "[ 11m 58s] Epoch-68 [60/549] loss: 0.0000\n",
      "[ 11m 59s] Epoch-68 [70/549] loss: 0.0000\n",
      "[ 11m 59s] Epoch-68 [80/549] loss: 0.0000\n",
      "[ 11m 59s] Epoch-68 [90/549] loss: 0.0000\n",
      "[ 11m 59s] Epoch-68 [100/549] loss: 0.0000\n",
      "[ 11m 59s] Epoch-68 [110/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [120/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [130/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [140/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [150/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [160/549] loss: 0.0000\n",
      "[ 12m  0s] Epoch-68 [170/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [180/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [190/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [200/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [210/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [220/549] loss: 0.0000\n",
      "[ 12m  1s] Epoch-68 [230/549] loss: 0.0000\n",
      "[ 12m  2s] Epoch-68 [240/549] loss: 0.0000\n",
      "[ 12m  2s] Epoch-68 [250/549] loss: 0.0000\n",
      "[ 12m  2s] Epoch-68 [260/549] loss: 0.0000\n",
      "[ 12m  2s] Epoch-68 [270/549] loss: 0.0000\n",
      "[ 12m  2s] Epoch-68 [280/549] loss: 0.0000\n",
      "[ 12m  3s] Epoch-68 [290/549] loss: 0.0000\n",
      "[ 12m  3s] Epoch-68 [300/549] loss: 0.0000\n",
      "[ 12m  3s] Epoch-68 [310/549] loss: 0.0000\n",
      "[ 12m  3s] Epoch-68 [320/549] loss: 0.0000\n",
      "[ 12m  3s] Epoch-68 [330/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [340/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [350/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [360/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [370/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [380/549] loss: 0.0000\n",
      "[ 12m  4s] Epoch-68 [390/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [400/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [410/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [420/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [430/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [440/549] loss: 0.0000\n",
      "[ 12m  5s] Epoch-68 [450/549] loss: 0.0000\n",
      "[ 12m  6s] Epoch-68 [460/549] loss: 0.0000\n",
      "[ 12m  6s] Epoch-68 [470/549] loss: 0.0000\n",
      "[ 12m  6s] Epoch-68 [480/549] loss: 0.0000\n",
      "[ 12m  6s] Epoch-68 [490/549] loss: 0.0000\n",
      "[ 12m  6s] Epoch-68 [500/549] loss: 0.0000\n",
      "[ 12m  7s] Epoch-68 [510/549] loss: 0.0000\n",
      "[ 12m  7s] Epoch-68 [520/549] loss: 0.0000\n",
      "[ 12m  7s] Epoch-68 [530/549] loss: 0.0000\n",
      "[ 12m  7s] Epoch-68 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.85%\n",
      "[ 12m  8s] Epoch-69 [10/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [20/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [30/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [40/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [50/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [60/549] loss: 0.0000\n",
      "[ 12m  9s] Epoch-69 [70/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [80/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [90/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [100/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [110/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [120/549] loss: 0.0000\n",
      "[ 12m 10s] Epoch-69 [130/549] loss: 0.0000\n",
      "[ 12m 11s] Epoch-69 [140/549] loss: 0.0000\n",
      "[ 12m 11s] Epoch-69 [150/549] loss: 0.0000\n",
      "[ 12m 11s] Epoch-69 [160/549] loss: 0.0000\n",
      "[ 12m 11s] Epoch-69 [170/549] loss: 0.0000\n",
      "[ 12m 11s] Epoch-69 [180/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [190/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [200/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [210/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [220/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [230/549] loss: 0.0000\n",
      "[ 12m 12s] Epoch-69 [240/549] loss: 0.0000\n",
      "[ 12m 13s] Epoch-69 [250/549] loss: 0.0000\n",
      "[ 12m 13s] Epoch-69 [260/549] loss: 0.0000\n",
      "[ 12m 13s] Epoch-69 [270/549] loss: 0.0000\n",
      "[ 12m 13s] Epoch-69 [280/549] loss: 0.0000\n",
      "[ 12m 13s] Epoch-69 [290/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [300/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [310/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [320/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [330/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [340/549] loss: 0.0000\n",
      "[ 12m 14s] Epoch-69 [350/549] loss: 0.0000\n",
      "[ 12m 15s] Epoch-69 [360/549] loss: 0.0000\n",
      "[ 12m 15s] Epoch-69 [370/549] loss: 0.0000\n",
      "[ 12m 15s] Epoch-69 [380/549] loss: 0.0000\n",
      "[ 12m 15s] Epoch-69 [390/549] loss: 0.0000\n",
      "[ 12m 15s] Epoch-69 [400/549] loss: 0.0000\n",
      "[ 12m 16s] Epoch-69 [410/549] loss: 0.0000\n",
      "[ 12m 16s] Epoch-69 [420/549] loss: 0.0000\n",
      "[ 12m 16s] Epoch-69 [430/549] loss: 0.0000\n",
      "[ 12m 16s] Epoch-69 [440/549] loss: 0.0000\n",
      "[ 12m 16s] Epoch-69 [450/549] loss: 0.0000\n",
      "[ 12m 17s] Epoch-69 [460/549] loss: 0.0000\n",
      "[ 12m 17s] Epoch-69 [470/549] loss: 0.0000\n",
      "[ 12m 17s] Epoch-69 [480/549] loss: 0.0000\n",
      "[ 12m 17s] Epoch-69 [490/549] loss: 0.0000\n",
      "[ 12m 17s] Epoch-69 [500/549] loss: 0.0000\n",
      "[ 12m 18s] Epoch-69 [510/549] loss: 0.0000\n",
      "[ 12m 18s] Epoch-69 [520/549] loss: 0.0000\n",
      "[ 12m 18s] Epoch-69 [530/549] loss: 0.0000\n",
      "[ 12m 18s] Epoch-69 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.84%\n",
      "[ 12m 19s] Epoch-70 [10/549] loss: 0.0000\n",
      "[ 12m 20s] Epoch-70 [20/549] loss: 0.0000\n",
      "[ 12m 20s] Epoch-70 [30/549] loss: 0.0000\n",
      "[ 12m 20s] Epoch-70 [40/549] loss: 0.0000\n",
      "[ 12m 20s] Epoch-70 [50/549] loss: 0.0000\n",
      "[ 12m 20s] Epoch-70 [60/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [70/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [80/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [90/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [100/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [110/549] loss: 0.0000\n",
      "[ 12m 21s] Epoch-70 [120/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [130/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [140/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [150/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [160/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [170/549] loss: 0.0000\n",
      "[ 12m 22s] Epoch-70 [180/549] loss: 0.0000\n",
      "[ 12m 23s] Epoch-70 [190/549] loss: 0.0000\n",
      "[ 12m 23s] Epoch-70 [200/549] loss: 0.0000\n",
      "[ 12m 23s] Epoch-70 [210/549] loss: 0.0000\n",
      "[ 12m 23s] Epoch-70 [220/549] loss: 0.0000\n",
      "[ 12m 23s] Epoch-70 [230/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [240/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [250/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [260/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [270/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [280/549] loss: 0.0000\n",
      "[ 12m 24s] Epoch-70 [290/549] loss: 0.0000\n",
      "[ 12m 25s] Epoch-70 [300/549] loss: 0.0000\n",
      "[ 12m 25s] Epoch-70 [310/549] loss: 0.0000\n",
      "[ 12m 25s] Epoch-70 [320/549] loss: 0.0000\n",
      "[ 12m 25s] Epoch-70 [330/549] loss: 0.0000\n",
      "[ 12m 25s] Epoch-70 [340/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [350/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [360/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [370/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [380/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [390/549] loss: 0.0000\n",
      "[ 12m 26s] Epoch-70 [400/549] loss: 0.0000\n",
      "[ 12m 27s] Epoch-70 [410/549] loss: 0.0000\n",
      "[ 12m 27s] Epoch-70 [420/549] loss: 0.0000\n",
      "[ 12m 27s] Epoch-70 [430/549] loss: 0.0000\n",
      "[ 12m 27s] Epoch-70 [440/549] loss: 0.0000\n",
      "[ 12m 27s] Epoch-70 [450/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [460/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [470/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [480/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [490/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [500/549] loss: 0.0000\n",
      "[ 12m 28s] Epoch-70 [510/549] loss: 0.0000\n",
      "[ 12m 29s] Epoch-70 [520/549] loss: 0.0000\n",
      "[ 12m 29s] Epoch-70 [530/549] loss: 0.0000\n",
      "[ 12m 29s] Epoch-70 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.84%\n",
      "[ 12m 30s] Epoch-71 [10/549] loss: 0.0000\n",
      "[ 12m 30s] Epoch-71 [20/549] loss: 0.0000\n",
      "[ 12m 31s] Epoch-71 [30/549] loss: 0.0000\n",
      "[ 12m 31s] Epoch-71 [40/549] loss: 0.0000\n",
      "[ 12m 31s] Epoch-71 [50/549] loss: 0.0000\n",
      "[ 12m 31s] Epoch-71 [60/549] loss: 0.0000\n",
      "[ 12m 31s] Epoch-71 [70/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [80/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [90/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [100/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [110/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [120/549] loss: 0.0000\n",
      "[ 12m 32s] Epoch-71 [130/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [140/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [150/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [160/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [170/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [180/549] loss: 0.0000\n",
      "[ 12m 33s] Epoch-71 [190/549] loss: 0.0000\n",
      "[ 12m 34s] Epoch-71 [200/549] loss: 0.0000\n",
      "[ 12m 34s] Epoch-71 [210/549] loss: 0.0000\n",
      "[ 12m 34s] Epoch-71 [220/549] loss: 0.0000\n",
      "[ 12m 34s] Epoch-71 [230/549] loss: 0.0000\n",
      "[ 12m 34s] Epoch-71 [240/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [250/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [260/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [270/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [280/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [290/549] loss: 0.0000\n",
      "[ 12m 35s] Epoch-71 [300/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [310/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [320/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [330/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [340/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [350/549] loss: 0.0000\n",
      "[ 12m 36s] Epoch-71 [360/549] loss: 0.0000\n",
      "[ 12m 37s] Epoch-71 [370/549] loss: 0.0000\n",
      "[ 12m 37s] Epoch-71 [380/549] loss: 0.0000\n",
      "[ 12m 37s] Epoch-71 [390/549] loss: 0.0000\n",
      "[ 12m 37s] Epoch-71 [400/549] loss: 0.0000\n",
      "[ 12m 37s] Epoch-71 [410/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [420/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [430/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [440/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [450/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [460/549] loss: 0.0000\n",
      "[ 12m 38s] Epoch-71 [470/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [480/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [490/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [500/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [510/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [520/549] loss: 0.0000\n",
      "[ 12m 39s] Epoch-71 [530/549] loss: 0.0000\n",
      "[ 12m 40s] Epoch-71 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 94.82%\n",
      "[ 12m 41s] Epoch-72 [10/549] loss: 0.0003\n",
      "[ 12m 41s] Epoch-72 [20/549] loss: 0.0003\n",
      "[ 12m 41s] Epoch-72 [30/549] loss: 0.0004\n",
      "[ 12m 41s] Epoch-72 [40/549] loss: 0.0004\n",
      "[ 12m 42s] Epoch-72 [50/549] loss: 0.0004\n",
      "[ 12m 42s] Epoch-72 [60/549] loss: 0.0005\n",
      "[ 12m 42s] Epoch-72 [70/549] loss: 0.0005\n",
      "[ 12m 42s] Epoch-72 [80/549] loss: 0.0005\n",
      "[ 12m 42s] Epoch-72 [90/549] loss: 0.0005\n",
      "[ 12m 43s] Epoch-72 [100/549] loss: 0.0005\n",
      "[ 12m 43s] Epoch-72 [110/549] loss: 0.0004\n",
      "[ 12m 43s] Epoch-72 [120/549] loss: 0.0005\n",
      "[ 12m 43s] Epoch-72 [130/549] loss: 0.0004\n",
      "[ 12m 43s] Epoch-72 [140/549] loss: 0.0004\n",
      "[ 12m 43s] Epoch-72 [150/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [160/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [170/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [180/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [190/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [200/549] loss: 0.0004\n",
      "[ 12m 44s] Epoch-72 [210/549] loss: 0.0004\n",
      "[ 12m 45s] Epoch-72 [220/549] loss: 0.0004\n",
      "[ 12m 45s] Epoch-72 [230/549] loss: 0.0004\n",
      "[ 12m 45s] Epoch-72 [240/549] loss: 0.0004\n",
      "[ 12m 45s] Epoch-72 [250/549] loss: 0.0004\n",
      "[ 12m 45s] Epoch-72 [260/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [270/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [280/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [290/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [300/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [310/549] loss: 0.0004\n",
      "[ 12m 46s] Epoch-72 [320/549] loss: 0.0004\n",
      "[ 12m 47s] Epoch-72 [330/549] loss: 0.0004\n",
      "[ 12m 47s] Epoch-72 [340/549] loss: 0.0004\n",
      "[ 12m 47s] Epoch-72 [350/549] loss: 0.0004\n",
      "[ 12m 47s] Epoch-72 [360/549] loss: 0.0004\n",
      "[ 12m 47s] Epoch-72 [370/549] loss: 0.0003\n",
      "[ 12m 47s] Epoch-72 [380/549] loss: 0.0003\n",
      "[ 12m 48s] Epoch-72 [390/549] loss: 0.0003\n",
      "[ 12m 48s] Epoch-72 [400/549] loss: 0.0003\n",
      "[ 12m 48s] Epoch-72 [410/549] loss: 0.0003\n",
      "[ 12m 48s] Epoch-72 [420/549] loss: 0.0003\n",
      "[ 12m 48s] Epoch-72 [430/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [440/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [450/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [460/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [470/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [480/549] loss: 0.0003\n",
      "[ 12m 49s] Epoch-72 [490/549] loss: 0.0003\n",
      "[ 12m 50s] Epoch-72 [500/549] loss: 0.0003\n",
      "[ 12m 50s] Epoch-72 [510/549] loss: 0.0003\n",
      "[ 12m 50s] Epoch-72 [520/549] loss: 0.0003\n",
      "[ 12m 50s] Epoch-72 [530/549] loss: 0.0003\n",
      "[ 12m 50s] Epoch-72 [540/549] loss: 0.0003\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.05%\n",
      "[ 12m 52s] Epoch-73 [10/549] loss: 0.0001\n",
      "[ 12m 52s] Epoch-73 [20/549] loss: 0.0001\n",
      "[ 12m 52s] Epoch-73 [30/549] loss: 0.0001\n",
      "[ 12m 52s] Epoch-73 [40/549] loss: 0.0001\n",
      "[ 12m 52s] Epoch-73 [50/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [60/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [70/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [80/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [90/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [100/549] loss: 0.0001\n",
      "[ 12m 53s] Epoch-73 [110/549] loss: 0.0001\n",
      "[ 12m 54s] Epoch-73 [120/549] loss: 0.0001\n",
      "[ 12m 54s] Epoch-73 [130/549] loss: 0.0001\n",
      "[ 12m 54s] Epoch-73 [140/549] loss: 0.0001\n",
      "[ 12m 54s] Epoch-73 [150/549] loss: 0.0001\n",
      "[ 12m 54s] Epoch-73 [160/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [170/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [180/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [190/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [200/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [210/549] loss: 0.0001\n",
      "[ 12m 55s] Epoch-73 [220/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [230/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [240/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [250/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [260/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [270/549] loss: 0.0001\n",
      "[ 12m 56s] Epoch-73 [280/549] loss: 0.0001\n",
      "[ 12m 57s] Epoch-73 [290/549] loss: 0.0001\n",
      "[ 12m 57s] Epoch-73 [300/549] loss: 0.0001\n",
      "[ 12m 57s] Epoch-73 [310/549] loss: 0.0001\n",
      "[ 12m 57s] Epoch-73 [320/549] loss: 0.0001\n",
      "[ 12m 57s] Epoch-73 [330/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [340/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [350/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [360/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [370/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [380/549] loss: 0.0001\n",
      "[ 12m 58s] Epoch-73 [390/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [400/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [410/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [420/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [430/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [440/549] loss: 0.0001\n",
      "[ 12m 59s] Epoch-73 [450/549] loss: 0.0001\n",
      "[ 13m  0s] Epoch-73 [460/549] loss: 0.0001\n",
      "[ 13m  0s] Epoch-73 [470/549] loss: 0.0001\n",
      "[ 13m  0s] Epoch-73 [480/549] loss: 0.0001\n",
      "[ 13m  0s] Epoch-73 [490/549] loss: 0.0001\n",
      "[ 13m  0s] Epoch-73 [500/549] loss: 0.0001\n",
      "[ 13m  1s] Epoch-73 [510/549] loss: 0.0001\n",
      "[ 13m  1s] Epoch-73 [520/549] loss: 0.0001\n",
      "[ 13m  1s] Epoch-73 [530/549] loss: 0.0001\n",
      "[ 13m  1s] Epoch-73 [540/549] loss: 0.0001\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.34%\n",
      "[ 13m  2s] Epoch-74 [10/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [20/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [30/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [40/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [50/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [60/549] loss: 0.0000\n",
      "[ 13m  3s] Epoch-74 [70/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [80/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [90/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [100/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [110/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [120/549] loss: 0.0000\n",
      "[ 13m  4s] Epoch-74 [130/549] loss: 0.0000\n",
      "[ 13m  5s] Epoch-74 [140/549] loss: 0.0000\n",
      "[ 13m  5s] Epoch-74 [150/549] loss: 0.0000\n",
      "[ 13m  5s] Epoch-74 [160/549] loss: 0.0000\n",
      "[ 13m  5s] Epoch-74 [170/549] loss: 0.0000\n",
      "[ 13m  5s] Epoch-74 [180/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [190/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [200/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [210/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [220/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [230/549] loss: 0.0000\n",
      "[ 13m  6s] Epoch-74 [240/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [250/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [260/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [270/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [280/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [290/549] loss: 0.0000\n",
      "[ 13m  7s] Epoch-74 [300/549] loss: 0.0000\n",
      "[ 13m  8s] Epoch-74 [310/549] loss: 0.0000\n",
      "[ 13m  8s] Epoch-74 [320/549] loss: 0.0000\n",
      "[ 13m  8s] Epoch-74 [330/549] loss: 0.0000\n",
      "[ 13m  8s] Epoch-74 [340/549] loss: 0.0000\n",
      "[ 13m  8s] Epoch-74 [350/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [360/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [370/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [380/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [390/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [400/549] loss: 0.0000\n",
      "[ 13m  9s] Epoch-74 [410/549] loss: 0.0000\n",
      "[ 13m 10s] Epoch-74 [420/549] loss: 0.0000\n",
      "[ 13m 10s] Epoch-74 [430/549] loss: 0.0000\n",
      "[ 13m 10s] Epoch-74 [440/549] loss: 0.0000\n",
      "[ 13m 10s] Epoch-74 [450/549] loss: 0.0000\n",
      "[ 13m 10s] Epoch-74 [460/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [470/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [480/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [490/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [500/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [510/549] loss: 0.0000\n",
      "[ 13m 11s] Epoch-74 [520/549] loss: 0.0000\n",
      "[ 13m 12s] Epoch-74 [530/549] loss: 0.0000\n",
      "[ 13m 12s] Epoch-74 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.63%\n",
      "[ 13m 13s] Epoch-75 [10/549] loss: 0.0000\n",
      "[ 13m 13s] Epoch-75 [20/549] loss: 0.0000\n",
      "[ 13m 13s] Epoch-75 [30/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [40/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [50/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [60/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [70/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [80/549] loss: 0.0000\n",
      "[ 13m 14s] Epoch-75 [90/549] loss: 0.0000\n",
      "[ 13m 15s] Epoch-75 [100/549] loss: 0.0000\n",
      "[ 13m 15s] Epoch-75 [110/549] loss: 0.0000\n",
      "[ 13m 15s] Epoch-75 [120/549] loss: 0.0000\n",
      "[ 13m 15s] Epoch-75 [130/549] loss: 0.0000\n",
      "[ 13m 15s] Epoch-75 [140/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [150/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [160/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [170/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [180/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [190/549] loss: 0.0000\n",
      "[ 13m 16s] Epoch-75 [200/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [210/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [220/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [230/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [240/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [250/549] loss: 0.0000\n",
      "[ 13m 17s] Epoch-75 [260/549] loss: 0.0000\n",
      "[ 13m 18s] Epoch-75 [270/549] loss: 0.0000\n",
      "[ 13m 18s] Epoch-75 [280/549] loss: 0.0000\n",
      "[ 13m 18s] Epoch-75 [290/549] loss: 0.0000\n",
      "[ 13m 18s] Epoch-75 [300/549] loss: 0.0000\n",
      "[ 13m 18s] Epoch-75 [310/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [320/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [330/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [340/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [350/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [360/549] loss: 0.0000\n",
      "[ 13m 19s] Epoch-75 [370/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [380/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [390/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [400/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [410/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [420/549] loss: 0.0000\n",
      "[ 13m 20s] Epoch-75 [430/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [440/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [450/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [460/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [470/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [480/549] loss: 0.0000\n",
      "[ 13m 21s] Epoch-75 [490/549] loss: 0.0000\n",
      "[ 13m 22s] Epoch-75 [500/549] loss: 0.0000\n",
      "[ 13m 22s] Epoch-75 [510/549] loss: 0.0000\n",
      "[ 13m 22s] Epoch-75 [520/549] loss: 0.0000\n",
      "[ 13m 22s] Epoch-75 [530/549] loss: 0.0000\n",
      "[ 13m 22s] Epoch-75 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.70%\n",
      "[ 13m 24s] Epoch-76 [10/549] loss: 0.0000\n",
      "[ 13m 24s] Epoch-76 [20/549] loss: 0.0000\n",
      "[ 13m 24s] Epoch-76 [30/549] loss: 0.0000\n",
      "[ 13m 24s] Epoch-76 [40/549] loss: 0.0000\n",
      "[ 13m 24s] Epoch-76 [50/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [60/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [70/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [80/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [90/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [100/549] loss: 0.0000\n",
      "[ 13m 25s] Epoch-76 [110/549] loss: 0.0000\n",
      "[ 13m 26s] Epoch-76 [120/549] loss: 0.0000\n",
      "[ 13m 26s] Epoch-76 [130/549] loss: 0.0000\n",
      "[ 13m 26s] Epoch-76 [140/549] loss: 0.0000\n",
      "[ 13m 26s] Epoch-76 [150/549] loss: 0.0000\n",
      "[ 13m 26s] Epoch-76 [160/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [170/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [180/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [190/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [200/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [210/549] loss: 0.0000\n",
      "[ 13m 27s] Epoch-76 [220/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [230/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [240/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [250/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [260/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [270/549] loss: 0.0000\n",
      "[ 13m 28s] Epoch-76 [280/549] loss: 0.0000\n",
      "[ 13m 29s] Epoch-76 [290/549] loss: 0.0000\n",
      "[ 13m 29s] Epoch-76 [300/549] loss: 0.0000\n",
      "[ 13m 29s] Epoch-76 [310/549] loss: 0.0000\n",
      "[ 13m 29s] Epoch-76 [320/549] loss: 0.0000\n",
      "[ 13m 29s] Epoch-76 [330/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [340/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [350/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [360/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [370/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [380/549] loss: 0.0000\n",
      "[ 13m 30s] Epoch-76 [390/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [400/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [410/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [420/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [430/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [440/549] loss: 0.0000\n",
      "[ 13m 31s] Epoch-76 [450/549] loss: 0.0000\n",
      "[ 13m 32s] Epoch-76 [460/549] loss: 0.0000\n",
      "[ 13m 32s] Epoch-76 [470/549] loss: 0.0000\n",
      "[ 13m 32s] Epoch-76 [480/549] loss: 0.0000\n",
      "[ 13m 32s] Epoch-76 [490/549] loss: 0.0000\n",
      "[ 13m 32s] Epoch-76 [500/549] loss: 0.0000\n",
      "[ 13m 33s] Epoch-76 [510/549] loss: 0.0000\n",
      "[ 13m 33s] Epoch-76 [520/549] loss: 0.0000\n",
      "[ 13m 33s] Epoch-76 [530/549] loss: 0.0000\n",
      "[ 13m 33s] Epoch-76 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.69%\n",
      "[ 13m 34s] Epoch-77 [10/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [20/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [30/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [40/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [50/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [60/549] loss: 0.0000\n",
      "[ 13m 35s] Epoch-77 [70/549] loss: 0.0000\n",
      "[ 13m 36s] Epoch-77 [80/549] loss: 0.0000\n",
      "[ 13m 36s] Epoch-77 [90/549] loss: 0.0000\n",
      "[ 13m 36s] Epoch-77 [100/549] loss: 0.0000\n",
      "[ 13m 36s] Epoch-77 [110/549] loss: 0.0000\n",
      "[ 13m 36s] Epoch-77 [120/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [130/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [140/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [150/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [160/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [170/549] loss: 0.0000\n",
      "[ 13m 37s] Epoch-77 [180/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [190/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [200/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [210/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [220/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [230/549] loss: 0.0000\n",
      "[ 13m 38s] Epoch-77 [240/549] loss: 0.0000\n",
      "[ 13m 39s] Epoch-77 [250/549] loss: 0.0000\n",
      "[ 13m 39s] Epoch-77 [260/549] loss: 0.0000\n",
      "[ 13m 39s] Epoch-77 [270/549] loss: 0.0000\n",
      "[ 13m 39s] Epoch-77 [280/549] loss: 0.0000\n",
      "[ 13m 39s] Epoch-77 [290/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [300/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [310/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [320/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [330/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [340/549] loss: 0.0000\n",
      "[ 13m 40s] Epoch-77 [350/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [360/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [370/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [380/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [390/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [400/549] loss: 0.0000\n",
      "[ 13m 41s] Epoch-77 [410/549] loss: 0.0000\n",
      "[ 13m 42s] Epoch-77 [420/549] loss: 0.0000\n",
      "[ 13m 42s] Epoch-77 [430/549] loss: 0.0000\n",
      "[ 13m 42s] Epoch-77 [440/549] loss: 0.0000\n",
      "[ 13m 42s] Epoch-77 [450/549] loss: 0.0000\n",
      "[ 13m 42s] Epoch-77 [460/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [470/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [480/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [490/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [500/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [510/549] loss: 0.0000\n",
      "[ 13m 43s] Epoch-77 [520/549] loss: 0.0000\n",
      "[ 13m 44s] Epoch-77 [530/549] loss: 0.0000\n",
      "[ 13m 44s] Epoch-77 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.77%\n",
      "[ 13m 45s] Epoch-78 [10/549] loss: 0.0000\n",
      "[ 13m 45s] Epoch-78 [20/549] loss: 0.0000\n",
      "[ 13m 45s] Epoch-78 [30/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [40/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [50/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [60/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [70/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [80/549] loss: 0.0000\n",
      "[ 13m 46s] Epoch-78 [90/549] loss: 0.0000\n",
      "[ 13m 47s] Epoch-78 [100/549] loss: 0.0000\n",
      "[ 13m 47s] Epoch-78 [110/549] loss: 0.0000\n",
      "[ 13m 47s] Epoch-78 [120/549] loss: 0.0000\n",
      "[ 13m 47s] Epoch-78 [130/549] loss: 0.0000\n",
      "[ 13m 47s] Epoch-78 [140/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [150/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [160/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [170/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [180/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [190/549] loss: 0.0000\n",
      "[ 13m 48s] Epoch-78 [200/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [210/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [220/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [230/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [240/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [250/549] loss: 0.0000\n",
      "[ 13m 49s] Epoch-78 [260/549] loss: 0.0000\n",
      "[ 13m 50s] Epoch-78 [270/549] loss: 0.0000\n",
      "[ 13m 50s] Epoch-78 [280/549] loss: 0.0000\n",
      "[ 13m 50s] Epoch-78 [290/549] loss: 0.0000\n",
      "[ 13m 50s] Epoch-78 [300/549] loss: 0.0000\n",
      "[ 13m 50s] Epoch-78 [310/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [320/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [330/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [340/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [350/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [360/549] loss: 0.0000\n",
      "[ 13m 51s] Epoch-78 [370/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [380/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [390/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [400/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [410/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [420/549] loss: 0.0000\n",
      "[ 13m 52s] Epoch-78 [430/549] loss: 0.0000\n",
      "[ 13m 53s] Epoch-78 [440/549] loss: 0.0000\n",
      "[ 13m 53s] Epoch-78 [450/549] loss: 0.0000\n",
      "[ 13m 53s] Epoch-78 [460/549] loss: 0.0000\n",
      "[ 13m 53s] Epoch-78 [470/549] loss: 0.0000\n",
      "[ 13m 53s] Epoch-78 [480/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [490/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [500/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [510/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [520/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [530/549] loss: 0.0000\n",
      "[ 13m 54s] Epoch-78 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.75%\n",
      "[ 13m 56s] Epoch-79 [10/549] loss: 0.0000\n",
      "[ 13m 56s] Epoch-79 [20/549] loss: 0.0000\n",
      "[ 13m 56s] Epoch-79 [30/549] loss: 0.0000\n",
      "[ 13m 56s] Epoch-79 [40/549] loss: 0.0000\n",
      "[ 13m 56s] Epoch-79 [50/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [60/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [70/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [80/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [90/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [100/549] loss: 0.0000\n",
      "[ 13m 57s] Epoch-79 [110/549] loss: 0.0000\n",
      "[ 13m 58s] Epoch-79 [120/549] loss: 0.0000\n",
      "[ 13m 58s] Epoch-79 [130/549] loss: 0.0000\n",
      "[ 13m 58s] Epoch-79 [140/549] loss: 0.0000\n",
      "[ 13m 58s] Epoch-79 [150/549] loss: 0.0000\n",
      "[ 13m 58s] Epoch-79 [160/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [170/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [180/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [190/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [200/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [210/549] loss: 0.0000\n",
      "[ 13m 59s] Epoch-79 [220/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [230/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [240/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [250/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [260/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [270/549] loss: 0.0000\n",
      "[ 14m  0s] Epoch-79 [280/549] loss: 0.0000\n",
      "[ 14m  1s] Epoch-79 [290/549] loss: 0.0000\n",
      "[ 14m  1s] Epoch-79 [300/549] loss: 0.0000\n",
      "[ 14m  1s] Epoch-79 [310/549] loss: 0.0000\n",
      "[ 14m  1s] Epoch-79 [320/549] loss: 0.0000\n",
      "[ 14m  1s] Epoch-79 [330/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [340/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [350/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [360/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [370/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [380/549] loss: 0.0000\n",
      "[ 14m  2s] Epoch-79 [390/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [400/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [410/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [420/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [430/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [440/549] loss: 0.0000\n",
      "[ 14m  3s] Epoch-79 [450/549] loss: 0.0000\n",
      "[ 14m  4s] Epoch-79 [460/549] loss: 0.0000\n",
      "[ 14m  4s] Epoch-79 [470/549] loss: 0.0000\n",
      "[ 14m  4s] Epoch-79 [480/549] loss: 0.0000\n",
      "[ 14m  4s] Epoch-79 [490/549] loss: 0.0000\n",
      "[ 14m  4s] Epoch-79 [500/549] loss: 0.0000\n",
      "[ 14m  5s] Epoch-79 [510/549] loss: 0.0000\n",
      "[ 14m  5s] Epoch-79 [520/549] loss: 0.0000\n",
      "[ 14m  5s] Epoch-79 [530/549] loss: 0.0000\n",
      "[ 14m  5s] Epoch-79 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.74%\n",
      "[ 14m  6s] Epoch-80 [10/549] loss: 0.0000\n",
      "[ 14m  6s] Epoch-80 [20/549] loss: 0.0000\n",
      "[ 14m  7s] Epoch-80 [30/549] loss: 0.0000\n",
      "[ 14m  7s] Epoch-80 [40/549] loss: 0.0000\n",
      "[ 14m  7s] Epoch-80 [50/549] loss: 0.0000\n",
      "[ 14m  7s] Epoch-80 [60/549] loss: 0.0000\n",
      "[ 14m  7s] Epoch-80 [70/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [80/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [90/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [100/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [110/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [120/549] loss: 0.0000\n",
      "[ 14m  8s] Epoch-80 [130/549] loss: 0.0000\n",
      "[ 14m  9s] Epoch-80 [140/549] loss: 0.0000\n",
      "[ 14m  9s] Epoch-80 [150/549] loss: 0.0000\n",
      "[ 14m  9s] Epoch-80 [160/549] loss: 0.0000\n",
      "[ 14m  9s] Epoch-80 [170/549] loss: 0.0000\n",
      "[ 14m  9s] Epoch-80 [180/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [190/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [200/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [210/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [220/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [230/549] loss: 0.0000\n",
      "[ 14m 10s] Epoch-80 [240/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [250/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [260/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [270/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [280/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [290/549] loss: 0.0000\n",
      "[ 14m 11s] Epoch-80 [300/549] loss: 0.0000\n",
      "[ 14m 12s] Epoch-80 [310/549] loss: 0.0000\n",
      "[ 14m 12s] Epoch-80 [320/549] loss: 0.0000\n",
      "[ 14m 12s] Epoch-80 [330/549] loss: 0.0000\n",
      "[ 14m 12s] Epoch-80 [340/549] loss: 0.0000\n",
      "[ 14m 12s] Epoch-80 [350/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [360/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [370/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [380/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [390/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [400/549] loss: 0.0000\n",
      "[ 14m 13s] Epoch-80 [410/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [420/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [430/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [440/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [450/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [460/549] loss: 0.0000\n",
      "[ 14m 14s] Epoch-80 [470/549] loss: 0.0000\n",
      "[ 14m 15s] Epoch-80 [480/549] loss: 0.0000\n",
      "[ 14m 15s] Epoch-80 [490/549] loss: 0.0000\n",
      "[ 14m 15s] Epoch-80 [500/549] loss: 0.0000\n",
      "[ 14m 15s] Epoch-80 [510/549] loss: 0.0000\n",
      "[ 14m 15s] Epoch-80 [520/549] loss: 0.0000\n",
      "[ 14m 16s] Epoch-80 [530/549] loss: 0.0000\n",
      "[ 14m 16s] Epoch-80 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.71%\n",
      "[ 14m 17s] Epoch-81 [10/549] loss: 0.0000\n",
      "[ 14m 17s] Epoch-81 [20/549] loss: 0.0000\n",
      "[ 14m 17s] Epoch-81 [30/549] loss: 0.0000\n",
      "[ 14m 17s] Epoch-81 [40/549] loss: 0.0000\n",
      "[ 14m 18s] Epoch-81 [50/549] loss: 0.0000\n",
      "[ 14m 18s] Epoch-81 [60/549] loss: 0.0000\n",
      "[ 14m 18s] Epoch-81 [70/549] loss: 0.0000\n",
      "[ 14m 18s] Epoch-81 [80/549] loss: 0.0000\n",
      "[ 14m 18s] Epoch-81 [90/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [100/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [110/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [120/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [130/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [140/549] loss: 0.0000\n",
      "[ 14m 19s] Epoch-81 [150/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [160/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [170/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [180/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [190/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [200/549] loss: 0.0000\n",
      "[ 14m 20s] Epoch-81 [210/549] loss: 0.0000\n",
      "[ 14m 21s] Epoch-81 [220/549] loss: 0.0000\n",
      "[ 14m 21s] Epoch-81 [230/549] loss: 0.0000\n",
      "[ 14m 21s] Epoch-81 [240/549] loss: 0.0000\n",
      "[ 14m 21s] Epoch-81 [250/549] loss: 0.0000\n",
      "[ 14m 21s] Epoch-81 [260/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [270/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [280/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [290/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [300/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [310/549] loss: 0.0000\n",
      "[ 14m 22s] Epoch-81 [320/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [330/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [340/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [350/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [360/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [370/549] loss: 0.0000\n",
      "[ 14m 23s] Epoch-81 [380/549] loss: 0.0000\n",
      "[ 14m 24s] Epoch-81 [390/549] loss: 0.0001\n",
      "[ 14m 24s] Epoch-81 [400/549] loss: 0.0001\n",
      "[ 14m 24s] Epoch-81 [410/549] loss: 0.0001\n",
      "[ 14m 24s] Epoch-81 [420/549] loss: 0.0001\n",
      "[ 14m 24s] Epoch-81 [430/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [440/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [450/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [460/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [470/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [480/549] loss: 0.0001\n",
      "[ 14m 25s] Epoch-81 [490/549] loss: 0.0001\n",
      "[ 14m 26s] Epoch-81 [500/549] loss: 0.0001\n",
      "[ 14m 26s] Epoch-81 [510/549] loss: 0.0001\n",
      "[ 14m 26s] Epoch-81 [520/549] loss: 0.0001\n",
      "[ 14m 26s] Epoch-81 [530/549] loss: 0.0002\n",
      "[ 14m 26s] Epoch-81 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 94.74%\n",
      "[ 14m 28s] Epoch-82 [10/549] loss: 0.0003\n",
      "[ 14m 28s] Epoch-82 [20/549] loss: 0.0003\n",
      "[ 14m 28s] Epoch-82 [30/549] loss: 0.0003\n",
      "[ 14m 28s] Epoch-82 [40/549] loss: 0.0003\n",
      "[ 14m 28s] Epoch-82 [50/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [60/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [70/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [80/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [90/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [100/549] loss: 0.0003\n",
      "[ 14m 29s] Epoch-82 [110/549] loss: 0.0003\n",
      "[ 14m 30s] Epoch-82 [120/549] loss: 0.0003\n",
      "[ 14m 30s] Epoch-82 [130/549] loss: 0.0002\n",
      "[ 14m 30s] Epoch-82 [140/549] loss: 0.0002\n",
      "[ 14m 30s] Epoch-82 [150/549] loss: 0.0002\n",
      "[ 14m 30s] Epoch-82 [160/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [170/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [180/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [190/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [200/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [210/549] loss: 0.0002\n",
      "[ 14m 31s] Epoch-82 [220/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [230/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [240/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [250/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [260/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [270/549] loss: 0.0002\n",
      "[ 14m 32s] Epoch-82 [280/549] loss: 0.0002\n",
      "[ 14m 33s] Epoch-82 [290/549] loss: 0.0002\n",
      "[ 14m 33s] Epoch-82 [300/549] loss: 0.0002\n",
      "[ 14m 33s] Epoch-82 [310/549] loss: 0.0002\n",
      "[ 14m 33s] Epoch-82 [320/549] loss: 0.0002\n",
      "[ 14m 33s] Epoch-82 [330/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [340/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [350/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [360/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [370/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [380/549] loss: 0.0002\n",
      "[ 14m 34s] Epoch-82 [390/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [400/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [410/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [420/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [430/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [440/549] loss: 0.0002\n",
      "[ 14m 35s] Epoch-82 [450/549] loss: 0.0002\n",
      "[ 14m 36s] Epoch-82 [460/549] loss: 0.0002\n",
      "[ 14m 36s] Epoch-82 [470/549] loss: 0.0002\n",
      "[ 14m 36s] Epoch-82 [480/549] loss: 0.0002\n",
      "[ 14m 36s] Epoch-82 [490/549] loss: 0.0002\n",
      "[ 14m 36s] Epoch-82 [500/549] loss: 0.0002\n",
      "[ 14m 37s] Epoch-82 [510/549] loss: 0.0002\n",
      "[ 14m 37s] Epoch-82 [520/549] loss: 0.0002\n",
      "[ 14m 37s] Epoch-82 [530/549] loss: 0.0002\n",
      "[ 14m 37s] Epoch-82 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.15%\n",
      "[ 14m 38s] Epoch-83 [10/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [20/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [30/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [40/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [50/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [60/549] loss: 0.0000\n",
      "[ 14m 39s] Epoch-83 [70/549] loss: 0.0000\n",
      "[ 14m 40s] Epoch-83 [80/549] loss: 0.0000\n",
      "[ 14m 40s] Epoch-83 [90/549] loss: 0.0000\n",
      "[ 14m 40s] Epoch-83 [100/549] loss: 0.0000\n",
      "[ 14m 40s] Epoch-83 [110/549] loss: 0.0000\n",
      "[ 14m 40s] Epoch-83 [120/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [130/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [140/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [150/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [160/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [170/549] loss: 0.0000\n",
      "[ 14m 41s] Epoch-83 [180/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [190/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [200/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [210/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [220/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [230/549] loss: 0.0000\n",
      "[ 14m 42s] Epoch-83 [240/549] loss: 0.0000\n",
      "[ 14m 43s] Epoch-83 [250/549] loss: 0.0000\n",
      "[ 14m 43s] Epoch-83 [260/549] loss: 0.0000\n",
      "[ 14m 43s] Epoch-83 [270/549] loss: 0.0000\n",
      "[ 14m 43s] Epoch-83 [280/549] loss: 0.0000\n",
      "[ 14m 43s] Epoch-83 [290/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [300/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [310/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [320/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [330/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [340/549] loss: 0.0000\n",
      "[ 14m 44s] Epoch-83 [350/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [360/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [370/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [380/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [390/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [400/549] loss: 0.0000\n",
      "[ 14m 45s] Epoch-83 [410/549] loss: 0.0000\n",
      "[ 14m 46s] Epoch-83 [420/549] loss: 0.0000\n",
      "[ 14m 46s] Epoch-83 [430/549] loss: 0.0000\n",
      "[ 14m 46s] Epoch-83 [440/549] loss: 0.0000\n",
      "[ 14m 46s] Epoch-83 [450/549] loss: 0.0000\n",
      "[ 14m 46s] Epoch-83 [460/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [470/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [480/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [490/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [500/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [510/549] loss: 0.0000\n",
      "[ 14m 47s] Epoch-83 [520/549] loss: 0.0000\n",
      "[ 14m 48s] Epoch-83 [530/549] loss: 0.0000\n",
      "[ 14m 48s] Epoch-83 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.48%\n",
      "[ 14m 49s] Epoch-84 [10/549] loss: 0.0000\n",
      "[ 14m 49s] Epoch-84 [20/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [30/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [40/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [50/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [60/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [70/549] loss: 0.0000\n",
      "[ 14m 50s] Epoch-84 [80/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [90/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [100/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [110/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [120/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [130/549] loss: 0.0000\n",
      "[ 14m 51s] Epoch-84 [140/549] loss: 0.0000\n",
      "[ 14m 52s] Epoch-84 [150/549] loss: 0.0000\n",
      "[ 14m 52s] Epoch-84 [160/549] loss: 0.0000\n",
      "[ 14m 52s] Epoch-84 [170/549] loss: 0.0000\n",
      "[ 14m 52s] Epoch-84 [180/549] loss: 0.0000\n",
      "[ 14m 52s] Epoch-84 [190/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [200/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [210/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [220/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [230/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [240/549] loss: 0.0000\n",
      "[ 14m 53s] Epoch-84 [250/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [260/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [270/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [280/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [290/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [300/549] loss: 0.0000\n",
      "[ 14m 54s] Epoch-84 [310/549] loss: 0.0000\n",
      "[ 14m 55s] Epoch-84 [320/549] loss: 0.0000\n",
      "[ 14m 55s] Epoch-84 [330/549] loss: 0.0000\n",
      "[ 14m 55s] Epoch-84 [340/549] loss: 0.0000\n",
      "[ 14m 55s] Epoch-84 [350/549] loss: 0.0000\n",
      "[ 14m 55s] Epoch-84 [360/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [370/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [380/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [390/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [400/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [410/549] loss: 0.0000\n",
      "[ 14m 56s] Epoch-84 [420/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [430/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [440/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [450/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [460/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [470/549] loss: 0.0000\n",
      "[ 14m 57s] Epoch-84 [480/549] loss: 0.0000\n",
      "[ 14m 58s] Epoch-84 [490/549] loss: 0.0000\n",
      "[ 14m 58s] Epoch-84 [500/549] loss: 0.0000\n",
      "[ 14m 58s] Epoch-84 [510/549] loss: 0.0000\n",
      "[ 14m 58s] Epoch-84 [520/549] loss: 0.0000\n",
      "[ 14m 58s] Epoch-84 [530/549] loss: 0.0000\n",
      "[ 14m 59s] Epoch-84 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.62%\n",
      "[ 15m  0s] Epoch-85 [10/549] loss: 0.0000\n",
      "[ 15m  0s] Epoch-85 [20/549] loss: 0.0000\n",
      "[ 15m  0s] Epoch-85 [30/549] loss: 0.0000\n",
      "[ 15m  0s] Epoch-85 [40/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [50/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [60/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [70/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [80/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [90/549] loss: 0.0000\n",
      "[ 15m  1s] Epoch-85 [100/549] loss: 0.0000\n",
      "[ 15m  2s] Epoch-85 [110/549] loss: 0.0000\n",
      "[ 15m  2s] Epoch-85 [120/549] loss: 0.0000\n",
      "[ 15m  2s] Epoch-85 [130/549] loss: 0.0000\n",
      "[ 15m  2s] Epoch-85 [140/549] loss: 0.0000\n",
      "[ 15m  2s] Epoch-85 [150/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [160/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [170/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [180/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [190/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [200/549] loss: 0.0000\n",
      "[ 15m  3s] Epoch-85 [210/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [220/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [230/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [240/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [250/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [260/549] loss: 0.0000\n",
      "[ 15m  4s] Epoch-85 [270/549] loss: 0.0000\n",
      "[ 15m  5s] Epoch-85 [280/549] loss: 0.0000\n",
      "[ 15m  5s] Epoch-85 [290/549] loss: 0.0000\n",
      "[ 15m  5s] Epoch-85 [300/549] loss: 0.0000\n",
      "[ 15m  5s] Epoch-85 [310/549] loss: 0.0000\n",
      "[ 15m  5s] Epoch-85 [320/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [330/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [340/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [350/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [360/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [370/549] loss: 0.0000\n",
      "[ 15m  6s] Epoch-85 [380/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [390/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [400/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [410/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [420/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [430/549] loss: 0.0000\n",
      "[ 15m  7s] Epoch-85 [440/549] loss: 0.0000\n",
      "[ 15m  8s] Epoch-85 [450/549] loss: 0.0000\n",
      "[ 15m  8s] Epoch-85 [460/549] loss: 0.0000\n",
      "[ 15m  8s] Epoch-85 [470/549] loss: 0.0000\n",
      "[ 15m  8s] Epoch-85 [480/549] loss: 0.0000\n",
      "[ 15m  8s] Epoch-85 [490/549] loss: 0.0000\n",
      "[ 15m  9s] Epoch-85 [500/549] loss: 0.0000\n",
      "[ 15m  9s] Epoch-85 [510/549] loss: 0.0000\n",
      "[ 15m  9s] Epoch-85 [520/549] loss: 0.0000\n",
      "[ 15m  9s] Epoch-85 [530/549] loss: 0.0000\n",
      "[ 15m  9s] Epoch-85 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.68%\n",
      "[ 15m 11s] Epoch-86 [10/549] loss: 0.0000\n",
      "[ 15m 11s] Epoch-86 [20/549] loss: 0.0000\n",
      "[ 15m 11s] Epoch-86 [30/549] loss: 0.0000\n",
      "[ 15m 11s] Epoch-86 [40/549] loss: 0.0000\n",
      "[ 15m 11s] Epoch-86 [50/549] loss: 0.0000\n",
      "[ 15m 11s] Epoch-86 [60/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [70/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [80/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [90/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [100/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [110/549] loss: 0.0000\n",
      "[ 15m 12s] Epoch-86 [120/549] loss: 0.0000\n",
      "[ 15m 13s] Epoch-86 [130/549] loss: 0.0000\n",
      "[ 15m 13s] Epoch-86 [140/549] loss: 0.0000\n",
      "[ 15m 13s] Epoch-86 [150/549] loss: 0.0000\n",
      "[ 15m 13s] Epoch-86 [160/549] loss: 0.0000\n",
      "[ 15m 13s] Epoch-86 [170/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [180/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [190/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [200/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [210/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [220/549] loss: 0.0000\n",
      "[ 15m 14s] Epoch-86 [230/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [240/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [250/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [260/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [270/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [280/549] loss: 0.0000\n",
      "[ 15m 15s] Epoch-86 [290/549] loss: 0.0000\n",
      "[ 15m 16s] Epoch-86 [300/549] loss: 0.0000\n",
      "[ 15m 16s] Epoch-86 [310/549] loss: 0.0000\n",
      "[ 15m 16s] Epoch-86 [320/549] loss: 0.0000\n",
      "[ 15m 16s] Epoch-86 [330/549] loss: 0.0000\n",
      "[ 15m 16s] Epoch-86 [340/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [350/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [360/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [370/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [380/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [390/549] loss: 0.0000\n",
      "[ 15m 17s] Epoch-86 [400/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [410/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [420/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [430/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [440/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [450/549] loss: 0.0000\n",
      "[ 15m 18s] Epoch-86 [460/549] loss: 0.0000\n",
      "[ 15m 19s] Epoch-86 [470/549] loss: 0.0000\n",
      "[ 15m 19s] Epoch-86 [480/549] loss: 0.0000\n",
      "[ 15m 19s] Epoch-86 [490/549] loss: 0.0000\n",
      "[ 15m 19s] Epoch-86 [500/549] loss: 0.0000\n",
      "[ 15m 19s] Epoch-86 [510/549] loss: 0.0000\n",
      "[ 15m 20s] Epoch-86 [520/549] loss: 0.0000\n",
      "[ 15m 20s] Epoch-86 [530/549] loss: 0.0000\n",
      "[ 15m 20s] Epoch-86 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.82%\n",
      "[ 15m 21s] Epoch-87 [10/549] loss: 0.0000\n",
      "[ 15m 21s] Epoch-87 [20/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [30/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [40/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [50/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [60/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [70/549] loss: 0.0000\n",
      "[ 15m 22s] Epoch-87 [80/549] loss: 0.0000\n",
      "[ 15m 23s] Epoch-87 [90/549] loss: 0.0000\n",
      "[ 15m 23s] Epoch-87 [100/549] loss: 0.0000\n",
      "[ 15m 23s] Epoch-87 [110/549] loss: 0.0000\n",
      "[ 15m 23s] Epoch-87 [120/549] loss: 0.0000\n",
      "[ 15m 23s] Epoch-87 [130/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [140/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [150/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [160/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [170/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [180/549] loss: 0.0000\n",
      "[ 15m 24s] Epoch-87 [190/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [200/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [210/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [220/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [230/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [240/549] loss: 0.0000\n",
      "[ 15m 25s] Epoch-87 [250/549] loss: 0.0000\n",
      "[ 15m 26s] Epoch-87 [260/549] loss: 0.0000\n",
      "[ 15m 26s] Epoch-87 [270/549] loss: 0.0000\n",
      "[ 15m 26s] Epoch-87 [280/549] loss: 0.0000\n",
      "[ 15m 26s] Epoch-87 [290/549] loss: 0.0000\n",
      "[ 15m 26s] Epoch-87 [300/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [310/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [320/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [330/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [340/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [350/549] loss: 0.0000\n",
      "[ 15m 27s] Epoch-87 [360/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [370/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [380/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [390/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [400/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [410/549] loss: 0.0000\n",
      "[ 15m 28s] Epoch-87 [420/549] loss: 0.0000\n",
      "[ 15m 29s] Epoch-87 [430/549] loss: 0.0000\n",
      "[ 15m 29s] Epoch-87 [440/549] loss: 0.0000\n",
      "[ 15m 29s] Epoch-87 [450/549] loss: 0.0000\n",
      "[ 15m 29s] Epoch-87 [460/549] loss: 0.0000\n",
      "[ 15m 29s] Epoch-87 [470/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [480/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [490/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [500/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [510/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [520/549] loss: 0.0000\n",
      "[ 15m 30s] Epoch-87 [530/549] loss: 0.0000\n",
      "[ 15m 31s] Epoch-87 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.79%\n",
      "[ 15m 32s] Epoch-88 [10/549] loss: 0.0000\n",
      "[ 15m 32s] Epoch-88 [20/549] loss: 0.0000\n",
      "[ 15m 32s] Epoch-88 [30/549] loss: 0.0000\n",
      "[ 15m 32s] Epoch-88 [40/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [50/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [60/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [70/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [80/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [90/549] loss: 0.0000\n",
      "[ 15m 33s] Epoch-88 [100/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [110/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [120/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [130/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [140/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [150/549] loss: 0.0000\n",
      "[ 15m 34s] Epoch-88 [160/549] loss: 0.0000\n",
      "[ 15m 35s] Epoch-88 [170/549] loss: 0.0000\n",
      "[ 15m 35s] Epoch-88 [180/549] loss: 0.0000\n",
      "[ 15m 35s] Epoch-88 [190/549] loss: 0.0000\n",
      "[ 15m 35s] Epoch-88 [200/549] loss: 0.0000\n",
      "[ 15m 35s] Epoch-88 [210/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [220/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [230/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [240/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [250/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [260/549] loss: 0.0000\n",
      "[ 15m 36s] Epoch-88 [270/549] loss: 0.0000\n",
      "[ 15m 37s] Epoch-88 [280/549] loss: 0.0000\n",
      "[ 15m 37s] Epoch-88 [290/549] loss: 0.0000\n",
      "[ 15m 37s] Epoch-88 [300/549] loss: 0.0000\n",
      "[ 15m 37s] Epoch-88 [310/549] loss: 0.0000\n",
      "[ 15m 37s] Epoch-88 [320/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [330/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [340/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [350/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [360/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [370/549] loss: 0.0000\n",
      "[ 15m 38s] Epoch-88 [380/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [390/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [400/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [410/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [420/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [430/549] loss: 0.0000\n",
      "[ 15m 39s] Epoch-88 [440/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [450/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [460/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [470/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [480/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [490/549] loss: 0.0000\n",
      "[ 15m 40s] Epoch-88 [500/549] loss: 0.0000\n",
      "[ 15m 41s] Epoch-88 [510/549] loss: 0.0000\n",
      "[ 15m 41s] Epoch-88 [520/549] loss: 0.0000\n",
      "[ 15m 41s] Epoch-88 [530/549] loss: 0.0000\n",
      "[ 15m 41s] Epoch-88 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.89%\n",
      "[ 15m 42s] Epoch-89 [10/549] loss: 0.0000\n",
      "[ 15m 43s] Epoch-89 [20/549] loss: 0.0000\n",
      "[ 15m 43s] Epoch-89 [30/549] loss: 0.0000\n",
      "[ 15m 43s] Epoch-89 [40/549] loss: 0.0000\n",
      "[ 15m 43s] Epoch-89 [50/549] loss: 0.0000\n",
      "[ 15m 43s] Epoch-89 [60/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [70/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [80/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [90/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [100/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [110/549] loss: 0.0000\n",
      "[ 15m 44s] Epoch-89 [120/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [130/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [140/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [150/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [160/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [170/549] loss: 0.0000\n",
      "[ 15m 45s] Epoch-89 [180/549] loss: 0.0000\n",
      "[ 15m 46s] Epoch-89 [190/549] loss: 0.0000\n",
      "[ 15m 46s] Epoch-89 [200/549] loss: 0.0000\n",
      "[ 15m 46s] Epoch-89 [210/549] loss: 0.0000\n",
      "[ 15m 46s] Epoch-89 [220/549] loss: 0.0000\n",
      "[ 15m 46s] Epoch-89 [230/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [240/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [250/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [260/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [270/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [280/549] loss: 0.0000\n",
      "[ 15m 47s] Epoch-89 [290/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [300/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [310/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [320/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [330/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [340/549] loss: 0.0000\n",
      "[ 15m 48s] Epoch-89 [350/549] loss: 0.0000\n",
      "[ 15m 49s] Epoch-89 [360/549] loss: 0.0000\n",
      "[ 15m 49s] Epoch-89 [370/549] loss: 0.0000\n",
      "[ 15m 49s] Epoch-89 [380/549] loss: 0.0000\n",
      "[ 15m 49s] Epoch-89 [390/549] loss: 0.0000\n",
      "[ 15m 49s] Epoch-89 [400/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [410/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [420/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [430/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [440/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [450/549] loss: 0.0000\n",
      "[ 15m 50s] Epoch-89 [460/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [470/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [480/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [490/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [500/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [510/549] loss: 0.0000\n",
      "[ 15m 51s] Epoch-89 [520/549] loss: 0.0000\n",
      "[ 15m 52s] Epoch-89 [530/549] loss: 0.0000\n",
      "[ 15m 52s] Epoch-89 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.85%\n",
      "[ 15m 53s] Epoch-90 [10/549] loss: 0.0000\n",
      "[ 15m 53s] Epoch-90 [20/549] loss: 0.0000\n",
      "[ 15m 53s] Epoch-90 [30/549] loss: 0.0000\n",
      "[ 15m 54s] Epoch-90 [40/549] loss: 0.0000\n",
      "[ 15m 54s] Epoch-90 [50/549] loss: 0.0000\n",
      "[ 15m 54s] Epoch-90 [60/549] loss: 0.0000\n",
      "[ 15m 54s] Epoch-90 [70/549] loss: 0.0000\n",
      "[ 15m 54s] Epoch-90 [80/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [90/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [100/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [110/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [120/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [130/549] loss: 0.0000\n",
      "[ 15m 55s] Epoch-90 [140/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [150/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [160/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [170/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [180/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [190/549] loss: 0.0000\n",
      "[ 15m 56s] Epoch-90 [200/549] loss: 0.0000\n",
      "[ 15m 57s] Epoch-90 [210/549] loss: 0.0000\n",
      "[ 15m 57s] Epoch-90 [220/549] loss: 0.0000\n",
      "[ 15m 57s] Epoch-90 [230/549] loss: 0.0000\n",
      "[ 15m 57s] Epoch-90 [240/549] loss: 0.0000\n",
      "[ 15m 57s] Epoch-90 [250/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [260/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [270/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [280/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [290/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [300/549] loss: 0.0000\n",
      "[ 15m 58s] Epoch-90 [310/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [320/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [330/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [340/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [350/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [360/549] loss: 0.0000\n",
      "[ 15m 59s] Epoch-90 [370/549] loss: 0.0000\n",
      "[ 16m  0s] Epoch-90 [380/549] loss: 0.0000\n",
      "[ 16m  0s] Epoch-90 [390/549] loss: 0.0000\n",
      "[ 16m  0s] Epoch-90 [400/549] loss: 0.0000\n",
      "[ 16m  0s] Epoch-90 [410/549] loss: 0.0000\n",
      "[ 16m  0s] Epoch-90 [420/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [430/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [440/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [450/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [460/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [470/549] loss: 0.0000\n",
      "[ 16m  1s] Epoch-90 [480/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [490/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [500/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [510/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [520/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [530/549] loss: 0.0000\n",
      "[ 16m  2s] Epoch-90 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.86%\n",
      "[ 16m  4s] Epoch-91 [10/549] loss: 0.0000\n",
      "[ 16m  4s] Epoch-91 [20/549] loss: 0.0000\n",
      "[ 16m  4s] Epoch-91 [30/549] loss: 0.0000\n",
      "[ 16m  4s] Epoch-91 [40/549] loss: 0.0000\n",
      "[ 16m  4s] Epoch-91 [50/549] loss: 0.0000\n",
      "[ 16m  5s] Epoch-91 [60/549] loss: 0.0000\n",
      "[ 16m  5s] Epoch-91 [70/549] loss: 0.0000\n",
      "[ 16m  5s] Epoch-91 [80/549] loss: 0.0000\n",
      "[ 16m  5s] Epoch-91 [90/549] loss: 0.0000\n",
      "[ 16m  5s] Epoch-91 [100/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [110/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [120/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [130/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [140/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [150/549] loss: 0.0000\n",
      "[ 16m  6s] Epoch-91 [160/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [170/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [180/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [190/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [200/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [210/549] loss: 0.0000\n",
      "[ 16m  7s] Epoch-91 [220/549] loss: 0.0000\n",
      "[ 16m  8s] Epoch-91 [230/549] loss: 0.0000\n",
      "[ 16m  8s] Epoch-91 [240/549] loss: 0.0000\n",
      "[ 16m  8s] Epoch-91 [250/549] loss: 0.0000\n",
      "[ 16m  8s] Epoch-91 [260/549] loss: 0.0000\n",
      "[ 16m  8s] Epoch-91 [270/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [280/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [290/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [300/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [310/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [320/549] loss: 0.0000\n",
      "[ 16m  9s] Epoch-91 [330/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [340/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [350/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [360/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [370/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [380/549] loss: 0.0000\n",
      "[ 16m 10s] Epoch-91 [390/549] loss: 0.0000\n",
      "[ 16m 11s] Epoch-91 [400/549] loss: 0.0001\n",
      "[ 16m 11s] Epoch-91 [410/549] loss: 0.0001\n",
      "[ 16m 11s] Epoch-91 [420/549] loss: 0.0001\n",
      "[ 16m 11s] Epoch-91 [430/549] loss: 0.0001\n",
      "[ 16m 11s] Epoch-91 [440/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [450/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [460/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [470/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [480/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [490/549] loss: 0.0001\n",
      "[ 16m 12s] Epoch-91 [500/549] loss: 0.0001\n",
      "[ 16m 13s] Epoch-91 [510/549] loss: 0.0001\n",
      "[ 16m 13s] Epoch-91 [520/549] loss: 0.0002\n",
      "[ 16m 13s] Epoch-91 [530/549] loss: 0.0002\n",
      "[ 16m 13s] Epoch-91 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 94.63%\n",
      "[ 16m 14s] Epoch-92 [10/549] loss: 0.0003\n",
      "[ 16m 15s] Epoch-92 [20/549] loss: 0.0003\n",
      "[ 16m 15s] Epoch-92 [30/549] loss: 0.0003\n",
      "[ 16m 15s] Epoch-92 [40/549] loss: 0.0002\n",
      "[ 16m 15s] Epoch-92 [50/549] loss: 0.0002\n",
      "[ 16m 15s] Epoch-92 [60/549] loss: 0.0002\n",
      "[ 16m 15s] Epoch-92 [70/549] loss: 0.0002\n",
      "[ 16m 16s] Epoch-92 [80/549] loss: 0.0002\n",
      "[ 16m 16s] Epoch-92 [90/549] loss: 0.0002\n",
      "[ 16m 16s] Epoch-92 [100/549] loss: 0.0002\n",
      "[ 16m 16s] Epoch-92 [110/549] loss: 0.0002\n",
      "[ 16m 16s] Epoch-92 [120/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [130/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [140/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [150/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [160/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [170/549] loss: 0.0002\n",
      "[ 16m 17s] Epoch-92 [180/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [190/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [200/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [210/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [220/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [230/549] loss: 0.0002\n",
      "[ 16m 18s] Epoch-92 [240/549] loss: 0.0002\n",
      "[ 16m 19s] Epoch-92 [250/549] loss: 0.0002\n",
      "[ 16m 19s] Epoch-92 [260/549] loss: 0.0002\n",
      "[ 16m 19s] Epoch-92 [270/549] loss: 0.0002\n",
      "[ 16m 19s] Epoch-92 [280/549] loss: 0.0002\n",
      "[ 16m 19s] Epoch-92 [290/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [300/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [310/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [320/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [330/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [340/549] loss: 0.0002\n",
      "[ 16m 20s] Epoch-92 [350/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [360/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [370/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [380/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [390/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [400/549] loss: 0.0002\n",
      "[ 16m 21s] Epoch-92 [410/549] loss: 0.0002\n",
      "[ 16m 22s] Epoch-92 [420/549] loss: 0.0002\n",
      "[ 16m 22s] Epoch-92 [430/549] loss: 0.0002\n",
      "[ 16m 22s] Epoch-92 [440/549] loss: 0.0002\n",
      "[ 16m 22s] Epoch-92 [450/549] loss: 0.0002\n",
      "[ 16m 22s] Epoch-92 [460/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [470/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [480/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [490/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [500/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [510/549] loss: 0.0002\n",
      "[ 16m 23s] Epoch-92 [520/549] loss: 0.0002\n",
      "[ 16m 24s] Epoch-92 [530/549] loss: 0.0002\n",
      "[ 16m 24s] Epoch-92 [540/549] loss: 0.0002\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.15%\n",
      "[ 16m 25s] Epoch-93 [10/549] loss: 0.0001\n",
      "[ 16m 25s] Epoch-93 [20/549] loss: 0.0001\n",
      "[ 16m 25s] Epoch-93 [30/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [40/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [50/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [60/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [70/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [80/549] loss: 0.0001\n",
      "[ 16m 26s] Epoch-93 [90/549] loss: 0.0001\n",
      "[ 16m 27s] Epoch-93 [100/549] loss: 0.0001\n",
      "[ 16m 27s] Epoch-93 [110/549] loss: 0.0001\n",
      "[ 16m 27s] Epoch-93 [120/549] loss: 0.0001\n",
      "[ 16m 27s] Epoch-93 [130/549] loss: 0.0001\n",
      "[ 16m 27s] Epoch-93 [140/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [150/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [160/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [170/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [180/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [190/549] loss: 0.0001\n",
      "[ 16m 28s] Epoch-93 [200/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [210/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [220/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [230/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [240/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [250/549] loss: 0.0001\n",
      "[ 16m 29s] Epoch-93 [260/549] loss: 0.0001\n",
      "[ 16m 30s] Epoch-93 [270/549] loss: 0.0001\n",
      "[ 16m 30s] Epoch-93 [280/549] loss: 0.0001\n",
      "[ 16m 30s] Epoch-93 [290/549] loss: 0.0001\n",
      "[ 16m 30s] Epoch-93 [300/549] loss: 0.0001\n",
      "[ 16m 30s] Epoch-93 [310/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [320/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [330/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [340/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [350/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [360/549] loss: 0.0001\n",
      "[ 16m 31s] Epoch-93 [370/549] loss: 0.0000\n",
      "[ 16m 32s] Epoch-93 [380/549] loss: 0.0001\n",
      "[ 16m 32s] Epoch-93 [390/549] loss: 0.0000\n",
      "[ 16m 32s] Epoch-93 [400/549] loss: 0.0000\n",
      "[ 16m 32s] Epoch-93 [410/549] loss: 0.0000\n",
      "[ 16m 32s] Epoch-93 [420/549] loss: 0.0000\n",
      "[ 16m 32s] Epoch-93 [430/549] loss: 0.0000\n",
      "[ 16m 33s] Epoch-93 [440/549] loss: 0.0000\n",
      "[ 16m 33s] Epoch-93 [450/549] loss: 0.0000\n",
      "[ 16m 33s] Epoch-93 [460/549] loss: 0.0000\n",
      "[ 16m 33s] Epoch-93 [470/549] loss: 0.0000\n",
      "[ 16m 33s] Epoch-93 [480/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [490/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [500/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [510/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [520/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [530/549] loss: 0.0000\n",
      "[ 16m 34s] Epoch-93 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.41%\n",
      "[ 16m 36s] Epoch-94 [10/549] loss: 0.0000\n",
      "[ 16m 36s] Epoch-94 [20/549] loss: 0.0000\n",
      "[ 16m 36s] Epoch-94 [30/549] loss: 0.0000\n",
      "[ 16m 36s] Epoch-94 [40/549] loss: 0.0000\n",
      "[ 16m 36s] Epoch-94 [50/549] loss: 0.0000\n",
      "[ 16m 37s] Epoch-94 [60/549] loss: 0.0000\n",
      "[ 16m 37s] Epoch-94 [70/549] loss: 0.0000\n",
      "[ 16m 37s] Epoch-94 [80/549] loss: 0.0000\n",
      "[ 16m 37s] Epoch-94 [90/549] loss: 0.0000\n",
      "[ 16m 37s] Epoch-94 [100/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [110/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [120/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [130/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [140/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [150/549] loss: 0.0000\n",
      "[ 16m 38s] Epoch-94 [160/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [170/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [180/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [190/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [200/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [210/549] loss: 0.0000\n",
      "[ 16m 39s] Epoch-94 [220/549] loss: 0.0000\n",
      "[ 16m 40s] Epoch-94 [230/549] loss: 0.0000\n",
      "[ 16m 40s] Epoch-94 [240/549] loss: 0.0000\n",
      "[ 16m 40s] Epoch-94 [250/549] loss: 0.0000\n",
      "[ 16m 40s] Epoch-94 [260/549] loss: 0.0000\n",
      "[ 16m 40s] Epoch-94 [270/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [280/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [290/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [300/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [310/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [320/549] loss: 0.0000\n",
      "[ 16m 41s] Epoch-94 [330/549] loss: 0.0000\n",
      "[ 16m 42s] Epoch-94 [340/549] loss: 0.0000\n",
      "[ 16m 42s] Epoch-94 [350/549] loss: 0.0000\n",
      "[ 16m 42s] Epoch-94 [360/549] loss: 0.0000\n",
      "[ 16m 42s] Epoch-94 [370/549] loss: 0.0000\n",
      "[ 16m 42s] Epoch-94 [380/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [390/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [400/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [410/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [420/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [430/549] loss: 0.0000\n",
      "[ 16m 43s] Epoch-94 [440/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [450/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [460/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [470/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [480/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [490/549] loss: 0.0000\n",
      "[ 16m 44s] Epoch-94 [500/549] loss: 0.0000\n",
      "[ 16m 45s] Epoch-94 [510/549] loss: 0.0000\n",
      "[ 16m 45s] Epoch-94 [520/549] loss: 0.0000\n",
      "[ 16m 45s] Epoch-94 [530/549] loss: 0.0000\n",
      "[ 16m 45s] Epoch-94 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.64%\n",
      "[ 16m 47s] Epoch-95 [10/549] loss: 0.0000\n",
      "[ 16m 47s] Epoch-95 [20/549] loss: 0.0000\n",
      "[ 16m 47s] Epoch-95 [30/549] loss: 0.0000\n",
      "[ 16m 47s] Epoch-95 [40/549] loss: 0.0000\n",
      "[ 16m 47s] Epoch-95 [50/549] loss: 0.0000\n",
      "[ 16m 47s] Epoch-95 [60/549] loss: 0.0000\n",
      "[ 16m 48s] Epoch-95 [70/549] loss: 0.0000\n",
      "[ 16m 48s] Epoch-95 [80/549] loss: 0.0000\n",
      "[ 16m 48s] Epoch-95 [90/549] loss: 0.0000\n",
      "[ 16m 48s] Epoch-95 [100/549] loss: 0.0000\n",
      "[ 16m 48s] Epoch-95 [110/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [120/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [130/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [140/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [150/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [160/549] loss: 0.0000\n",
      "[ 16m 49s] Epoch-95 [170/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [180/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [190/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [200/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [210/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [220/549] loss: 0.0000\n",
      "[ 16m 50s] Epoch-95 [230/549] loss: 0.0000\n",
      "[ 16m 51s] Epoch-95 [240/549] loss: 0.0000\n",
      "[ 16m 51s] Epoch-95 [250/549] loss: 0.0000\n",
      "[ 16m 51s] Epoch-95 [260/549] loss: 0.0000\n",
      "[ 16m 51s] Epoch-95 [270/549] loss: 0.0000\n",
      "[ 16m 51s] Epoch-95 [280/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [290/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [300/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [310/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [320/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [330/549] loss: 0.0000\n",
      "[ 16m 52s] Epoch-95 [340/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [350/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [360/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [370/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [380/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [390/549] loss: 0.0000\n",
      "[ 16m 53s] Epoch-95 [400/549] loss: 0.0000\n",
      "[ 16m 54s] Epoch-95 [410/549] loss: 0.0000\n",
      "[ 16m 54s] Epoch-95 [420/549] loss: 0.0000\n",
      "[ 16m 54s] Epoch-95 [430/549] loss: 0.0000\n",
      "[ 16m 54s] Epoch-95 [440/549] loss: 0.0000\n",
      "[ 16m 54s] Epoch-95 [450/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [460/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [470/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [480/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [490/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [500/549] loss: 0.0000\n",
      "[ 16m 55s] Epoch-95 [510/549] loss: 0.0000\n",
      "[ 16m 56s] Epoch-95 [520/549] loss: 0.0000\n",
      "[ 16m 56s] Epoch-95 [530/549] loss: 0.0000\n",
      "[ 16m 56s] Epoch-95 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.70%\n",
      "[ 16m 57s] Epoch-96 [10/549] loss: 0.0000\n",
      "[ 16m 57s] Epoch-96 [20/549] loss: 0.0000\n",
      "[ 16m 58s] Epoch-96 [30/549] loss: 0.0000\n",
      "[ 16m 58s] Epoch-96 [40/549] loss: 0.0000\n",
      "[ 16m 58s] Epoch-96 [50/549] loss: 0.0000\n",
      "[ 16m 58s] Epoch-96 [60/549] loss: 0.0000\n",
      "[ 16m 58s] Epoch-96 [70/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [80/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [90/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [100/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [110/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [120/549] loss: 0.0000\n",
      "[ 16m 59s] Epoch-96 [130/549] loss: 0.0000\n",
      "[ 17m  0s] Epoch-96 [140/549] loss: 0.0000\n",
      "[ 17m  0s] Epoch-96 [150/549] loss: 0.0000\n",
      "[ 17m  0s] Epoch-96 [160/549] loss: 0.0000\n",
      "[ 17m  0s] Epoch-96 [170/549] loss: 0.0000\n",
      "[ 17m  0s] Epoch-96 [180/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [190/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [200/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [210/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [220/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [230/549] loss: 0.0000\n",
      "[ 17m  1s] Epoch-96 [240/549] loss: 0.0000\n",
      "[ 17m  2s] Epoch-96 [250/549] loss: 0.0000\n",
      "[ 17m  2s] Epoch-96 [260/549] loss: 0.0000\n",
      "[ 17m  2s] Epoch-96 [270/549] loss: 0.0000\n",
      "[ 17m  2s] Epoch-96 [280/549] loss: 0.0000\n",
      "[ 17m  2s] Epoch-96 [290/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [300/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [310/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [320/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [330/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [340/549] loss: 0.0000\n",
      "[ 17m  3s] Epoch-96 [350/549] loss: 0.0000\n",
      "[ 17m  4s] Epoch-96 [360/549] loss: 0.0000\n",
      "[ 17m  4s] Epoch-96 [370/549] loss: 0.0000\n",
      "[ 17m  4s] Epoch-96 [380/549] loss: 0.0000\n",
      "[ 17m  4s] Epoch-96 [390/549] loss: 0.0000\n",
      "[ 17m  4s] Epoch-96 [400/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [410/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [420/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [430/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [440/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [450/549] loss: 0.0000\n",
      "[ 17m  5s] Epoch-96 [460/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [470/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [480/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [490/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [500/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [510/549] loss: 0.0000\n",
      "[ 17m  6s] Epoch-96 [520/549] loss: 0.0000\n",
      "[ 17m  7s] Epoch-96 [530/549] loss: 0.0000\n",
      "[ 17m  7s] Epoch-96 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.75%\n",
      "[ 17m  8s] Epoch-97 [10/549] loss: 0.0000\n",
      "[ 17m  8s] Epoch-97 [20/549] loss: 0.0000\n",
      "[ 17m  8s] Epoch-97 [30/549] loss: 0.0000\n",
      "[ 17m  9s] Epoch-97 [40/549] loss: 0.0000\n",
      "[ 17m  9s] Epoch-97 [50/549] loss: 0.0000\n",
      "[ 17m  9s] Epoch-97 [60/549] loss: 0.0000\n",
      "[ 17m  9s] Epoch-97 [70/549] loss: 0.0000\n",
      "[ 17m  9s] Epoch-97 [80/549] loss: 0.0000\n",
      "[ 17m 10s] Epoch-97 [90/549] loss: 0.0000\n",
      "[ 17m 10s] Epoch-97 [100/549] loss: 0.0000\n",
      "[ 17m 10s] Epoch-97 [110/549] loss: 0.0000\n",
      "[ 17m 10s] Epoch-97 [120/549] loss: 0.0000\n",
      "[ 17m 10s] Epoch-97 [130/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [140/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [150/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [160/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [170/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [180/549] loss: 0.0000\n",
      "[ 17m 11s] Epoch-97 [190/549] loss: 0.0000\n",
      "[ 17m 12s] Epoch-97 [200/549] loss: 0.0000\n",
      "[ 17m 12s] Epoch-97 [210/549] loss: 0.0000\n",
      "[ 17m 12s] Epoch-97 [220/549] loss: 0.0000\n",
      "[ 17m 12s] Epoch-97 [230/549] loss: 0.0000\n",
      "[ 17m 12s] Epoch-97 [240/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [250/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [260/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [270/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [280/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [290/549] loss: 0.0000\n",
      "[ 17m 13s] Epoch-97 [300/549] loss: 0.0000\n",
      "[ 17m 14s] Epoch-97 [310/549] loss: 0.0000\n",
      "[ 17m 14s] Epoch-97 [320/549] loss: 0.0000\n",
      "[ 17m 14s] Epoch-97 [330/549] loss: 0.0000\n",
      "[ 17m 14s] Epoch-97 [340/549] loss: 0.0000\n",
      "[ 17m 14s] Epoch-97 [350/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [360/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [370/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [380/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [390/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [400/549] loss: 0.0000\n",
      "[ 17m 15s] Epoch-97 [410/549] loss: 0.0000\n",
      "[ 17m 16s] Epoch-97 [420/549] loss: 0.0000\n",
      "[ 17m 16s] Epoch-97 [430/549] loss: 0.0000\n",
      "[ 17m 16s] Epoch-97 [440/549] loss: 0.0000\n",
      "[ 17m 16s] Epoch-97 [450/549] loss: 0.0000\n",
      "[ 17m 16s] Epoch-97 [460/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [470/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [480/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [490/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [500/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [510/549] loss: 0.0000\n",
      "[ 17m 17s] Epoch-97 [520/549] loss: 0.0000\n",
      "[ 17m 18s] Epoch-97 [530/549] loss: 0.0000\n",
      "[ 17m 18s] Epoch-97 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.83%\n",
      "[ 17m 19s] Epoch-98 [10/549] loss: 0.0000\n",
      "[ 17m 19s] Epoch-98 [20/549] loss: 0.0000\n",
      "[ 17m 19s] Epoch-98 [30/549] loss: 0.0000\n",
      "[ 17m 20s] Epoch-98 [40/549] loss: 0.0000\n",
      "[ 17m 20s] Epoch-98 [50/549] loss: 0.0000\n",
      "[ 17m 20s] Epoch-98 [60/549] loss: 0.0000\n",
      "[ 17m 20s] Epoch-98 [70/549] loss: 0.0000\n",
      "[ 17m 20s] Epoch-98 [80/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [90/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [100/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [110/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [120/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [130/549] loss: 0.0000\n",
      "[ 17m 21s] Epoch-98 [140/549] loss: 0.0000\n",
      "[ 17m 22s] Epoch-98 [150/549] loss: 0.0000\n",
      "[ 17m 22s] Epoch-98 [160/549] loss: 0.0000\n",
      "[ 17m 22s] Epoch-98 [170/549] loss: 0.0000\n",
      "[ 17m 22s] Epoch-98 [180/549] loss: 0.0000\n",
      "[ 17m 22s] Epoch-98 [190/549] loss: 0.0000\n",
      "[ 17m 23s] Epoch-98 [200/549] loss: 0.0000\n",
      "[ 17m 23s] Epoch-98 [210/549] loss: 0.0000\n",
      "[ 17m 23s] Epoch-98 [220/549] loss: 0.0000\n",
      "[ 17m 23s] Epoch-98 [230/549] loss: 0.0000\n",
      "[ 17m 23s] Epoch-98 [240/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [250/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [260/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [270/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [280/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [290/549] loss: 0.0000\n",
      "[ 17m 24s] Epoch-98 [300/549] loss: 0.0000\n",
      "[ 17m 25s] Epoch-98 [310/549] loss: 0.0000\n",
      "[ 17m 25s] Epoch-98 [320/549] loss: 0.0000\n",
      "[ 17m 25s] Epoch-98 [330/549] loss: 0.0000\n",
      "[ 17m 25s] Epoch-98 [340/549] loss: 0.0000\n",
      "[ 17m 25s] Epoch-98 [350/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [360/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [370/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [380/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [390/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [400/549] loss: 0.0000\n",
      "[ 17m 26s] Epoch-98 [410/549] loss: 0.0000\n",
      "[ 17m 27s] Epoch-98 [420/549] loss: 0.0000\n",
      "[ 17m 27s] Epoch-98 [430/549] loss: 0.0000\n",
      "[ 17m 27s] Epoch-98 [440/549] loss: 0.0000\n",
      "[ 17m 27s] Epoch-98 [450/549] loss: 0.0000\n",
      "[ 17m 27s] Epoch-98 [460/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [470/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [480/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [490/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [500/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [510/549] loss: 0.0000\n",
      "[ 17m 28s] Epoch-98 [520/549] loss: 0.0000\n",
      "[ 17m 29s] Epoch-98 [530/549] loss: 0.0000\n",
      "[ 17m 29s] Epoch-98 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.79%\n",
      "[ 17m 30s] Epoch-99 [10/549] loss: 0.0000\n",
      "[ 17m 30s] Epoch-99 [20/549] loss: 0.0000\n",
      "[ 17m 30s] Epoch-99 [30/549] loss: 0.0000\n",
      "[ 17m 31s] Epoch-99 [40/549] loss: 0.0000\n",
      "[ 17m 31s] Epoch-99 [50/549] loss: 0.0000\n",
      "[ 17m 31s] Epoch-99 [60/549] loss: 0.0000\n",
      "[ 17m 31s] Epoch-99 [70/549] loss: 0.0000\n",
      "[ 17m 31s] Epoch-99 [80/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [90/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [100/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [110/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [120/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [130/549] loss: 0.0000\n",
      "[ 17m 32s] Epoch-99 [140/549] loss: 0.0000\n",
      "[ 17m 33s] Epoch-99 [150/549] loss: 0.0000\n",
      "[ 17m 33s] Epoch-99 [160/549] loss: 0.0000\n",
      "[ 17m 33s] Epoch-99 [170/549] loss: 0.0000\n",
      "[ 17m 33s] Epoch-99 [180/549] loss: 0.0000\n",
      "[ 17m 33s] Epoch-99 [190/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [200/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [210/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [220/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [230/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [240/549] loss: 0.0000\n",
      "[ 17m 34s] Epoch-99 [250/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [260/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [270/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [280/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [290/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [300/549] loss: 0.0000\n",
      "[ 17m 35s] Epoch-99 [310/549] loss: 0.0000\n",
      "[ 17m 36s] Epoch-99 [320/549] loss: 0.0000\n",
      "[ 17m 36s] Epoch-99 [330/549] loss: 0.0000\n",
      "[ 17m 36s] Epoch-99 [340/549] loss: 0.0000\n",
      "[ 17m 36s] Epoch-99 [350/549] loss: 0.0000\n",
      "[ 17m 36s] Epoch-99 [360/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [370/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [380/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [390/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [400/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [410/549] loss: 0.0000\n",
      "[ 17m 37s] Epoch-99 [420/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [430/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [440/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [450/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [460/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [470/549] loss: 0.0000\n",
      "[ 17m 38s] Epoch-99 [480/549] loss: 0.0000\n",
      "[ 17m 39s] Epoch-99 [490/549] loss: 0.0000\n",
      "[ 17m 39s] Epoch-99 [500/549] loss: 0.0000\n",
      "[ 17m 39s] Epoch-99 [510/549] loss: 0.0000\n",
      "[ 17m 39s] Epoch-99 [520/549] loss: 0.0000\n",
      "[ 17m 39s] Epoch-99 [530/549] loss: 0.0000\n",
      "[ 17m 40s] Epoch-99 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.80%\n",
      "[ 17m 41s] Epoch-100 [10/549] loss: 0.0000\n",
      "[ 17m 41s] Epoch-100 [20/549] loss: 0.0000\n",
      "[ 17m 41s] Epoch-100 [30/549] loss: 0.0000\n",
      "[ 17m 41s] Epoch-100 [40/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [50/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [60/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [70/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [80/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [90/549] loss: 0.0000\n",
      "[ 17m 42s] Epoch-100 [100/549] loss: 0.0000\n",
      "[ 17m 43s] Epoch-100 [110/549] loss: 0.0000\n",
      "[ 17m 43s] Epoch-100 [120/549] loss: 0.0000\n",
      "[ 17m 43s] Epoch-100 [130/549] loss: 0.0000\n",
      "[ 17m 43s] Epoch-100 [140/549] loss: 0.0000\n",
      "[ 17m 43s] Epoch-100 [150/549] loss: 0.0000\n",
      "[ 17m 44s] Epoch-100 [160/549] loss: 0.0000\n",
      "[ 17m 44s] Epoch-100 [170/549] loss: 0.0000\n",
      "[ 17m 44s] Epoch-100 [180/549] loss: 0.0000\n",
      "[ 17m 44s] Epoch-100 [190/549] loss: 0.0000\n",
      "[ 17m 44s] Epoch-100 [200/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [210/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [220/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [230/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [240/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [250/549] loss: 0.0000\n",
      "[ 17m 45s] Epoch-100 [260/549] loss: 0.0000\n",
      "[ 17m 46s] Epoch-100 [270/549] loss: 0.0000\n",
      "[ 17m 46s] Epoch-100 [280/549] loss: 0.0000\n",
      "[ 17m 46s] Epoch-100 [290/549] loss: 0.0000\n",
      "[ 17m 46s] Epoch-100 [300/549] loss: 0.0000\n",
      "[ 17m 46s] Epoch-100 [310/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [320/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [330/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [340/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [350/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [360/549] loss: 0.0000\n",
      "[ 17m 47s] Epoch-100 [370/549] loss: 0.0000\n",
      "[ 17m 48s] Epoch-100 [380/549] loss: 0.0000\n",
      "[ 17m 48s] Epoch-100 [390/549] loss: 0.0000\n",
      "[ 17m 48s] Epoch-100 [400/549] loss: 0.0000\n",
      "[ 17m 48s] Epoch-100 [410/549] loss: 0.0000\n",
      "[ 17m 48s] Epoch-100 [420/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [430/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [440/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [450/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [460/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [470/549] loss: 0.0000\n",
      "[ 17m 49s] Epoch-100 [480/549] loss: 0.0000\n",
      "[ 17m 50s] Epoch-100 [490/549] loss: 0.0000\n",
      "[ 17m 50s] Epoch-100 [500/549] loss: 0.0000\n",
      "[ 17m 50s] Epoch-100 [510/549] loss: 0.0000\n",
      "[ 17m 50s] Epoch-100 [520/549] loss: 0.0000\n",
      "[ 17m 50s] Epoch-100 [530/549] loss: 0.0000\n",
      "[ 17m 51s] Epoch-100 [540/549] loss: 0.0000\n",
      "Evaluating Trained Model...\n",
      "Accuracy: 96.80%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRIES, N_LAYER)\n",
    "\n",
    "    if USE_GPU:\n",
    "        device = torch.device('cuda')\n",
    "        classifier.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=.001)\n",
    "\n",
    "    st_time = time.time()\n",
    "    acc_list = []\n",
    "    for epoch in range(N_EPOCH):\n",
    "        train_model()\n",
    "        acc = test_model()\n",
    "        acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i+1 for i in range(len(acc_list))], acc_list)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "- 电影评论情感分析 - [Kaggle](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpteam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
