{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环神经网络(基础)\n",
    "\n",
    "## 使用场景\n",
    "\n",
    "DNN 的参数量很容易过多, 训练费时耗能大. \n",
    "\n",
    "RNN 能够处理序列数据, 并且可以并行处理序列中的每个元素. 主要用于有顺序序关系的输入. \n",
    "\n",
    "## What is RNN cell?\n",
    "\n",
    "- RNN cell 本质是一个线性层. \n",
    "- RNN cell 输入一个向量, 输出一个变换维度的向量. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN cell Structure\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h_{t-1} \\in \\mathbb R^{hidden\\_size} \\rightarrow W_{hh} h_{t-1} + b{hh} \\rightarrow & + \\rightarrow tanh \\rightarrow h_t \\in \\mathbb R^{hidden\\_size} \\\\\n",
    "& \\uparrow \\\\\n",
    "W_{ih} & + b_{ih} \\\\\n",
    "& \\uparrow \\\\\n",
    "x_t \\in & \\mathbb R^{input\\_size}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN cell in Pytorch\n",
    "\n",
    "```python\n",
    "cell = torch.nn.RNNCell(input_size=input_dim, hidden_size=hidden_dim)\n",
    "hidden = cell(input, hidden)\n",
    "```\n",
    "\n",
    "Input Parameters:\n",
    "- input (Tensor): A mini-batch of input sequences. shape(batch, input_size).\n",
    "- hidden (Tensor): A mini-batch of initial hidden states. shape(batch, hidden_size).\n",
    "\n",
    "Return:\n",
    "- hidden (Tensor): A mini-batch of hidden states. shape(batch, hidden_size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use RNN cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 1 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "Hidden size: torch.Size([1, 2])\n",
      "tensor([[ 0.8535, -0.2568]], grad_fn=<TanhBackward0>)\n",
      "==================== 2 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "Hidden size: torch.Size([1, 2])\n",
      "tensor([[ 0.7672, -0.9486]], grad_fn=<TanhBackward0>)\n",
      "==================== 3 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "Hidden size: torch.Size([1, 2])\n",
      "tensor([[0.9501, 0.0591]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_dim = 4\n",
    "hidden_dim = 2\n",
    "\n",
    "cell = torch.nn.RNNCell(input_size=input_dim, hidden_size=hidden_dim)\n",
    "\n",
    "dataset = torch.randn(seq_len, batch_size, input_dim)\n",
    "hidden = torch.zeros(batch_size, hidden_dim)\n",
    "\n",
    "for idx, input in enumerate(dataset):\n",
    "    print(f\"{'='*20} {idx+1} {'='*20}\")\n",
    "    print(\"Input size:\", input.shape)\n",
    "\n",
    "    hidden = cell(input, hidden)\n",
    "\n",
    "    print(\"Hidden size:\", hidden.shape)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use RNN in PyTorch?\n",
    "\n",
    "```python\n",
    "cell = torch.nn.RNN(input_size, hidden_size, num_layers, ...)\n",
    "output, hidden = cell(input, hidden)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([3, 1, 2])\n",
      "tensor([[[0.1076, 0.8134]],\n",
      "\n",
      "        [[0.0182, 0.8129]],\n",
      "\n",
      "        [[0.4016, 0.5810]]], grad_fn=<StackBackward0>)\n",
      "Hidden size: torch.Size([1, 1, 2])\n",
      "tensor([[[0.4016, 0.5810]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "output, hidden = cell(inputs, hidden)\n",
    "\n",
    "print(\"Output size:\", output.shape)\n",
    "print(output)\n",
    "print(\"Hidden size:\", hidden.shape)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example-1: Transform `hello` to `ohlol` using a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted String: hohhh\n",
      "Epoch: 1, Loss: 7.254288673400879\n",
      "Predicted String: ooohh\n",
      "Epoch: 2, Loss: 5.930866241455078\n",
      "Predicted String: oolol\n",
      "Epoch: 3, Loss: 5.167537689208984\n",
      "Predicted String: oolll\n",
      "Epoch: 4, Loss: 4.718964576721191\n",
      "Predicted String: oolll\n",
      "Epoch: 5, Loss: 4.37188720703125\n",
      "Predicted String: oolll\n",
      "Epoch: 6, Loss: 4.059685707092285\n",
      "Predicted String: ohlll\n",
      "Epoch: 7, Loss: 3.7832038402557373\n",
      "Predicted String: ohlll\n",
      "Epoch: 8, Loss: 3.5647475719451904\n",
      "Predicted String: ohlll\n",
      "Epoch: 9, Loss: 3.3996331691741943\n",
      "Predicted String: ohlll\n",
      "Epoch: 10, Loss: 3.2502315044403076\n",
      "Predicted String: ohlll\n",
      "Epoch: 11, Loss: 3.0879557132720947\n",
      "Predicted String: ohlol\n",
      "Epoch: 12, Loss: 2.9208261966705322\n",
      "Predicted String: ohlol\n",
      "Epoch: 13, Loss: 2.7625157833099365\n",
      "Predicted String: ohlol\n",
      "Epoch: 14, Loss: 2.6187357902526855\n",
      "Predicted String: ohlol\n",
      "Epoch: 15, Loss: 2.496582508087158\n"
     ]
    }
   ],
   "source": [
    "# Step.1 Prepare Data\n",
    "idx2char = list('ehlo')\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]\n",
    "\n",
    "batch_size = 1\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "\n",
    "one_hot_lookup = [[1 if i == j else 0 for i in range(4)] for j in range(4)]\n",
    "x_one_hot = [one_hot_lookup[i] for i in x_data]\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)\n",
    "\n",
    "# Step.2 Design Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.rnncell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnncell(input, hidden)\n",
    "        return hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "\n",
    "net = Model(input_size=input_size, hidden_size=hidden_size, batch_size=batch_size)\n",
    "\n",
    "# Step.3 Loss and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "# Step.4 Train the model\n",
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print(\"Predicted String: \", end='')\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = net(input, hidden)\n",
    "        loss += criterion(hidden, label)\n",
    "        _, idx = hidden.max(dim=1)\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'\\nEpoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example-2: Using RNN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: eeeee\n",
      "Epoch: 1, Loss: 1.6607351303100586\n",
      "Predicted: eheee\n",
      "Epoch: 2, Loss: 1.51809823513031\n",
      "Predicted: ehlel\n",
      "Epoch: 3, Loss: 1.375065565109253\n",
      "Predicted: ehlll\n",
      "Epoch: 4, Loss: 1.2383852005004883\n",
      "Predicted: ehlll\n",
      "Epoch: 5, Loss: 1.1171627044677734\n",
      "Predicted: ohlll\n",
      "Epoch: 6, Loss: 1.0149692296981812\n",
      "Predicted: ohlll\n",
      "Epoch: 7, Loss: 0.9291753768920898\n",
      "Predicted: ohlll\n",
      "Epoch: 8, Loss: 0.8549618721008301\n",
      "Predicted: ohlll\n",
      "Epoch: 9, Loss: 0.789040744304657\n",
      "Predicted: ohlll\n",
      "Epoch: 10, Loss: 0.7315219044685364\n",
      "Predicted: ohlll\n",
      "Epoch: 11, Loss: 0.6842751502990723\n",
      "Predicted: ohlol\n",
      "Epoch: 12, Loss: 0.6474617719650269\n",
      "Predicted: ohlol\n",
      "Epoch: 13, Loss: 0.6184414625167847\n",
      "Predicted: ohlol\n",
      "Epoch: 14, Loss: 0.5939062833786011\n",
      "Predicted: ohlol\n",
      "Epoch: 15, Loss: 0.5719873905181885\n"
     ]
    }
   ],
   "source": [
    "# Step.1 Prepare Data\n",
    "idx2char = list('ehlo')\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]\n",
    "\n",
    "batch_size = 1\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "seq_len = 5\n",
    "\n",
    "one_hot_lookup = [[1 if i == j else 0 for i in range(4)] for j in range(4)]\n",
    "x_one_hot = [one_hot_lookup[i] for i in x_data]\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data)\n",
    "\n",
    "# Step.2 Design Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers=1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        out, _ = self.rnn(input, hidden)\n",
    "        return out.view(-1, self.hidden_size)\n",
    "\n",
    "net = Model(input_size=input_size, hidden_size=hidden_size, batch_size=batch_size, num_layers=num_layers)\n",
    "\n",
    "# Step.3 Loss and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "\n",
    "# Step.4 Train the model\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print(f'Predicted: {\"\".join([idx2char[i] for i in idx])}')\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example-3: Using Embedding and Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: hhhhh\n",
      "Epoch: 1, Loss: 1.4088255167007446\n",
      "Predicted: hhhhl\n",
      "Epoch: 2, Loss: 1.1075539588928223\n",
      "Predicted: oolol\n",
      "Epoch: 3, Loss: 0.8866984248161316\n",
      "Predicted: oolol\n",
      "Epoch: 4, Loss: 0.7328249216079712\n",
      "Predicted: oolol\n",
      "Epoch: 5, Loss: 0.6074686646461487\n",
      "Predicted: oolol\n",
      "Epoch: 6, Loss: 0.49092087149620056\n",
      "Predicted: oolol\n",
      "Epoch: 7, Loss: 0.37829408049583435\n",
      "Predicted: ohlol\n",
      "Epoch: 8, Loss: 0.2831459045410156\n",
      "Predicted: ohlol\n",
      "Epoch: 9, Loss: 0.20173685252666473\n",
      "Predicted: ohlol\n",
      "Epoch: 10, Loss: 0.13246771693229675\n",
      "Predicted: ohlol\n",
      "Epoch: 11, Loss: 0.08586840331554413\n",
      "Predicted: ohlol\n",
      "Epoch: 12, Loss: 0.05977001041173935\n",
      "Predicted: ohlol\n",
      "Epoch: 13, Loss: 0.04366439953446388\n",
      "Predicted: ohlol\n",
      "Epoch: 14, Loss: 0.0322958268225193\n",
      "Predicted: ohlol\n",
      "Epoch: 15, Loss: 0.024418506771326065\n"
     ]
    }
   ],
   "source": [
    "# Step.1 Prepare Data\n",
    "idx2char = list('ehlo')\n",
    "x_data = [[1, 0, 2, 2, 3]]\n",
    "y_data = [3, 1, 2, 3, 2]\n",
    "\n",
    "num_class = 4\n",
    "batch_size = 1\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embadding_size = 10\n",
    "num_layers = 2\n",
    "seq_len = 5\n",
    "\n",
    "inputs = torch.LongTensor(x_data)\n",
    "labels = torch.LongTensor(y_data)\n",
    "\n",
    "# Step.2 Design Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(input_size, embadding_size)\n",
    "\n",
    "        self.rnn = torch.nn.RNN(input_size=embadding_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        x = self.emb(x)\n",
    "        x, _ = self.rnn(x, hidden)\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, num_class)\n",
    "\n",
    "net = Model()\n",
    "\n",
    "# Step.3 Loss and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "\n",
    "# Step.4 Train the model\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print(f'Predicted: {\"\".join([idx2char[i] for i in idx])}')\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "- 学习使用 LSTM\n",
    "- 学习使用 GRU "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpteam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
